@article{Abramo2013,
abstract = {Unlike competitive higher education systems, non-competitive systems show relatively uniform distributions of top researchers and low performers among universities. In this study, we examine the impact of unproductive and top faculty members on overall research performance of the university they belong to. Furthermore, we analyze the potential relationship between research productivity of a university and the indexes of concentration of unproductive and top researchers. Research performance is evaluated using a bibliometric approach, through publications indexed on the Web of Science between 2004 and 2008. The set analyzed consists of all Italian universities active in the hard sciences. ?? 2012 Elsevier Ltd.},
author = {Abramo, Giovanni and Cicero, Tindaro and D'Angelo, Ciriaco Andrea},
doi = {10.1016/j.joi.2012.10.006},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abramo, Cicero, D'Angelo - 2013 - The impact of unproductive and top researchers on overall university research performance.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliometrics,Productivity,Rankings,Research evaluation,Top researchers,Universities},
number = {1},
pages = {166--175},
publisher = {Elsevier Ltd},
title = {{The impact of unproductive and top researchers on overall university research performance}},
url = {http://dx.doi.org/10.1016/j.joi.2012.10.006},
volume = {7},
year = {2013}
}
@article{Abramo2012,
abstract = {Because of the variations in citation behavior across research fields, appropriate standardization must be applied as part of any bibliometric analysis of the productivity of individual scientists and research organizations. Such standardization involves scaling by some factor that characterizes the distribution of the citations of articles from the same year and subject category. In this work we conduct an analysis of the sensitivity of researchers' productivity rankings to the scaling factor chosen to standardize their citations. To do this we first prepare the productivity rankings for all researchers (more than 30,000) operating in the hard sciences in Italy, over the period 2004-2008. We then measure the shifts in rankings caused by adopting scaling factors other than the particular factor that seems more effective for comparing the impact of publications in different fields: the citation average of the distribution of cited-only publications. ?? 2012 Elsevier Ltd.},
author = {Abramo, Giovanni and Cicero, Tindaro and D'Angelo, Ciriaco Andrea},
doi = {10.1016/j.joi.2012.07.002},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abramo, Cicero, D'Angelo - 2012 - How important is choice of the scaling factor in standardizing citations.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliometrics,Citations,Productivity,Research evaluation,Researchers,Scaling,Sensitivity analysis},
number = {4},
pages = {645--654},
publisher = {Elsevier Ltd},
title = {{How important is choice of the scaling factor in standardizing citations?}},
url = {http://dx.doi.org/10.1016/j.joi.2012.07.002},
volume = {6},
year = {2012}
}
@article{Abramo2015,
abstract = {Research performance values are not certain. Performance indexes should therefore be accompanied by uncertainty measures, to establish whether the performance of a unit is truly outstanding and not the result of random fluctuations. In this work we focus on the evaluation of research institutions on the basis of average individual performance, where uncertainty is inversely related to the number of research staff. We utilize the funnel plot, a tool originally developed in meta-analysis, to measure and visualize the uncertainty in the performance values of research institutions. As an illustrative example, we apply the funnel plot to represent the uncertainty in the assessed research performance for Italian universities active in biochemistry.},
author = {Abramo, Giovanni and D'Angelo, Ciriaco Andrea and Grilli, Leonardo},
doi = {10.1016/j.joi.2015.08.006},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abramo, D'Angelo, Grilli - 2015 - Funnel plots for visualizing uncertainty in the research performance of institutions.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Bibliometrics,FSS,Funnel plots,Research evaluation,Universities},
number = {4},
pages = {954--961},
publisher = {Elsevier Ltd},
title = {{Funnel plots for visualizing uncertainty in the research performance of institutions}},
url = {http://dx.doi.org/10.1016/j.joi.2015.08.006},
volume = {9},
year = {2015}
}
@article{Abramo2014,
abstract = {Productivity is the quintessential indicator of efficiency in any production system. It seems it has become a norm in bibliometrics to define research productivity as the number of publications per researcher, distinguishing it from impact. In this work we operationalize the economic concept of productivity for the specific context of research activity and show the limits of the commonly accepted definition. We propose then a measurable form of research productivity through the indicator ''Fractional Scientific Strength (FSS)'', in keeping with the microeconomic theory of production. We present the methodology for measure of FSS at various levels of analysis: individual, field, discipline, department, institution, region and nation. Finally, we compare the ranking lists of Italian universities by the two definitions of research productivity.},
author = {Abramo, Giovanni and D'Angelo, Ciriaco Andrea},
doi = {10.1007/s11192-014-1269-8},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abramo, D'Angelo - 2014 - How do you define and measure research productivity.pdf:pdf},
isbn = {0138-9130 1588-2861},
issn = {15882861},
journal = {Scientometrics},
keywords = {FSS,Research evaluation,Research productivity,University rankings},
number = {2},
pages = {1129--1144},
title = {{How do you define and measure research productivity?}},
volume = {101},
year = {2014}
}
@article{Abramo2016,
abstract = {The ability to attract and retain talented professors is a distinctive competence of world-class universities and a source of competitive advantage. The ratio of top scientists to academic staff could therefore be an indicator of the competitive strength of the universities. This work identifies the Italian top scientists in over 200 fields, by their research productivity. It then ranks the relative universities by the ratio of top scientists to overall faculty. Finally, it contrasts this list with the ranking list by average productivity of the overall faculty. The analysis is carried out at the field, discipline, and overall university levels. The paper also explores the secondary question of whether the ratio of top scientists to faculty is related to the size of the university.},
author = {Abramo, Giovanni and D'Angelo, Ciriaco Andrea and Soldatenkova, Anastasiia},
doi = {10.1016/j.joi.2016.04.013},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abramo, D'Angelo, Soldatenkova - 2016 - The ratio of top scientists to the academic staff as an indicator of the competitive strength.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliometrics,FSS,Italy,Rankings,Research evaluation},
number = {2},
pages = {596--605},
publisher = {Elsevier Ltd},
title = {{The ratio of top scientists to the academic staff as an indicator of the competitive strength of universities}},
url = {http://www.sciencedirect.com/science/article/pii/S175115771630027X},
volume = {10},
year = {2016}
}
@article{Abrizah2013,
abstract = {The study compares the coverage, ranking, impact and subject categorization of Library and Information Science journals, specifically, 79 titles based on data from Web of Science (WoS) and 128 titles from Scopus. Comparisons were made based on prestige factor scores reported in 2010 Journal Citation Reports and SCImago Journal Rank 2010 and noting the change in ranking when the differences are calculated. The rank normalized impact factor and the Library of Congress Classification System were used to compare impact rankings and subject categorization. There was high degree of similarity in rank normalized impact factor of titles in both WoS and Scopus databases. The searches found 162 journals, with 45 journals appearing in both databases. The rankings obtained for normalized impact scores confirm higher impact scores for titles covered in Scopus because of its larger coverage of titles. There was mismatch of subject categorization among 34 journal titles in both databases and 22 of the titles were not classified under Z subject headings in the Library of Congress catalogue. The results revealed the changes in journal title rankings when normalized, and the categorization of some journal titles in these databases might be incorrect.},
author = {Abrizah, A. and Zainab, A. N. and Kiran, K. and Raj, R. G.},
doi = {10.1007/s11192-012-0813-7},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abrizah et al. - 2013 - LIS journals scientific impact and subject categorization A comparison between Web of Science and Scopus.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Bibliometrics,Journal impact,Journal ranking,Journal studies,Library and Information Science,Rank normalized impact factor},
number = {2},
pages = {721--740},
title = {{LIS journals scientific impact and subject categorization: A comparison between Web of Science and Scopus}},
volume = {94},
year = {2013}
}
@article{Adachi2015,
abstract = {We provide three axiomatic characterizations of Egghe's g-index, which measures a researcher's scientific output based on the number of papers the researcher has published and the number of citations of each of the researcher's papers. We formulate six new axioms for indexes, namely, tail independence (TA), square monotonicity (SM), the cap condition (CC), strong square monotonicity (SSM), increasing marginal citations (IMC), and increasing marginal citations+ (IMC+). Along with the two well-known axioms T1 and T2 (Woeginger, 2008a), the g-index is characterized by (i) T1, T2, TA, SM, and CC, (ii) T1, T2, TA, SSM, and IMC, and (iii) T1, TA, SM, and IMC+. Two out of three characterizations are obtained by adding axioms to our new characterization of the class of indexes satisfying T1, T2, and TA, which are defined as generalizations of the g-index. Thus, the remaining four axioms in our first and second characterizations-SM, CC, SSM, and IMC-distinguish the original g-index from other related indexes in the class. Furthermore, the independence of our axioms and that of Woeginger's study is shown.},
author = {Adachi, Tsuyoshi and Kongo, Takumi},
doi = {10.1016/j.joi.2015.07.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adachi, Kongo - 2015 - Further axiomatizations of Egghe's g-index.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Axiomatization,Citation,Egghe's g-index,Increasing marginal citation,Square monotonicity,Tail independence},
number = {4},
pages = {839--844},
publisher = {Elsevier Ltd},
title = {{Further axiomatizations of Egghe's g-index}},
url = {http://dx.doi.org/10.1016/j.joi.2015.07.001},
volume = {9},
year = {2015}
}
@article{Adams2009,
abstract = {Research assessment in the UK has evolved over a quarter of a century from a loosely structured, peer-review based process to one with a well understood data portfolio and assessment methodology. After 2008, the assessment process will shift again, to the use of indicators based largely on publication and citation data. These indicators will in part follow the format introduced in 2008, with a profiling of assessment outcomes at national and international levels. However, the shift from peer assessment to a quantitative methodology raises critical issues about which metrics are appropriate and informative and how such metrics should be managed to produce weighting factors for funding formulae. The link between publication metrics and other perceptions of research quality needs to be thoroughly tested and reviewed, and may be variable between disciplines. Many of the indicators that drop out of publication data are poorly linked to quality and should not be used at all. There are also issues about which publications are the correct base for assessment, which staff should be included in a review, how subjects should be structured and how the citation data should be normalised to account for discipline-dependent variables. Finally, it is vital to consider the effect that any assessment process will have on the behaviour of those to be assessed.},
author = {Adams, Jonathan},
doi = {10.1007/s00005-009-0003-3},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adams - 2009 - The use of bibliometrics to measure research quality in UK higher education institutions.pdf:pdf},
isbn = {0004-069X$\backslash$r1661-4917},
issn = {0004069X},
journal = {Archivum Immunologiae et Therapiae Experimentalis},
keywords = {Assessment,Indicators,Peer review,Profiling},
number = {1},
pages = {19--32},
pmid = {19219531},
title = {{The use of bibliometrics to measure research quality in UK higher education institutions}},
volume = {57},
year = {2009}
}
@article{Ahlgren2012,
abstract = {We compared three different bibliometric evaluation approaches: two citation-based approaches and one based on manual classification of publishing channels into quality levels. Publication data for two universities was used, and we worked with two levels of analysis: article and department. For the article level, we investigated the predictive power of field normalized citation rates and field normalized journal impact with respect to journal level. The results for the article level show that evaluation of journals based on citation impact correlate rather well with manual classification of journals into quality levels. However, the prediction from field normalized citation rates to journal level was only marginally better than random guessing. At the department level, we studied three different indicators in the context of research fund allocation within universities and the extent to which the three indicators produce different distributions of research funds. It turned out that the three distributions of relative indicator values were very similar, which in turn yields that the corresponding distributions of hypothetical research funds would be very similar. },
author = {Ahlgren, Per and Colliander, Cristian and Persson, Olle},
doi = {10.1007/s11192-012-0632-x},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahlgren, Colliander, Persson - 2012 - Field normalized citation rates, field normalized journal impact and Norwegian weights for allocat.pdf:pdf},
issn = {01389130},
journal = {Scientometrics},
keywords = {Field normalized citation rates,Journal impact,Norwegian model,Research fund allocation},
number = {3},
pages = {767--780},
title = {{Field normalized citation rates, field normalized journal impact and Norwegian weights for allocation of university research funds}},
volume = {92},
year = {2012}
}
@article{Almeida2009,
abstract = {In this communication we perform an analysis of European science, investigating the way countries are joined in clusters according to their similarity. An extremely clear pattern arises, suggesting that geographical and cultural factors strongly influence the scientific fabric of these countries. Although it is seen that one of the major factors behind Science in Europe is, apparently, geographical proximity, bilateral cooperation between countries cannot fully account for the respective similarity. Long-term policies, planning and investment are also visible in the results. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
author = {Almeida, J. A S and Pais, A. A C C and Formosinho, S. J.},
doi = {10.1016/j.joi.2009.01.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Almeida, Pais, Formosinho - 2009 - Science indicators and science patterns in Europe.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Essential science indicators,European science,Scientific productivity,Web of science},
number = {2},
pages = {134--142},
title = {{Science indicators and science patterns in Europe}},
volume = {3},
year = {2009}
}
@article{Alonso2009,
abstract = {The h-index and some related bibliometric indices have received a lot of attention from the scientific community in the last few years due to some of their good properties (easiness of computation, balance between quantity of publications and their impact and so on). Many different indicators have been developed in order to extend and overcome the drawbacks of the original Hirsch proposal. In this contribution we present a comprehensive review on the h-index and related indicators field. From the initial h-index proposal we study their main advantages, drawbacks and the main applications that we can find in the literature. A description of many of the h-related indices that have been developed along with their main characteristics and some of the works that analyze and compare them are presented. We also review the most up to date standardization studies that allow a fair comparison by means of the h-index among scientists from different research areas and finally, some works that analyze the computation of the h-index and related indices by using different citation databases (ISI Citation Indexes, Google Scholar and Scopus) are introduced. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
author = {Alonso, S. and Cabrerizo, F. J. and Herrera-Viedma, E. and Herrera, F.},
doi = {10.1016/j.joi.2009.04.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alonso et al. - 2009 - h-Index A review focused in its variants, computation and standardization for different scientific fields.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliometric indicators,h-Index},
number = {4},
pages = {273--289},
title = {{h-Index: A review focused in its variants, computation and standardization for different scientific fields}},
volume = {3},
year = {2009}
}
@article{Alves2014,
abstract = {Benford's Law is a logarithmic probability distribution function used to predict the distribution of the first significant digits in numerical data. This paper presents the results of a study of the distribution of the first significant digits of the number of articles published of journals indexed in the JCR({\textregistered}) Sciences and Social Sciences Editions from 2007 to 2011. The data of these journals were also analyzed by the country of origin and the journal's category. Results considering the number of articles published informed by Scopus are also presented. Comparing the results we observe that there is a significant difference in the data informed in the two databases.},
author = {Alves, Alexandre Donizeti and Yanasse, Horacio Hideki and Soma, Nei Yoshihiro},
doi = {10.1007/s11192-013-1030-8},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alves, Yanasse, Soma - 2014 - Benford's Law and articles of scientific journals Comparison of JCR{\textregistered} and Scopus data.pdf:pdf},
issn = {01389130},
journal = {Scientometrics},
keywords = {Articles,Benford's Law,JCR{\textregistered},Scopus},
number = {1},
pages = {173--184},
pmid = {24415809},
title = {{Benford's Law and articles of scientific journals: Comparison of JCR{\textregistered} and Scopus data}},
volume = {98},
year = {2014}
}
@article{Amara2015,
abstract = {Studies on publication and citation scores tend to focus mostly on frequently published and cited scholars. This paper contributes to advancing knowledge by simul-taneously looking into both high and low performing scholars, including non-publishing scholars, and by focusing on factors increasing or impeding scholarly performances. To this end, two complementary sources of data are used: (1) data from ISI web of science on publications and citations of scholars from 35 Canadian business schools and, and (2) survey data on factors explaining the productivity and impact performances of these scholars. The analysis of the data reveals five scholar profiles: (i) non-publishing scholars; (ii) low performing scholars; (iii) frequently publishing scholars; (iv) frequently cited scholars and; (v) high-impact frequently publishing scholars. Statistical modeling is then used to look into factors that explain why scholars are any of these performance con-figuration rather another. Two major results emerge: first, scholars in the low performing profile differ from those in the non-publishing profile only by being in top tier universities and by having high levels of funding from research councils. Second, scholars who publish frequently and are frequently cited differ from those in the low performing profile in many ways: they are full professors, they dedicate more time to their research activities, they receive all their research funding from research councils, and, finally, they are located in top tier universities. The last part of the paper discusses policy implications for the de-velopment of research skills by university managers willing to increase the publication and citation scores of their faculty members.},
author = {Amara, Nabil and Landry, R{\'{e}}jean and Halilem, Norrin},
doi = {10.1007/s11192-015-1537-2},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amara, Landry, Halilem - 2015 - What can university administrators do to increase the publication and citation scores of their faculty m.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Academic rank,Citations,Fields,Publications,Survey,Time allocation},
number = {2},
pages = {489--530},
title = {{What can university administrators do to increase the publication and citation scores of their faculty members?}},
volume = {103},
year = {2015}
}
@article{Amjad2015,
abstract = {Topic-based ranking of authors, papers and journals can serve as a vital tool for identifying authorities of a given topic within a particular domain. Existing methods that measure topic-based scholarly output are limited to homogeneous networks. This study proposes a new informative metric called Topic-based Heterogeneous Rank (TH Rank) which measures the impact of a scholarly entity with respect to a given topic in a heterogeneous scholarly network containing authors, papers and journals. TH Rank calculates topic-dependent ranks for authors by considering the combined impact of the multiple factors which contribute to an author's level of prestige. Information retrieval serves as the test field and articles about information retrieval published between 1956 and 2014 were extracted from web of science. Initial results show that TH Rank can effectively identify the most prestigious authors, papers and journals related to a specific topic. [ABSTRACT FROM AUTHOR]},
author = {Amjad, Tehmina and Ding, Ying and Daud, Ali and Xu, Jian and Malic, Vincent},
doi = {10.1007/s11192-015-1601-y},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amjad et al. - 2015 - Topic-based heterogeneous rank.pdf:pdf},
issn = {01389130},
journal = {Scientometrics},
keywords = {Heterogeneous networks,Topic modeling,Topic sensitive ranking,Topic-based rank},
number = {1},
pages = {313--334},
publisher = {Springer Netherlands},
title = {{Topic-based heterogeneous rank}},
url = {"http://dx.doi.org/10.1007/s11192-015-1601-y},
volume = {104},
year = {2015}
}
@techreport{Archambault2004,
abstract = {The Social Sciences and Humanities Research Council (SSHRC) asked Science-Metrix to identify current practices in bibliometric evaluation of research in the social sciences and humanities (SSH). The resulting study involves a critical review of the literature in order to identify the specific characteristics of the SSH and their effects on the use of bibliometrics for evaluating and mapping research. In addition, this report presents an overview of methods of research benchmarking and mapping and identification of emerging SSH fields. This part of the report is particularly relevant because of the need to exercise considerable caution when using bibliometrics to evaluate and map SSH research. This report shows that bibliometrics must be used with care and caution in a number of SSH disciplines. Knowledge dissemination media in the SSH are different from those in the natural sciences and engineering (NSE), particularly because of the much greater role of books in the SSH. Articles account for 45{\%} to 70{\%} of research output in the social sciences and for 20{\%} to 35{\%} in the humanities, depending on the discipline. Bibliometric analyses that focus solely on research published in journals may not give an accurate representation of SSH research output. In addition, bibliometric analyses reflect the biases of the databases used. For example, the Social Science Citation Index (SSCI) and the Arts and Humanities Citation Index (AHCI) of Thomson ISI over-represent research output published in English. Original findings produced by this study show that the},
author = {Archambault, E and {Vignola Gagn{\'{e}}}, E},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Archambault, Vignola Gagn{\'{e}} - 2004 - The Use of Bibliometrics in the Social Sciences and Humanities.pdf:pdf},
institution = {www.science-metrix.com},
issn = {00280836},
pages = {1--79},
title = {{The Use of Bibliometrics in the Social Sciences and Humanities}},
url = {http://www.science-metrix.com/pdf/SM{\_}2004{\_}008{\_}SSHRC{\_}Bibliometrics{\_}Social{\_}Science.pdf},
year = {2004}
}
@article{ArchambaultEric;CampbellDavid;GingrasYves;Lariviere2009,
archivePrefix = {arXiv},
arxivId = {0803.1716},
author = {{Archambault, {\'{E}}ric; Campbell, David; Gingras, Yves; Larivi{\`{e}}re}, Vincent},
doi = {10.1002/asi},
eprint = {0803.1716},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Archambault, ric Campbell, David Gingras, Yves Larivire - 2009 - Comparing Bibliometric Statistics Obtained From theWeb of Science and.pdf:pdf},
isbn = {9783848215430},
issn = {14923831},
journal = {Journal of the American Society for Information Science and Technology},
number = {7},
pages = {1320--1326},
pmid = {502955140},
title = {{Comparing Bibliometric Statistics Obtained From theWeb of Science and Scopus {\'{E}}ric}},
volume = {60},
year = {2009}
}

@article{Ausloos2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1207.1614v1},
author = {Ausloos, M.},
doi = {10.1007/s11192-012-0936-x},
eprint = {arXiv:1207.1614v1},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ausloos - 2013 - A scientometrics law about co-authors and their ranking The co-author core.pdf:pdf},
isbn = {1119201209},
issn = {01389130},
journal = {Scientometrics},
number = {3},
pages = {895--909},
title = {{A scientometrics law about co-authors and their ranking: The co-author core}},
volume = {95},
year = {2013}
}
@article{Bailon-Moreno2005,
abstract = {The bibliometric laws of Zipf, Bradford, and Lotka, in their various mathematical expressions, frequently present difficulties in the fitting of empirical values. The empirical flaws of fit take place in the frequency of the words, in the productivity of the authors and the journals, as well as in econometric and demographic aspects. This indicates that the underlying fractal model should be revised, since, as shown, the inverse power equations (of the Zipf{\~{n}}Mandelbrot type) are not adequate, as they need to include exponential terms. These modifications not only affect Bibliometrics and Scientometrics, but also, for the generality of the fractal model, apply to Economy, Demography, and even Natural Sciences in general.},
author = {Bail{\'{o}}n-Moreno, R. and Jurado-Alameda, E. and Ruiz-Bao{\~{N}}s, R. and Courtial, J. P.},
doi = {10.1007/s11192-005-0211-5},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bailn-Moreno et al. - 2005 - Bibliometric laws Empirical flaws of fit.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {2},
pages = {209--229},
title = {{Bibliometric laws: Empirical flaws of fit}},
volume = {63},
year = {2005}
}
@article{Banks2006,
abstract = {This paper argues that the distinction between grey and non-grey (or white) literature will become less relevant over time, as online discovery options proliferate.  In the meantime, the political success of the open access publishing movement has valuable lessons for proponents of increasing access to grey literature.},
author = {Banks, Marcus A.},
doi = {10.1007/s12109-006-0002-8},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Banks - 2006 - Towards a continuum of scholarship The eventual collapse of the distinction between grey and non-grey literature.pdf:pdf},
issn = {10538801},
journal = {Publishing Research Quarterly},
number = {1},
pages = {4--11},
title = {{Towards a continuum of scholarship: The eventual collapse of the distinction between grey and non-grey literature}},
volume = {22},
year = {2006}
}
@article{Banks2006a,
abstract = {An interesting twist of the Hirsch index is given, in terms of an index for topics and compounds. By comparing both the hb index and m for a number of compounds and topics, it can be used to differentiate between a new so-called hot topic with older topics. This quick method is shown to help new comers to identify how much interest and work has already been achieved in their chosen area of research.},
archivePrefix = {arXiv},
arxivId = {physics/0604216},
author = {Banks, Michael G.},
doi = {10.1007/s11192-006-0146-5},
eprint = {0604216},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Banks - 2006 - An extension of the Hirsch index Indexing scientific topics and compounds.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {1},
pages = {161--168},
primaryClass = {physics},
title = {{An extension of the Hirsch index: Indexing scientific topics and compounds}},
volume = {69},
year = {2006}
}
@article{Bar-Ilan2008a,
abstract = {This paper compares the h-indices of a list of highly-cited Israeli researchers based on citations counts retrieved from the Web of Science, Scopus and Google Scholar respectively. In several case the results obtained through Google Scholar are considerably different from the results based on the Web of Science and Scopus. Data cleansing is discussed extensively.},
archivePrefix = {arXiv},
arxivId = {cs/0612132},
author = {Bar-Ilan, Judit},
doi = {10.1007/s11192-008-0216-y},
eprint = {0612132},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bar-Ilan - 2008 - Which h-index - A comparison of WoS, Scopus and Google Scholar.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {2},
pages = {257--271},
pmid = {16805916},
primaryClass = {cs},
title = {{Which h-index? - A comparison of WoS, Scopus and Google Scholar}},
volume = {74},
year = {2008}
}
@article{Bar-Ilan2010,
abstract = {Google Scholar and Scopus are recent rivals to Web of Science. In this paper we examined these three citation databases through the citations of the book "Introduction to informetrics" by Leo Egghe and Ronald Rousseau. Scopus citations are comparable to Web of Science citations when limiting the citation period to 1996 and onwards (the citation coverage of Scopus)-each database covered about 90{\%} of the citations located by the other. Google Scholar missed about 30{\%} of the citations covered by Scopus and Web of Science (90 citations), but another 108 citations located by Google Scholar were not covered either by Scopus or by Web of Science. Google Scholar performed considerably better than reported in previous studies, however Google Scholar is not very "user-friendly" as a bibliometric data collection tool at this point in time. Such "microscopic" analysis of the citing documents retrieved by each of the citation databases allows us a deeper understanding of the similarities and the differences between the databases. {\textcopyright} 2010 Akad{\'{e}}miai Kiad{\'{o}}, Budapest, Hungary.},
author = {Bar-Ilan, Judit},
doi = {10.1007/s11192-010-0185-9},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bar-Ilan - 2010 - Citations to the Introduction to informetrics indexed by WOS, Scopus and Google Scholar.pdf:pdf},
isbn = {1119201001859},
issn = {01389130},
journal = {Scientometrics},
keywords = {Citations,Google Scholar,Introduction to informetrics,Scopus,Web of Science},
number = {3},
pages = {495--506},
title = {{Citations to the "Introduction to informetrics" indexed by WOS, Scopus and Google Scholar}},
volume = {82},
year = {2010}
}
@article{Bar-Ilan2008,
abstract = {This paper reviews developments in informetrics between 2000 and 2006. At the beginning of the 21st century we witness considerable growth in webometrics, mapping and visualization and open access. A new topic is comparison between citation databases, as a result of the introduction of two new citation databases Scopus and Google Scholar. There is renewed interest in indicators as a result of the introduction of the h-index. Traditional topics like citation analysis and informetric theory also continue to develop. The impact factor debate, especially outside the informetric literature continues to thrive. Ranked lists (of journal, highly cited papers or of educational institutions) are of great public interest. ?? 2007 Elsevier Ltd. All rights reserved.},
author = {Bar-Ilan, Judit},
doi = {10.1016/j.joi.2007.11.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bar-Ilan - 2008 - Informetrics at the beginning of the 21st century-A review.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliometrics,Informetrics,Scientometrics,Webometrics},
number = {1},
pages = {1--52},
title = {{Informetrics at the beginning of the 21st century-A review}},
volume = {2},
year = {2008}
}
@article{Bartneck2010,
abstract = {Collaboration between researchers and between research organizations is generally considered a desirable course of action, in particular by some funding bodies. However, collaboration within a multidisciplinary community, such as the Computer-Human Interaction (CHI) community, can be challenging. We performed a bibliometric analysis of the CHI conference proceedings to determine if papers that have authors from different organization or countries receive more citations than papers that are authored by members of the same organization. There was no significant difference between these three groups, indicating that there is no advantage for collaboration in terms of citation frequency. Furthermore, we tested if papers written by authors from different organizations or countries receive more best paper awards or at least award nominations. Papers from only one organization received significantly fewer nominations than collaborative papers.},
author = {Bartneck, Christoph and Hu, Jun},
doi = {10.1007/s11192-010-0242-4},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bartneck, Hu - 2010 - The fruits of collaboration in a multidisciplinary field.pdf:pdf},
isbn = {0138-9130 (Print)$\backslash$n0138-9130 (Linking)},
issn = {01389130},
journal = {Scientometrics},
keywords = {Bibliometrics,Citations,Collaboration,Organizations},
number = {1},
pages = {41--52},
pmid = {20927182},
title = {{The fruits of collaboration in a multidisciplinary field}},
volume = {85},
year = {2010}
}
@article{Bartneck2011,
abstract = {The h-index has received an enormous attention for being an indicator that measures the quality of researchers and organizations. We investigate to what degree authors can inflate their h-index through strategic self-citations with the help of a simulation. We extended Burrell's publication model with a procedure for placing self-citations, following three different strategies: random self-citation, recent self-citations and h-manipulating self-citations. The results show that authors can considerably inflate their h-index through self-citations. We propose the q-index as an indicator for how strategically an author has placed self-citations, and which serves as a tool to detect possible manipulation of the h-index. The results also show that the best strategy for an high h-index is publishing papers that are highly cited by others. The productivity has also a positive effect on the h-index.},
author = {Bartneck, Christoph and Kokkelmans, Servaas},
doi = {10.1007/s11192-010-0306-5},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bartneck, Kokkelmans - 2011 - Detecting h-index manipulation through self-citation analysis.pdf:pdf},
isbn = {0138-9130 (Print)$\backslash$n0138-9130 (Linking)},
issn = {01389130},
journal = {Scientometrics},
keywords = {Manipulation,Self-citation,Simulation,h-Index,q-Index},
number = {1},
pages = {85--98},
pmid = {21472020},
title = {{Detecting h-index manipulation through self-citation analysis}},
volume = {87},
year = {2011}
}
@article{Batista2006,
abstract = {The number h of papers with at least h citations has been proposed to evaluate individuals scientific research production. This index is robust in several ways but yet strongly dependent on the research field. We propose a complementary index 2 (T ) hI = h Na , with (T ) Na being the total number of authors in the considered h papers. A researcher with index hI has hI papers with at least hI citation if he/she had published alone. We have obtained the rank plots of h and hI for four Brazilian scientific communities. In contrast with the h-index, the hI index rank plots collapse into a single curve allowing comparison among different research areas.},
archivePrefix = {arXiv},
arxivId = {http://arxiv.org/ftp/physics/papers/0509/0509048.pdf},
author = {Batista, Pablo D. and Campiteli, M??nica G. and Kinouchi, Osame and Martinez, Alexandre S.},
doi = {10.1007/s11192-006-0090-4},
eprint = {/arxiv.org/ftp/physics/papers/0509/0509048.pdf},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Batista et al. - 2006 - Is it possible to compare researchers with different scientific interests.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {1},
pages = {179--189},
primaryClass = {http:},
title = {{Is it possible to compare researchers with different scientific interests?}},
volume = {68},
year = {2006}
}
@inproceedings{Bell2001,
abstract = {This paper considers the use of the freeware package XLISP-STAT (Tierney, 1990) and the add-on package ARC (Cook and Weisberg, 1999) to explore multilevel data structures before more formal modelling. Exploratory data analysis (Chatfield, 1988) is regarded as an essential before further analysis. XLISP- STAT is highly interactive and with ARC can be used to investigate multilevel structures graphically. This feature is used to demonstrate how exploratory analysis can be carried out for a range of multilevel models including those with binary or ordinal outcome variables. The advantages of this software are that it can be used to identify potential outliers before models are fitted and it is also possible to decide on suitable models for a more formal multilevel analysis.},
address = {Amsterdam},
author = {Bell, Jf},
booktitle = {Third International Conference on Multilevel Analysis},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bell - 2001 - Visualising multilevel models the initial analysis of data.pdf:pdf},
pages = {1--30},
title = {{Visualising multilevel models: the initial analysis of data}},
url = {http://www.cambridgeassessment.org.uk/images/109679-visualising-multilevel-models-the-initial-analysis-of-data.pdf},
year = {2001}
}
@book{Bellis2009,
address = {Lanham, Maryland 20706},
author = {Bellis, Nicola De},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellis - 2009 - Bibliometrics and.pdf:pdf},
isbn = {9780810867130},
pages = {451},
publisher = {The Scarecrow Press, Inc.},
title = {{Bibliometrics and citation analysis : from the Science citation index to cybermetrics}},
year = {2009}
}
@article{Bertoli-Barsotti2015,
abstract = {The h-index is a celebrated indicator widely used to assess the quality of researchers and organizations. Empirical studies support the fact that the h-index is well correlated with other simple bibliometric indicators, such as the total number of publications N and the total number of citations C. In this paper we introduce a new formula hww=hw(N,C,cMAX), as a representative predictive formula that relates functionally h to these aggregate indicators, N, C and the highest citation count cMAX. The formula is based on the 'specific' assumption of geometrically distributed citations, but provides a good estimate of the h-index for the general case. To empirically evaluate the adequacy of the fit of the proposed formula hww, an empirical study with 131 datasets (13,347 papers; 288,972 citations) was carried out. The overall fit (defined as the capacity of h{\~{}}w to reproduce the true value of h, for each single scientist) was remarkably accurate. The predicted value was within one of the actual value h for more than 60{\%} of the datasets. We found, in approximately three cases out of four, an absolute error less than or equal to 2, and an average absolute error of only 1.9, for the whole sample of datasets.},
author = {Bertoli-Barsotti, Lucio and Lando, Tommaso},
doi = {10.1016/j.joi.2015.07.004},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertoli-Barsotti, Lando - 2015 - On a formula for the h-index.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Citation data,Citation statistic,Geometric distribution,H-Index,Lambert W function},
number = {4},
pages = {762--776},
publisher = {Elsevier Ltd},
title = {{On a formula for the h-index}},
url = {http://dx.doi.org/10.1016/j.joi.2015.07.004},
volume = {9},
year = {2015}
}
@article{Biswal2013,
abstract = {Bibliographic analysis has been a very powerful tool in evaluating the effective contributions of a researcher and determining his/her future research potential. The lack of an absolute quantification of the author's scientific contributions by the existing measurement system hampers the decision-making process. In this paper, a new metric system, Absolute index (Ab-index), has been proposed that allows a more objective comparison of the contributions of a researcher. The Ab-index takes into account the impact of research findings while keeping in mind the physical and intellectual contributions of the author(s) in accomplishing the task. The Ab-index and h-index were calculated for 10 highly cited geneticists and molecular biologist and 10 young researchers of biological sciences and compared for their relationship to the researchers input as a primary author. This is the first report of a measuring method clarifying the contributions of the first author, corresponding author, and other co-authors and the sharing of credit in a logical ratio. A java application has been developed for the easy calculation of the Ab-index. It can be used as a yardstick for comparing the credibility of different scientists competing for the same resources while the Productivity index (Pr-index), which is the rate of change in the Ab-index per year, can be used for comparing scientists of different age groups. The Ab-index has clear advantage over other popular metric systems in comparing scientific credibility of young scientists. The sum of the Ab-indices earned by individual researchers of an institute per year can be referred to as Pr-index of the institute.},
author = {Biswal, Akshaya Kumar},
doi = {10.1371/journal.pone.0084334},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biswal - 2013 - An Absolute index (Ab-index) to measure a researcher's useful contributions and productivity.pdf:pdf},
isbn = {1932-6203 (Electronic)$\backslash$r1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
pages = {1--10},
pmid = {24391941},
title = {{An Absolute index (Ab-index) to measure a researcher's useful contributions and productivity}},
volume = {8},
year = {2013}
}
@article{Bjork2015,
abstract = {The subscription prices of peer-reviewed journals have in the past not been closely related to the scientific quality. This relationship has been further obscured by bundled e-licenses. The situation is different for Open Access (OA) journals that finance their operations via article processing charges (APCs). Due to competition and the fact that authors are often directly involved in making APC payments from their own or other limited funds, APC pricing has so far been sensitive to the quality and services offered by journals. We conducted a systematic survey of prices charged by OA journals indexed in Scopus and this revealed a moderate (0.40) correlation between the APCs and Source Normalized Impact per Paper values, a measure of citation rates. When weighted by article volumes the correlations between the quality and the price were significantly higher (0.67). This would seem to indicate that while publishers to some extent take the quality into account when pricing their journals, authors are even more sensitive to the relationship between price and quality in their choices of where to submit their manuscripts.},
author = {Bj{\"{o}}rk, Bo Christer and Solomon, David},
doi = {10.1007/s11192-015-1556-z},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bj{\"{o}}rk, Solomon - 2015 - Article processing charges in OA journals relationship between price and quality.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Business model,Open Access,SNIP value},
number = {2},
pages = {373--385},
title = {{Article processing charges in OA journals: relationship between price and quality}},
volume = {103},
year = {2015}
}
@article{Bollen2006,
abstract = {The status of an actor in a social context is commonly defined in terms of two factors: the total number of endorsements the actor receives from other actors and the prestige of the endorsing actors. These two factors indicate the distinction between popularity and expert appreciation of the actor, respectively. We refer to the former as popularity and to the latter as prestige. These notions of popularity and prestige also apply to the domain of scholarly assessment. The ISI Impact Factor (ISI IF) is defined as the mean number of citations a journal receives over a 2 year period. By merely counting the amount of citations and disregarding the prestige of the citing journals, the ISI IF is a metric of popularity, not of prestige. We demonstrate how a weighted version of the popular PageRank algorithm can be used to obtain a metric that reflects prestige. We contrast the rankings of journals according to their ISI IF and their weighted PageRank, and we provide an analysis that reveals both significant overlaps and differences. Furthermore, we introduce the Y-factor which is a simple combination of both the ISI IF and the weighted PageRank, and find that the resulting journal rankings correspond well to a general understanding of journal status.},
archivePrefix = {arXiv},
arxivId = {cs/0601030},
author = {Bollen, Johan and Rodriquez, Marko A. and {Van De Sompel}, Herbert},
doi = {10.1007/s11192-006-0176-z},
eprint = {0601030},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bollen, Rodriquez, Van De Sompel - 2006 - Journal status(2).pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {3},
pages = {669--687},
primaryClass = {cs},
title = {{Journal status}},
volume = {69},
year = {2006}
}
@article{Bonaccorsi2016,
abstract = {Rankings in higher education are largely used to summarize a huge amount of information into easily understandable numbers. They are also used by governments in order to allocate funding. Nevertheless, they are often criticized. One stream of criticism refers to the fact that rankings build up an ordinal order by considering only the mean of the distribution of indicators and not their variability. Using the micro-data from the Italian evaluation of the quality of research (VQR, Valutazione della Qualit{\`{a}} della Ricerca), we examine whether difference in performance between departments with different position in the ranking are distinguishable from random effects. We obtain a robust clustering of departments in a limited number of groups. The number of groups is in the range 3-7, while in most cases it is 4-6. The implications of these findings for evaluation and research policy are explored.},
author = {Bonaccorsi, Andrea and Cicero, Tindaro},
doi = {10.1016/j.joi.2016.01.007},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bonaccorsi, Cicero - 2016 - Nondeterministic ranking of university departments.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Departments ranking,National research assessment,Ranking,Research quality},
number = {1},
pages = {224--237},
publisher = {Elsevier Ltd},
title = {{Nondeterministic ranking of university departments}},
url = {http://dx.doi.org/10.1016/j.joi.2016.01.007},
volume = {10},
year = {2016}
}
@article{Bornmann2014,
abstract = {Today, it is not clear how the impact of research on other areas of society than science should be measured. While peer review and bibliometrics have become standard methods for measuring the impact of research in science, there is not yet an accepted framework within which to measure societal impact. Alternative metrics (called altmetrics to distinguish them from bibliometrics) are considered an interesting option for assessing the societal impact of research, as they offer new ways to measure (public) engagement with research output. Altmetrics is a term to describe web-based metrics for the impact of publications and other scholarly material by using data from social media platforms (e.g. Twitter or Mendeley). This overview of studies explores the potential of altmetrics for measuring societal impact. It deals with the definition and classification of altmetrics. Furthermore, their benefits and disadvantages for measuring impact are discussed.},
archivePrefix = {arXiv},
arxivId = {1406.7091},
author = {Bornmann, Lutz},
doi = {10.1016/j.joi.2014.09.005},
eprint = {1406.7091},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bornmann - 2014 - Do altmetrics point to the broader impact of research An overview of benefits and disadvantages of altmetrics.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Altmetrics,Broader impact,Scientometrics,Societal impact},
number = {4},
pages = {895--903},
pmid = {23133655},
publisher = {Elsevier Ltd},
title = {{Do altmetrics point to the broader impact of research? An overview of benefits and disadvantages of altmetrics}},
url = {http://dx.doi.org/10.1016/j.joi.2014.09.005},
volume = {8},
year = {2014}
}
@article{Bornmann2009,
author = {Bornmann, Lutz and Daniel, Hans-Dieter},
doi = {10.1163/156853010X510807},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Education - 2004 - The State of.pdf:pdf},
isbn = {9789211322910},
issn = {1525-2531},
journal = {EMBO reports},
number = {1},
pages = {5--9},
title = {{The state of h index research}},
volume = {10},
year = {2009}
}
@article{Bornmann2015,
abstract = {The increased interest in an impact measurement of research on other areas of the society than research has led in scientometrics to an investigation of altmetrics. Particular attention is paid here to a targeted broad impact measurement: The aim is to discover the impact which a particular publication set has on specific user groups (outside research) by using altmetrics. This study used the Mendeley application programming interface (API) to download the Mendeley counts (broken down by different user types of publications in Mendeley) for a comprehensive F1000Prime data set. F1000Prime is a post-publication peer review system for papers from the biomedical area. As the F1000 papers are provided with tags from experts in this area (Faculty members) which can characterise a paper more exactly (such as "good for teaching" or "new finding"), the interest of different user groups in specifically tagged papers could be investigated. This study's evaluation of the variously tagged F1000 papers provided interesting insights into the use of research papers by different user groups. The most interesting tag for altmetrics research is "good for teaching". This applies to papers which are well written and provide an overview of a topic. Papers with this tag can be expected to arouse interest among people who are hardly or not at all involved in research. The results of the regression models in this study do in fact show that lecturers, researchers at a non-academic institution, and others (such as librarians) have a special interest in this kind of papers. In the case of a key article in a field, or a particularly well written article that provides a good overview of a topic, then it will tend to be better received by people which are not particularly related to academic research.},
author = {Bornmann, Lutz and Haunschild, Robin},
doi = {10.1016/j.joi.2015.04.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bornmann, Haunschild - 2015 - Which people use which scientific papers An evaluation of data from F1000 and Mendeley.pdf:pdf},
isbn = {1751-1577},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Altmetrics,F1000,Mendeley,Societal impact},
number = {3},
pages = {477--487},
publisher = {Elsevier Ltd},
title = {{Which people use which scientific papers? An evaluation of data from F1000 and Mendeley}},
url = {http://dx.doi.org/10.1016/j.joi.2015.04.001},
volume = {9},
year = {2015}
}
@article{Bornmann2013,
abstract = {For comparisons of citation impacts across fields and over time, bibliometricians normalize the observed citation counts with reference to an expected citation value. Percentile-based approaches have been proposed as a non-parametric alternative to parametric central-tendency statistics. Percentiles are based on an ordered set of citation counts in a reference set, whereby the fraction of papers at or below the citation counts of a focal paper is used as an indicator for its relative citation impact in the set. In this study, we pursue two related objectives: (1) although different percentile-based approaches have been developed, an approach is hitherto missing that satisfies a number of criteria such as scaling of the percentile ranks from zero (all other papers perform better) to 100 (all other papers perform worse), and solving the problem with tied citation ranks unambiguously. We introduce a new citation-rank approach having these properties, namely P100; (2) we compare the reliability of P100 empirically with other percentile-based approaches, such as the approaches developed by the SCImago group, the Centre for Science and Technology Studies (CWTS), and Thomson Reuters (InCites), using all papers published in 1980 in Thomson Reuters Web of Science (WoS). How accurately can the different approaches predict the long-term citation impact in 2010 (in year 31) using citation impact measured in previous time windows (years 1-30)? The comparison of the approaches shows that the method used by InCites overestimates citation impact (because of using the highest percentile rank when papers are assigned to more than a single subject category) whereas the SCImago indicator shows higher power in predicting the long-term citation impact on the basis of citation rates in early years. Since the results show a disadvantage in this predictive ability for P100 against the other approaches, there is still room for further improvements. {\textcopyright} 2013 Elsevier Ltd.},
author = {Bornmann, Lutz and Leydesdorff, Loet and Wang, Jian},
doi = {10.1016/j.joi.2013.09.003},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bornmann, Leydesdorff, Wang - 2013 - Which percentile-based approach should be preferred for calculating normalized citation impact valu.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Citation impact normalization,Citation rank,P100,Percentile,Percentile rank class},
number = {4},
pages = {933--944},
publisher = {Elsevier Ltd},
title = {{Which percentile-based approach should be preferred for calculating normalized citation impact values? An empirical comparison of five approaches including a newly developed citation-rank approach (P100)}},
url = {http://dx.doi.org/10.1016/j.joi.2013.09.003},
volume = {7},
year = {2013}
}
@article{Bornmann2015a,
abstract = {Evaluative bibliometrics compare the citation impact of researchers, research groups and institutions with each other across time scales and disciplines. Both factors, discipline and period - have an influence on the citation count which is independent of the quality of the publication. Normalizing the citation impact of papers for these two factors started in the mid-1980s. Since then, a range of different methods have been presented for producing normalized citation impact scores. The current study uses a data set of over 50,000 records to test which of the methods so far presented correlate better with the assessment of papers by peers. The peer assessments come from F1000Prime - a post-publication peer review system of the biomedical literature. Of the normalized indicators, the current study involves not only cited-side indicators, such as the mean normalized citation score, but also citing-side indicators. As the results show, the correlations of the indicators with the peer assessments all turn out to be very similar. Since F1000 focuses on biomedicine, it is important that the results of this study are validated by other studies based on datasets from other disciplines or (ideally) based on multi-disciplinary datasets.},
author = {Bornmann, Lutz and Marx, Werner},
doi = {10.1016/j.joi.2015.01.006},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bornmann, Marx - 2015 - Methods for the generation of normalized citation impact scores in bibliometrics Which method best reflects the.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliometrics,Cited-side indicator,Citing-side indicator,F1000,Normalized citation impact},
number = {2},
pages = {408--418},
publisher = {Elsevier Ltd},
title = {{Methods for the generation of normalized citation impact scores in bibliometrics: Which method best reflects the judgements of experts?}},
url = {http://dx.doi.org/10.1016/j.joi.2015.01.006},
volume = {9},
year = {2015}
}
@article{Braun1999,
abstract = {The word 'intelligence' has many connotations. It can mean intelligence in the sense of an ability to understand, but it can also mean news or information, especially the more qualified or sophisticated information needed for example by the military or the police. Nowadays, however the term 'intelligence' is quite often used in connection with information systems -particularly for strategic planning and marketing purposes -to describe management's needs in the decision making process. Strongly believable information becomes absolutely indispensable in a rapidly changing and globalizing world. Recent knowledge is nowadays developed e.g., on strategic intelligence systems, competitive business intelligence systems, etc.. Common to these systems is their ability, using a variety of methods, to obtain information from sources that are generally available, to process it by special means and then to select it critically and compile the particular information which is relevant to a specific topic at a given moment, e.g. as the basis for a decision. Thus, in this case 'intelligence' means selection, evaluation, analysis and compilation of pieces of information transformed into knowledge. Scientometric tools are based on a statistical analysis of the occurrence frequency of certain events in the scientific literature, as opposed to an analysis of the literature's content. Counting and statistical processing of these events leads to a whole series of procedures of different degrees of sophistication. The fact that scientometrics is based on databases of the scientific literature, and confines the method to the study of science, has many positive consequences. First, scientometrics relies on the very structured nature of the refereed scientific literature, not on potentially biased expert opinions, to establish sometime unexpected connections between persons, facts, fields and achievements. T. BRAUN: BIBLIOMETRIC INDICATORS FOR THE EVALUATION OF UNIVERSITIES Second, it focuses on basic rather than applied research or technology, so it is best suited for long-term planning and for identifying emerging scientific platforms that will support themselves and point towards future technology developments e.g. in a business environment. Scientometric tools have increased in complexity and sophistication over time. Originally, they provided simplistic means by linear ranking or lists; now they can reveal intricate networks and connections. The tools that support these increasingly elaborate methods are proportionately complex. This range of complexities affects the data and the software that support the various analyses.},
author = {Braun, T},
doi = {10.1007/BF02457602},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Braun - 1999 - Bibliometric Indicators for the Evaluation of Universities -Intelligence From the Quantitation of the Scientific Literatu.pdf:pdf},
isbn = {0138-9130},
issn = {0138-9130},
journal = {Budapest Scientometrics},
number = {3},
pages = {425--432},
title = {{Bibliometric Indicators for the Evaluation of Universities -Intelligence From the Quantitation of the Scientific Literature}},
volume = {45},
year = {1999}
}
@article{Breuer2009,
author = {Breuer, Wolfgang},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Breuer - 2009 - Google Scholar as a Means for Quantitative Evaluation of German Research Output in Business Administration-Some Prelimin.pdf:pdf},
issn = {1556-5068},
journal = {Social Science Research Network},
keywords = {German business administration,Google Scholar,ISI web of science,research output},
title = {{Google Scholar as a Means for Quantitative Evaluation of German Research Output in Business Administration-Some Preliminary Results}},
url = {http://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=1280033},
year = {2009}
}
@article{Burnham2006,
abstract = {The Scopus database provides access to STM journal articles and the references included in those articles, allowing the searcher to search both forward and backward in time. The database can be used for collection development as well as for research. This review provides information on the key points of the database and compares it to Web of Science. Neither database is inclusive, but complements each other. If a library can only afford one, choice must be based in institutional needs.},
author = {Burnham, Judy F},
doi = {10.1186/1742-5581-3-1},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burnham - 2006 - Scopus database a review.pdf:pdf},
isbn = {1742-5581},
issn = {1742-5581},
journal = {Biomedical digital libraries},
pages = {1},
pmid = {16522216},
title = {{Scopus database: a review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16522216},
volume = {3},
year = {2006}
}
@article{Buter2011,
abstract = {We define converging research as the emergence of an interdisciplinary research area from fields that did not show interdisciplinary connections before. This paper presents a process to search for converging research using journal subject categories as a proxy for fields and citations to measure interdisciplinary connections, as well as an application of this search. The search consists of two phases: a quantitative phase in which pairs of citing and cited fields are located that show a significant change in number of citations, followed by a qualitative phase in which thematic focus is sought in publications associated with located pairs. Applying this search on publications from the Web of Science published between 1995 and 2005, 38 candidate converging pairs were located, 27 of which showed thematic focus, and 20 also showed a similar focus in the other, reci- procal pair},
author = {Buter, Reindert K. and Noyons, Ed C M and van Raan, Anthony F J},
doi = {10.1007/s11192-010-0246-0},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buter, Noyons, van Raan - 2011 - Searching for converging research using field to field citations.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Citations,Convergence,Emergence,Interdisciplinarity,Journal subject categories,Non-linear growth,Research focus},
number = {2},
pages = {325--338},
pmid = {21297857},
title = {{Searching for converging research using field to field citations}},
volume = {86},
year = {2011}
}
@article{Charlton2007,
abstract = {人文は研究評価する必要などなく、自然科学系は指標でやるほうが、透明で長期的比較・国際比較ができるという主張。 特に引用数を主張するのだが、その根拠分析になると、規模が影響していそうな、引用数・論文数・上海ランキングの相関の高さにとどまる。ただし、ある種、確信犯であり、引用数が平均的に高い分野を中心とする競争のフレームワークの中で大学が駆動するように（要は人文軽視）持って行こうとしている面もある。だが、後半は支離滅裂な主張ばかり。},
author = {Charlton, Bruce G and Andras, Peter},
doi = {10.3152/030234207X254413},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Charlton, Andras - 2007 - Evaluating universities using simple scientometric research-output metrics total citation counts per universit.pdf:pdf},
issn = {03023427},
journal = {Science and Public Policy},
number = {October},
pages = {555--563},
title = {{Evaluating universities using simple scientometric research-output metrics: total citation counts per university for a retrospective seven-year rolling sample}},
url = {http://openurl.ingenta.com/content/xref?genre=article{\&}issn=0302-3427{\&}volume=34{\&}issue=8{\&}spage=555},
volume = {34},
year = {2007}
}
@phdthesis{Christelova2011,
abstract = {The thesis focuses on the evaluation of Research and Development in the Czech Republic. The introductory part of thesis highlights the recency of the topic and describes the quantitative and qualitative methods of assessing outlets of science. The second part of the thesis discusses in detail the evaluation of science in the Czech Republic; the legislative framework and the evaluation of Research and Development are mentioned. The third chapter shows the evaluation of institutional Research and Development and uses the 1st Faculty of Medicine of Charles University in Prague as an example. The core of the thesis is the fourth chapter with an analysis of selected primary scientometric data. The final part summarizes the entire topic and highlights some problem areas},
author = {Christelov{\'{a}}, Al{\v{z}}b{\v{e}}ta},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karlova et al. - 2011 - Univerzita Karlova v Praze Diplomov{\'{a}} pr{\'{a}}ce Bc . Al{\v{z}}b{\v{e}}ta Christelov{\'{a}} Hodnocen{\'{i}} v{\v{e}}dy a v{\'{y}}zkumu na {\'{U}}.pdf:pdf},
keywords = {Hirsch index,analysis,citation databases,citation index,evaluation of scientific work,higher education institution,impact factor,results of Research and Development,science,scientometrics},
school = {Univerzita Karlova v Praze, Filozofick{\'{a}} fakulta},
title = {{Hodnocen{\'{i}} v{\v{e}}dy a v{\'{y}}zkumu na {\'{U}}stavu v{\v{e}}deck{\'{y}}ch informac{\'{i}} 1. l{\'{e}}kařsk{\'{e}} fakulty Univerzity Karlovy v Praze = Evaluation of Science and Research at Institute of Scientific Information of 1st Faculty of Medicine of Charles University in Prague}},
year = {2011}
}
@article{Claassen2015,
abstract = {This study provides a methodological critique of major quality assessments in U.S. higher education over the last 70 years, through an examination of their taxonomy, unit of analysis, frame of reference, and definition of quality. Many quantitative indicators currently used in assessments have a weak theoretical link to quality and have serious methodological drawbacks. The study offers recommendations for continued improvements to assessment indicators, so that institutions may better assert their own voices in debates over higher education qualit},
author = {Claassen, Christopher},
doi = {10.1007/s11192-015-1584-8},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Claassen - 2015 - Measuring university quality.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Bayesian models,Latent trait models,University rankings},
number = {April},
pages = {793--807},
title = {{Measuring university quality}},
url = {http://dx.doi.org/10.1007/s11192-015-1584-8},
year = {2015}
}
@article{Colliander2011,
abstract = {In this paper we study the effects of field normalization baseline on relative performance of 20 natural science departments in terms of citation impact. Impact is studied under three baselines: journal, ISI/Thomson Reuters subject category, and Essential Science Indicators field. For the measurement of citation impact, the indicators item-oriented mean normalized citation rate and Top-5{\%} are employed. The results, which we analyze with respect to stability, show that the choice of normalization baseline matters. We observe that normalization against publishing journal is particular. The rankings of the departments obtained when journal is used as baseline, irrespective of indicator, differ considerably from the rankings obtained when ISI/Thomson Reuters subject category or Essential Science Indicators field is used. Since no substantial differences are observed when the baselines Essential Science Indicators field and ISI/Thomson Reuters subject category are contrasted, one might suggest that people without access to subject category data can perform reasonable normalized citation impact studies by combining normalization against journal with normalization against Essential Science Indicators field. ?? 2010 Elsevier Ltd.},
author = {Colliander, Cristian and Ahlgren, Per},
doi = {10.1016/j.joi.2010.09.003},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Colliander, Ahlgren - 2011 - The effects and their stability of field normalization baseline on relative performance with respect to cit.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Citation impact,Essential Science Indicators field,Field normalization baseline,ISI/Thomson Reuters subject category,Journal,Stability analysis},
number = {1},
pages = {101--113},
publisher = {Elsevier Ltd},
title = {{The effects and their stability of field normalization baseline on relative performance with respect to citation impact: A case study of 20 natural science departments}},
url = {http://dx.doi.org/10.1016/j.joi.2010.09.003},
volume = {5},
year = {2011}
}
@article{Costa2013,
abstract = {This article aims to be a reflection upon Bibliometrics, its application and the issues that might be involved. To produce its conclusions Bibliometrics concepts and the concepts of scientific peer validation are briefly explained. The analysis of the publishing industry and its impact on Bibliometric studies.},
author = {da Costa, Maria},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Journal - 2014 - a Study on.pdf:pdf},
journal = {Research Gate},
keywords = {Bibliometrics,Bradford's law,FH analysis,FI analysis,Informetrics,Lotka's law,Obsolescence,Publishing industry,Scientific production,Scientometrics,Webometrics,Zipf's law.},
number = {1},
pages = {0--13},
title = {{A Study on Bibliometrics: From the emergence to modern days Big Science}},
volume = {XVI},
year = {2013}
}
@article{Costas2011,
abstract = {The obsolescence and "durability" of scientific literature have been important elements of debate during many years, especially regarding the proper calculation of bibliometric indicators. The effects of "delayed recognition" on impact indicators have importance and are of interest not only to bibliometricians but also among research managers and scientists themselves. It has been suggested that the "Mendel syndrome" is a potential drawback when assessing individual researchers through impact measures. If publications from particular researchers need more time than "normal" to be properly acknowledged by their colleagues, the impact of these researchers may be underestimated with common citation windows. In this paper, we answer the question whether the bibliometric indicators for scientists can be significantly affected by the Mendel syndrome. Applying a methodology developed previously for the classification of papers according to their durability (Costas et al., J Am Soc Inf Sci Technol 61(8):1564-1581, 2010a; J Am Soc Inf Sci Technol 61(2):329-339, 2010b), the scientific production of 1,064 researchers working at the Spanish Council for Scientific Research (CSIC) in three different research areas has been analyzed. Cases of potential "Mendel syndrome" are rarely found among researchers and these cases do not significantly outperform the impact of researchers with a standard pattern of reception in their citations. The analysis of durability could be included as a parameter for the consideration of the citation windows used in the bibliometric analysis of individuals.},
author = {Costas, Rodrigo and van Leeuwen, Thed N. and van Raan, Anthony F J},
doi = {10.1007/s11192-011-0436-4},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Costas, van Leeuwen, van Raan - 2011 - The Mendel syndrome in science Durability of scientific literature and its effects on bibliometri.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Bibliometric indicators,Durability,Individual level analysis,Mendel syndrome,Micro-level analysis,Obsolescence},
number = {1},
pages = {177--205},
pmid = {21957319},
title = {{The "Mendel syndrome" in science: Durability of scientific literature and its effects on bibliometric analysis of individual scientists}},
volume = {89},
year = {2011}
}
@article{DeBattisti2015,
abstract = {Topic models are a well known clustering approach for textual data,$\backslash$nwhich provides promising applications in the bibliometric context for$\backslash$nthe purpose of discovering scientific topics and trends in a corpus of$\backslash$nscientific publications. However, topic models per se provide poorly$\backslash$ndescriptive metadata featuring the discovered clusters of publications$\backslash$nand they are not related to the other important metadata usually$\backslash$navailable with publications, such as authors affiliation, publication$\backslash$nvenue, and publication year. In this paper, we propose a methodological$\backslash$napproach to topic modeling and post-processing of topic models results$\backslash$nto the end of describing in depth a field of research over time. In$\backslash$nparticular, we work on a selection of publications from the$\backslash$ninternational statistical literature, we propose an approach that allows$\backslash$nus to identify sophisticated topic descriptors, and we analyze the links$\backslash$nbetween topics and their temporal evolution.},
author = {de Battisti, Francesca and Ferrara, Alfio and Salini, Silvia},
doi = {10.1007/s11192-015-1554-1},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Battisti, Ferrara, Salini - 2015 - A decade of research in statistics a topic model approach.pdf:pdf},
issn = {01389130},
journal = {Scientometrics},
keywords = {Clustering,Probabilistic topic models,Scientometrics,Text mining},
number = {May 2014},
pages = {413--433},
title = {{A decade of research in statistics: a topic model approach}},
year = {2015}
}
@article{DeGloucester2013,
abstract = {Misconduct is extensive and damaging. So-called science is prevalent. Articles resulting from so-called science are often cited in other publications. This can have damaging consequences for society and for science. The present work includes a scientometric study of 350 articles (published by the Association for Computing Machinery; Elsevier; The Institute of Electrical and Electronics Engineers, Inc.; John Wiley; Springer; Taylor {\&} Francis; and World Scientific Publishing Co.). A lower bound of 85.4{\%} articles are found to be incongruous. Authors cite inherently self-contradictory articles more than valid articles. Incorrect informational cascades ruin the literature's signal-to-noise ratio even for uncomplicated cases.},
author = {de Gloucester, Paul Colin},
doi = {10.1080/08989621.2013.788379},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Gloucester - 2013 - Referees often miss obvious errors in computer and electronic publications.pdf:pdf},
isbn = {0035123982},
issn = {1545-5815},
journal = {Accountability in Research},
keywords = {citations,computer science,electronic engineering,impact factor,misconduct,refereeing shortcomings},
number = {3},
pages = {143--66},
pmid = {23672521},
title = {{Referees often miss obvious errors in computer and electronic publications.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23672521},
volume = {20},
year = {2013}
}
@article{DeMoya-Aneg??n2007,
abstract = {Nuestro objetivo es comparar la cobertura de la base de datos Scopus con el de Ulrich, para determinar qu{\'{e}} tan homog{\'{e}}nea que est{\'{a}} en el mundo acad{\'{e}}mico. Las variables tenidas en cuenta fueron la distribuci{\'{o}}n por materias, la distribuci{\'{o}}n geogr{\'{a}}fica, la distribuci{\'{o}}n por los editores y el idioma de publicaci{\'{o}}n. El an{\'{a}}lisis de la cobertura de un producto de esta naturaleza debe hacerse en relaci{\'{o}}n con un modelo aceptado, la elecci{\'{o}}n {\'{o}}ptima siendo Directorio de Ulrich, considerado el punto de referencia internacional para la informaci{\'{o}}n m{\'{a}}s completa sobre las revistas publicadas en todo el mundo. Los resultados aqu{\'{i}} descritos nos permiten trazar un perfil de Scopus, en t{\'{e}}rminos de su cobertura por {\'{a}}reas geogr{\'{a}}ficas y tem{\'{a}}ticas - - y la importancia de la revisi{\'{o}}n por pares en sus publicaciones. Estos dos aspectos son consideraciones muy pragm{\'{a}}ticas para la recuperaci{\'{o}}n de informaci{\'{o}}n, la evaluaci{\'{o}}n de la investigaci{\'{o}}n y el dise{\~{n}}o de pol{\'{i}}ticas para el uso de bases de datos cient{\'{i}}ficos en la promoci{\'{o}}n cient{\'{i}}fica.},
author = {{De Moya-Aneg??n}, F??lix and Chinchilla-Rodr??guez, Zaida and Vargas-Quesada, Benjam??n and Corera-??lvarez, Elena and Mu??oz-Fern??ndez, Francisco Jos?? and Gonz??lez-Molina, Antonio and Herrero-Solana, Victor},
doi = {10.1007/s11192-007-1681-4},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Moya-Anegn et al. - 2007 - Coverage analysis of Scopus A journal metric approach.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {1},
pages = {53--78},
title = {{Coverage analysis of Scopus: A journal metric approach}},
volume = {73},
year = {2007}
}
@article{Diaz-Faes2015,
abstract = {Individual research performance needs to be addressed by means of a diverse set of indicators capturing the multidimensional framework of science. In this context, Biplot methods emerge as powerful and reliable visualisation tools similar to a scatterplot but capturing the multivariate covariance structures among bibliometric indicators. In this paper, we introduce the Canonical Biplot technique to explore differences in the scientific performance of Spanish CSIC researchers, organised by field (Chemistry and Materials Science) and grouped by academic rank (research fellows and three types of full-time permanent scientists). This method enables us to build a Biplot where the groups of individuals are sorted out by the maximum discriminating power between the different indicators considered. Besides, as confidence intervals are displayed in the plot, statistical differences between groups are liable to be studied simultaneously. Since test hypotheses are sensitive to different sample size effects, sizes for some pairwise comparisons are computed. We have found two gradients: a primary gradient where scientists mainly differ in terms of age, production, number of collaborators, number of highly-cited papers and their position in the byline of the publications; and a second gradient, in which scientists with the same academic rank differ by sort of field.},
author = {D{\'{i}}az-Faes, Adri{\'{a}}n A. and Costas, Rodrigo and {Purificaci{\'{o}}n Galindo}, M. and Bordons, Mar{\'{i}}a},
doi = {10.1016/j.joi.2015.04.006},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daz-Faes et al. - 2015 - Unravelling the performance of individual scholars Use of Canonical Biplot analysis to explore the performance.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Academic rank,Bibliometrics,Canonical Biplot,Individual-level,Multivariate analysis},
number = {4},
pages = {722--733},
publisher = {Elsevier Ltd},
title = {{Unravelling the performance of individual scholars: Use of Canonical Biplot analysis to explore the performance of scientists by academic rank and scientific field}},
url = {http://dx.doi.org/10.1016/j.joi.2015.04.006},
volume = {9},
year = {2015}
}
@article{Dorta-Gonz??lez2014,
abstract = {The journal impact factor is not comparable among fields of science and social science because of systematic differences in publication and citation behavior across disciplines. In this work, a source normalization of the journal impact factor is proposed. We use the aggregate impact factor of the citing journals as a measure of the citation potential in the journal topic, and we employ this citation potential in the normalization of the journal impact factor to make it comparable between scientific fields. An empirical application comparing some impact indicators with our topic normalized impact factor in a set of 224 journals from four different fields shows that our normalization, using the citation potential in the journal topic, reduces the between-group variance with respect to the within-group variance in a higher proportion than the rest of indicators analyzed. The effect of journal self-citations over the normalization process is also studied. ?? 2014 Elsevier Ltd.},
author = {Dorta-Gonz??lez, Pablo and Dorta-Gonz??lez, Mar??a Isabel and Santos-Pe??ate, Dolores Rosa and Su??rez-Vega, Rafael},
doi = {10.1016/j.joi.2014.01.013},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dorta-Gonzlez et al. - 2014 - Journal topic citation potential and between-field comparisons The topic normalized impact factor.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliometric indicator,Citation analysis,Citation potential,Journal assessment,Journal impact factor,Journal metric,Source normalization},
number = {2},
pages = {406--418},
title = {{Journal topic citation potential and between-field comparisons: The topic normalized impact factor}},
volume = {8},
year = {2014}
}
@book{Drake2005,
address = {Boca Raton},
author = {Drake, Miriam A.},
edition = {Second Edi},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Drake - 2005 - Encyclopedia of Library and Information Science.pdf:pdf},
isbn = {0-8493-3894-8},
pages = {429},
publisher = {Taylor {\&} Francis Group},
title = {{Encyclopedia of Library and Information Science}},
year = {2005}
}
@article{Dunaiski2016,
abstract = {In the work presented in this paper, we analyse ranking algorithms that can be applied to bibliographic citation networks and rank academic entities such as papers and authors. We evaluate how well these algorithms identify important and high-impact entities.The ranking algorithms are computed on the Microsoft Academic Search (MAS) and the ACM digital library citation databases. The MAS database contains 40 million papers and over 260 million citations that span across multiple academic disciplines, while the ACM database contains 1.8 million papers from the computing literature and over 7 million citations.We evaluate the ranking algorithms by using a test data set of papers and authors that won renowned prizes at numerous computer science conferences. The results show that using citation counts is, in general, the best ranking metric to measure high-impact. However, for certain tasks, such as ranking important papers or identifying high-impact authors, algorithms based on PageRank perform better.},
author = {Dunaiski, Marcel and Visser, Willem and Geldenhuys, Jaco},
doi = {10.1016/j.joi.2016.01.010},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dunaiski, Visser, Geldenhuys - 2016 - Evaluating paper and author ranking algorithms using impact and contribution awards.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Bibliometrics,Citation analysis,Ranking},
number = {2},
pages = {392--407},
publisher = {Elsevier Ltd},
title = {{Evaluating paper and author ranking algorithms using impact and contribution awards}},
url = {http://dx.doi.org/10.1016/j.joi.2016.01.010},
volume = {10},
year = {2016}
}
@phdthesis{Dvorakova2013,
abstract = {Bachelor thesis is focused on the development of bibliometrics in the Czech Republic which includes significant events, personalities and institutions which substantially related to the Czech bibliometrics. In the thesis bibliometrics is firstly defined as the science with its methods, laws and use. The general history of bibliometrics is also outlined for comparison with the Czech development. It describes the world development from the beginning to the present. History of the Czech bibliometrics presents similar description of history but in this case applied to the Czech scene. In detail the thesis focuses on probably the most famous Czech achievement from the field of bibliometrics. This is the scientometric working group founded by Jan Vlach{\'{y}}, world renowned Czech bibliometrician and scientometrician. In particular, we address to the group's activity and two preserved proceedings from organized seminars. Below the thesis emphasises the facts which still illustrate the situation in the field of the Czech bibliometrics. Specifically, it relates to the personalities of the Czech bibliometrics who in some way contributed to the development in this area and in this place the analyses of bibliometric literature of the Czech authors are also evaluated.},
author = {Dvoř{\'{a}}kov{\'{a}}, Michaela},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Temperature, Cells - 2009 - Bakal{\'{a}} ř sk{\'{a}} pr{\'{a}}ce.pdf:pdf},
keywords = {Czech Republic,Jan Vlach{\'{y}},bibliometrics,research evaluation,scientometric working group,scientometrics},
school = {Univerzita Karlova v Praze, Filozofick{\'{a}} fakulta},
title = {{Bakal{\'{a}}řsk{\'{a}} pr{\'{a}}ce V{\'{y}}voj bibliometrie v {\v{C}}R Development}},
year = {2013}
}
@article{Egghe2005,
author = {Egghe, Leo},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Egghe - 2005 - Relations between the continous and the discrete Lotka power function.pdf:pdf},
issn = {2330-1643},
journal = {Journal of the American Society for Information Science and Technology},
number = {7},
pages = {664--668},
title = {{Relations between the continous and the discrete Lotka power function}},
volume = {56},
year = {2005}
}
@article{Egghe2006,
abstract = {The g-index is introduced as an improvement of the h-index of Hirsch to measure the global citation performance of a set of articles. If this set is ranked in decreasing order of the number of citations that they received, the g-index is the (unique) largest number such that the top g articles received (together) at least g2 citations. We prove the unique existence of g for any set of articles and we have that g ≥ h. The general Lotkaian theory of the g-index is presented and we show that −1 1 ? − 1 ? g = $\alpha$$\alpha$ $\alpha$ $\alpha$ ? ? T $\alpha$ ? − 2 ? where $\alpha$ {\textgreater} 2 is the Lotkaian exponent and where T denotes the total number of sources. We then present the g-index of the (still active) Price medallists for their complete careers up to 1972 and compare it with the h-index. It is shown that the g-index inherits all the good properties of the h-index and, in addition, better takes into account the citation scores of the top articles. This yields a better distinction between and order of the scientists from the point of view of visibility.},
author = {Egghe, Leo},
doi = {10.1007/s11192-006-0144-7},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Egghe - 2006 - Theory and practise of the g -index.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {1},
pages = {131--152},
title = {{Theory and practise of the g -index}},
volume = {69},
year = {2006}
}
@article{Ellegaard2015,
abstract = {Bibliometric methods or "analysis" are now firmly established as scientific specialties and are an integral part of research evaluation methodology especially within the scientific and applied fields. The methods are used increasingly when studying various aspects of science and also in the way institutions and universities are ranked worldwide. A sufficient number of studies have been completed, and with the resulting literature, it is now possible to analyse the bibliometric method by using its own methodology. The bibliometric literature in this study, which was extracted from Web of Science, is divided into two parts using a method comparable to the method of Jonkers et al. (Characteristics of bibliometrics articles in library and information sciences (LIS) and other journals, pp. 449-551, 2012: The publications either lie within the Information and Library Science (ILS) category or within the non-ILS category which includes more applied, "subject" based studies. The impact in the different groupings is judged by means of citation analysis using normalized data and an almost linear increase can be observed from 1994 onwards in the non-ILS category. The implication for the dissemination and use of the bibliometric methods in the different contexts is discussed. A keyword analysis identifies the most popular subjects covered by bibliometric analysis, and multidisciplinary articles are shown to have the highest impact. A noticeable shift is observed in those countries which contribute to the pool of bibliometric analysis, as well as a self-perpetuating effect in giving and taking references.},
author = {Ellegaard, Ole and Wallin, Johan A.},
doi = {10.1007/s11192-015-1645-z},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ellegaard, Wallin - 2015 - The bibliometric analysis of scholarly production How great is the impact.pdf:pdf},
issn = {15882861},
journal = {Scientometrics},
keywords = {Bibliometric analysis,Citation analysis,Impact of publications,Publication analysis},
number = {3},
pages = {1809--1831},
pmid = {26594073},
publisher = {Springer Netherlands},
title = {{The bibliometric analysis of scholarly production: How great is the impact?}},
url = {"http://dx.doi.org/10.1007/s11192-015-1645-z},
volume = {105},
year = {2015}
}
@article{Etxebarria2010,
abstract = {Abstract  A large part of Social Sciences and the Humanities do not adapt to international proceedings used in English for scientific$\backslash$n  output on databases such as the Web of Science and Scopus. The aim of this paper is to show the different results obtained$\backslash$n  in scientific work by comparing Social Sciences researchers with those of other sciences in four Spanish universities. The$\backslash$n  first finding is that some Social Sciences researchers are somewhat internationalised. However, the majority of individuals$\backslash$n  who are prestigious in their local academic-scientific community do not even appear on the information sources mentioned above.},
author = {Etxebarria, Goio and Gomez-Uranga, Mikel},
doi = {10.1007/s11192-009-0043-9},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Etxebarria, Gomez-Uranga - 2010 - Use of Scopus and Google Scholar to measure social sciences production in four major Spanish universit.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Social Sciences production,Spanish universities,Visibility on international databases},
number = {2},
pages = {333--349},
title = {{Use of Scopus and Google Scholar to measure social sciences production in four major Spanish universities}},
volume = {82},
year = {2010}
}
@article{Franceschini2011,
abstract = {Evaluating the scientific output of researchers, research institutions, academic departments and even universities is a challenging issue. To do this, bibliometric indicators are helpful tools, more and more familiar to research and governmental institutions.This paper proposes a structured method to compare academic research groups within the same discipline, by means of some Hirsch (h) based bibliometric indicators. Precisely, five different typologies of indicators are used so as to depict groups' bibliometric positioning within the scientific community. A specific analysis concerning the Italian researchers in the scientific sector of Production Technology and Manufacturing Systems is developed. The analysis is supported by empirical data and can be extended to research groups associated to other scientific sectors. ?? 2010 Elsevier Ltd.},
author = {Franceschini, Fiorenzo and Maisano, Domenico},
doi = {10.1016/j.joi.2010.08.003},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Franceschini, Maisano - 2011 - Structured evaluation of the scientific output of academic research groups by recent h-based indicators.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Academic research group,Bibliometric positioning,Ch-index,H-Index,H-Spectrum,Research evaluation,Scientific production,Successive h-indices},
number = {1},
pages = {64--74},
pmid = {51803309},
publisher = {Elsevier Ltd},
title = {{Structured evaluation of the scientific output of academic research groups by recent h-based indicators}},
url = {http://dx.doi.org/10.1016/j.joi.2010.08.003},
volume = {5},
year = {2011}
}
@article{Franceschini2016a,
abstract = {Recent studies have shown that the Scopus bibliometric database is probably less accuratethan one thinks. As a further evidence of this fact, this paper presents a structured collectionof several weird typologies of database errors, which can therefore be classified as horrors.Some of them concern the incorrect indexing of so-called Online-First paper, duplicate pub-lications, and the missing/incorrect indexing of references. A crucial point is that most ofthese errors could probably be avoided by adopting some basic data checking systems.Although this paper does not provide a quantitative and systematic analysis (which willbe provided in a future publication), it can be easily understood that these errors can haveserious consequences such as: (i) making it difficult or even impossible to retrieve some doc-uments, and (ii) distorting bibliometric indicators/metrics relating to journals, individualscientists or research institutions.Our attention is focused on the Scopus database, although preliminary data show thatthe Web of Science database is far from being free from these errors. The tone of the paperis deliberately provocative, in order to emphasize the seriousness of these errors.},
author = {Franceschini, Fiorenzo and Maisano, Domenico and Mastrogiacomo, Luca},
doi = {10.1016/j.joi.2015.11.006},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Franceschini, Maisano, Mastrogiacomo - 2016 - The museum of errorshorrors in Scopus.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
number = {1},
pages = {174--182},
publisher = {Elsevier Ltd},
title = {{The museum of errors/horrors in Scopus}},
url = {http://dx.doi.org/10.1016/j.joi.2015.11.006},
volume = {10},
year = {2016}
}
@article{Franceschini2016,
abstract = {Omitted citations—i.e., missing links between a cited paper and the corre-sponding citing papers—are a consequence of several bibliometric-database errors. To reduce these errors, databases may undertake two actions: (1) improving the control of the (new) papers to be indexed, i.e., limiting the introduction of ''new'' dirty data, and (2) detecting and correcting errors in the papers already indexed by the database, i.e., cleaning ''old'' dirty data. The latter action is probably more complicated, as it requires the application of suitable error-detection procedures to a huge amount of data. Based on an extensive sample of scientific papers in the Engineering-Manufacturing field, this study focuses on old dirty data in the Scopus and WoS databases. To this purpose, a recent automated algorithm for estimating the omitted-citation rate of databases is applied to the same sample of papers, but in three different-time sessions. A database's ability to clean the old dirty data is evaluated considering the variations in the omitted-citation rate from session to session. The major outcomes of this study are that: (1) both databases slowly correct old omitted citations, and (2) a small portion of initially corrected citations can surprisingly come off from databases over time.},
author = {Franceschini, Fiorenzo and Maisano, Domenico and Mastrogiacomo, Luca},
doi = {10.1007/s11192-016-1867-8},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Franceschini, Maisano, Mastrogiacomo - 2016 - Do Scopus and WoS correct old omitted citations.pdf:pdf},
issn = {15882861},
journal = {Scientometrics},
keywords = {Bibliometric database,Database errors,Engineering-Manufacturing journals,Error correction,Old dirty data,Omitted citations},
number = {2},
pages = {321--335},
publisher = {Springer Netherlands},
title = {{Do Scopus and WoS correct "old" omitted citations?}},
url = {"http://dx.doi.org/10.1007/s11192-016-1867-8},
volume = {107},
year = {2016}
}
@article{Frandsen2008,
abstract = {This paper presents a study of possible changes in patterns of document$\backslash$ntypes in economics journals since the mid-1980s. Furthermore, the study$\backslash$nincludes an analysis of a possible relation between the profile of a$\backslash$njournal concerning composition of document types and factors such as$\backslash$nplace of publication and JIF. The results provide little evidence that$\backslash$nthe journal editors have succeeded in manipulating the distribution of$\backslash$ndocument types. Furthermore, there is little support for the hypothesis$\backslash$nthat journal editors decrease the number of publications included in the$\backslash$ncalculation of JIF or for that matter for the hypothesis that journal$\backslash$neditors increase the number of publications not included in the$\backslash$ncalculation of JIF. The results of the analyses show that there is a$\backslash$nclear distinction of journals based on place of publication and JLF.},
author = {Frandsen, Tove Faber},
doi = {10.1007/s11192-007-1697-9},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frandsen - 2008 - On the ratio of citable versus non-citable items in economics journals.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {3},
pages = {439--451},
title = {{On the ratio of citable versus non-citable items in economics journals}},
volume = {74},
year = {2008}
}
@article{Freyer2014,
abstract = {Defined errors are entered into data collections in order to test their influence on the reliability of multivariate rankings. Random numbers and real ranking data serve as data origins. In the course of data collection small random errors often lead to a switch in ranking, which can influence the general ranking picture considerably. For stabilisation an objective weighting method is evaluated. The robustness of these rankings is then compared to the original forms. Robust forms of the published Shanghai top 100 rankings are calculated and compared to each other. As a result, the possibilities and restrictions of this type of weighting become recognisable.},
author = {Freyer, Leo},
doi = {10.1007/s11192-014-1313-8},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Freyer - 2014 - Robust rankings Review of multivariate assessments illustrated by the Shanghai rankings.pdf:pdf},
issn = {01389130},
journal = {Scientometrics},
keywords = {Fault tolerance,Objective weighting,Robustness,Shanghai ranking},
number = {2},
pages = {391--406},
pmid = {25018571},
title = {{Robust rankings: Review of multivariate assessments illustrated by the Shanghai rankings}},
volume = {100},
year = {2014}
}
@article{Fu2013,
abstract = {The institutionally independent publications of Tsinghua University and Peking University were compared by two main indicators namely peak-year citations per publication and h-index, based on the data extracted from the Science Citation Index Expanded, Web of Science from 1974 to 2011. Analyzed aspects covered total publication outputs, annual production, impact, authorships, Web of Science categories, journals, and most cited articles. Results shows that the two universities were in the same scale based on the peak-year citations per publication, the h-index, and top cited articles with no less than 100 citations. Publication of the top three most productive Web of Science categories differed between these two universities. Tsinghua University published more articles in applied science and engineering fields, while Peking University had more basic science articles. In addition, article life was applied to compare the impact of the most cited articles and single author articles of the two universities.},
author = {Fu, Hui Zhen and Ho, Yuh Shan},
doi = {10.1007/s11192-012-0912-5},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fu, Ho - 2013 - Comparison of independent research of China's top universities using bibliometric indicators.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Peak-year citations per publication,Science indicators,Scientometrics,Web of science,h-Index},
number = {1},
pages = {259--276},
pmid = {88228928},
title = {{Comparison of independent research of China's top universities using bibliometric indicators}},
volume = {96},
year = {2013}
}
@article{Gagolewski2012,
abstract = {The process of assessing individual authors should rely upon a proper aggregation of reliable and valid papers' quality metrics. Citations are merely one possible way to measure appreciation of publications. In this study we propose some new, SJR- and SNIP-based indicators, which not only take into account the broadly conceived popularity of a paper (manifested by the number of citations), but also other factors like its potential, or the quality of papers that cite a given publication. We explore the relation and correlation between different metrics and study how they affect the values of a real-valued generalized h-index calculated for 11 prominent scientometricians. We note that the h-index is a very unstable impact function, highly sensitive for applying input elements' scaling. Our analysis is not only of theoretical significance: data scaling is often performed to normalize citations across disciplines. Uncontrolled application of this operation may lead to unfair and biased (toward some groups) decisions. This puts the validity of authors assessment and ranking using the h-index into question. Obviously, a good impact function to be used in practice should not be as much sensitive to changing input data as the analyzed one. ?? 2012 Elsevier Ltd.},
author = {Gagolewski, Marek and Mesiar, Radko},
doi = {10.1016/j.joi.2012.05.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagolewski, Mesiar - 2012 - Aggregating different paper quality measures with a generalized h-index.pdf:pdf},
isbn = {17511577 (ISSN)},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Aggregation operators,Bibliometrics,CITAN,Hirsch's h-index,Impact functions,Quality control,R,SJR,SNIP,Scientometrics,Scopus},
number = {4},
pages = {566--579},
publisher = {Elsevier Ltd},
title = {{Aggregating different paper quality measures with a generalized h-index}},
url = {http://dx.doi.org/10.1016/j.joi.2012.05.001},
volume = {6},
year = {2012}
}
@article{Garcia-Perez2009,
abstract = {The h-index is becoming a reference tool for career assessment and$\backslash$nit is starting to be considered by some agencies and institutions$\backslash$nin promotion, allocation, and funding decisions. In areas where h$\backslash$nindices tend to be low, individuals with different research accomplishments$\backslash$nmay end up with the same h. This paper proposes a multidimensional$\backslash$nextension of the h index in which the conventional h is only the$\backslash$nfirst component. Additional components of the multidimensional index$\backslash$nare obtained by computing the h-index for the subset of papers not$\backslash$nconsidered in the immediately preceding component. Computation of$\backslash$nthe multidimensional index for 204 faculty members in Departments$\backslash$nof Methodology of the Behavioral Sciences in Spain shows that individuals$\backslash$nwith the same h can indeed be distinguished by their values in the$\backslash$nremaining components, and that the strength of the correlation of$\backslash$nthe second and third components of the multidimensional index with$\backslash$nalternative bibliometric indicators is similar to that of the first$\backslash$ncomponent (i.e., the original h). {\textcopyright} 2009 Akad{\'{e}}miai Kiad{\'{o}}, Budapest.},
author = {Garc{\'{i}}a-P{\'{e}}rez, Miguel A.},
doi = {10.1007/s11192-009-2290-1},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garca-Prez - 2009 - A multidimensional extension to Hirsch's h-index.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {3},
pages = {779--785},
title = {{A multidimensional extension to Hirsch's h-index}},
volume = {81},
year = {2009}
}
@article{Garfield1955,
author = {Garfield, Eugene},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garfield - 1955 - Citation Indexes for Science.pdf:pdf},
journal = {Science},
number = {3159},
pages = {108--111},
title = {{Citation Indexes for Science}},
volume = {122},
year = {1955}
}
@article{Garfield2009,
abstract = {While ISSI was founded in 1993, Scientometrics and Bibliometrics are now at least half a century old. Indeed, the field can be traced to early quantitative studies in the early 20th century. In the 1930s, it evolved to the "science of science." The publication of J.D. Bernal's Social Function of Science in 1939 was a key transition point but the field lay dormant until after World War II, when D.J.D. Price's books Science Since Babylon and Little Science, Big Science were published in 1961 and 1963. His role as the "Father of Scientometrics" is clearly evident by using the HistCite software to visualize his impact as well as the subsequent impact of the journal Scientometrics on the growth of the field. Scientometrics owes its name to V.V. Nalimov, the author of Naukometriya, and to Tibor Braun who adapted the neologism for the journal. The primordial paper on citation indexing by Garfield which appeared in Science 1955 became a bridge between Bernal and Price. The timeline for the evolution of Scientometrics is demonstrated by a HistCite tabulation of the ranked citation index of the 100,000 references cited in the 3000 papers citing Price. ?? 2009 Elsevier Ltd.},
author = {Garfield, Eugene},
doi = {10.1016/j.joi.2009.03.009},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garfield - 2009 - From the science of science to Scientometrics visualizing the history of science with HistCite software.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Algorithmic,Bibliometrics,Derek J.D. Price,Etymology of Scientometrics,HistCite,Historiography,History of Scientometrics,J.D. Bernal,Science of science,V.V. Nalimov},
number = {3},
pages = {173--179},
title = {{From the science of science to Scientometrics visualizing the history of science with HistCite software}},
volume = {3},
year = {2009}
}
@article{Garfield1955a,
author = {Garfield, Eugene},
issn = {1095-9203},
journal = {Science},
number = {3159},
pages = {108--111},
title = {{Citation indexes for science: A new dimension in documentation through association of ideas}},
volume = {122},
year = {1955}
}
@article{Genova2016,
abstract = {This article deals with a modern disease of academic science that consists of an enormous increase in the number of scientific publications without a corresponding advance of knowledge. Findings are sliced as thin as salami and submitted to different journals to produce more papers. If we consider academic papers as a kind of scientific 'currency' that is backed by gold bullion in the central bank of 'true' science, then we are witnessing an article-inflation phenomenon, a scientometric bubble that is most harmful for science and promotes an unethical and antiscientific culture among researchers. The main problem behind the scenes is that the impact factor is used as a proxy for quality. Therefore, not only for convenience, but also based on ethical principles of scientific research, we adhere to the San Francisco Declaration on Research Assessment when it emphasizes "the need to eliminate the use of journal-based metrics in funding, appointment and promotion considerations; and the need to assess research on its own merits rather on the journal in which the research is published". Our message is mainly addressed to the funding agencies and universities that award tenures or grants and manage research programmes, especially in developing countries. The message is also addressed to well-established scientists who have the power to change things when they participate in committees for grants and jobs.},
author = {G{\'{e}}nova, Gonzalo and Astudillo, Hern{\'{a}}n and Fraga, Anabel},
doi = {10.1007/s11948-015-9632-6},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{e}}nova, Astudillo, Fraga - 2016 - The Scientometric Bubble Considered Harmful.pdf:pdf},
issn = {14715546},
journal = {Science and Engineering Ethics},
keywords = {Careers in Academia,Ethics in scientific publications,Impact factor,Research Assessment,Scientometrics},
number = {1},
pages = {227--235},
pmid = {25689931},
title = {{The Scientometric Bubble Considered Harmful}},
volume = {22},
year = {2016}
}
@article{Godin2007,
abstract = {In 1906, James McKeen Cattell, editor of Science, published a directory on men of science. American Men of Science was a collection of biographical sketches of thousands of men of science in the United States and was published periodically. It launched and was used in the very first systematic quantitative studies on science. Cattell used two concepts for his statistics: productivity, defined as the number of men of science a nation produces, and performance or merit, defined as scientific contributions to research as judged by peers. These are the two dimensions that still define the measurement of science today: quantity and quality. This paper analyzes the emergence of statistics on science and the very first uses to which they were put. It argues that the measurement of science emerged out of interest in great men, heredity and eugenics, and the contribution of eminent men to civilization. Among these eminent men were men of science, the population of whom was thought to be in decline and insufficiently appreciated and supported. Statistics on men of science thus came to be collected to document the case, and to contribute to the advancement of science and of the scientific profession},
author = {Godin, Beno{\^{i}}t},
doi = {10.1177/0306312706075338},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Godin - 2006 - From Eugenics to Scientometrics Galton , Cattell and Men of Science Beno{\^{i}}t Godin 3465 Durocher Street Montreal , Quebec.pdf:pdf},
issn = {0306-3127},
journal = {Social Studies of Science},
number = {5},
pages = {691--728},
title = {{From Eugenics to Scientometrics : Galton , Cattell and Men of Science}},
volume = {37},
year = {2007}
}
@article{Godin2006,
author = {Godin, Beno{\^{i}}t},
doi = {10.1007/s11192-006-0086-0},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Godin - 2006 - On the origins of bibliometrics.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {1},
pages = {109--133},
title = {{On the origins of bibliometrics}},
volume = {68},
year = {2006}
}
@article{Gurney2012,
abstract = {La clave para los an{\'{a}}lisis bibliom{\'{e}}tricos precisos es la posibilidad de enlazar correctamente los individuos a su corpus de trabajo, con un equilibrio {\'{o}}ptimo entre la precisi{\'{o}}n y recordar. Hemos desarrollado un algoritmo que hace esta tarea de desambiguaci{\'{o}}n con una muy alta recuperaci{\'{o}}n y precisi{\'{o}}n. El m{\'{e}}todo se ocupa de las cuestiones de los registros descartados debido a los campos de datos nulos y su efecto resultante en el recuerdo, precisi{\'{o}}n y resultados F-medida. Hemos puesto en marcha un enfoque din{\'{a}}mico a la similitud c{\'{a}}lculos basados ​​en todos los campos de datos disponibles. Tambi{\'{e}}n hemos incluido las diferencias en la contribuci{\'{o}}n autor y la diferencia de edad entre las publicaciones, las cuales tienen efectos significativos sobre las medidas generales de similitud, lo que significativamente mayor recuerdo y la precisi{\'{o}}n de los registros devueltos. Los resultados se presentan a partir de un conjunto de datos de prueba de las publicaciones de la cat{\'{a}}lisis heterog{\'{e}}nea. Los resultados demuestran significativamente alto promedio de calificaciones de F-medida y mejoras sustanciales en las t{\'{e}}cnicas anteriores y aut{\'{o}}nomos.},
author = {Gurney, Thomas and Horlings, Edwin and van den Besselaar, Peter},
doi = {10.1007/s11192-011-0589-1},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gurney, Horlings, van den Besselaar - 2012 - Author disambiguation using multi-aspect similarity indicators.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Author disambiguation,Community detection,Data discarding,Homonyms,Precision and recall},
number = {2},
pages = {435--449},
pmid = {22485059},
title = {{Author disambiguation using multi-aspect similarity indicators}},
volume = {91},
year = {2012}
}
@article{Hagen2010,
abstract = {A collection of coauthored papers is the new norm for doctoral dissertations in the natural and biomedical sciences, yet there is no consensus on how to partition authorship credit between PhD candidates and their coauthors. Guidelines for PhD programs vary but tend to specify only a suggested range for the number of papers to be submitted for evaluation, sometimes supplemented with a requirement for the PhD candidate to be the principal author on the majority of submitted papers. Here I use harmonic counting to quantify the actual amount of authorship credit attributable to individual PhD graduates from two Scandinavian universities in 2008. Harmonic counting corrects for the inherent inflationary and equalizing biases of routine counting methods, thereby allowing the bibliometrically identifiable amount of authorship credit in approved dissertations to be analyzed with unprecedented accuracy. Unbiased partitioning of authorship credit between graduates and their coauthors provides a post hoc bibliometric measure of current PhD requirements, and sets a de facto baseline for the requisite scientific productivity of these contemporary PhD's at a median value of approximately 1.6 undivided papers per dissertation. Comparison with previous census data suggests that the baseline has shifted over the past two decades as a result of a decrease in the number of submitted papers per candidate and an increase in the number of coauthors per paper. A simple solution to this shifting baseline syndrome would be to benchmark the amount of unbiased authorship credit deemed necessary for successful completion of a specific PhD program, and then monitor for departures from this level over time. Harmonic partitioning of authorship credit also facilitates cross-disciplinary and inter-institutional analysis of the scientific output from different PhD programs. Juxtaposing bibliometric benchmarks with current baselines may thus assist the development of harmonized guidelines and transparent transnational quality assurance procedures for doctoral programs by providing a robust and meaningful standard for further exploration of the causes of intra- and inter-institutional variation in the amount of unbiased authorship credit per dissertation.},
author = {Hagen, Nils T.},
doi = {10.1007/s11192-010-0214-8},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hagen - 2010 - Deconstructing doctoral dissertations How many papers does it take to make a PhD.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Baseline,Benchmark,Bias,Bibliometric counting,Bibliometry},
number = {2},
pages = {567--579},
pmid = {20949112},
title = {{Deconstructing doctoral dissertations: How many papers does it take to make a PhD?}},
volume = {85},
year = {2010}
}
@article{Hardeman2013,
abstract = {The general aim of this paper is to come to terms with the organization and organization level research in scientometrics. Most of the debate on the issues that revolve organization level research in scientometrics is technical. As such, most contributions presume a clear understanding of what constitutes the organization in the first place. To our opinion however, such "a-priorism" is at least awkward, given that even in specialist fields there is no clear understanding of what constitutes the organization. The main argument of this paper holds that performing organization level research in scientometrics can only proceed by taking a pragmatic stance on the constitution of the organization. As such, we argue that performing organization level research in scientometrics (i) requires both authoritative "objective" and non-authoritative "subjective" background knowledge, (ii) involves non-logic practices that can be more or less theoretically informed, and (iii) depends crucially upon the general aim of the research endeavor in which the organization is taken as a basic unit of analysis. To our opinion a pragmatic stance on organization level research in scientometrics is a viable alternative to both overly positivist and overly relativist approaches as well as that it might render the relation between scientometrics and science policy more productive.},
author = {Hardeman, Sjoerd},
doi = {10.1007/s11192-012-0806-6},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hardeman - 2013 - Organization level research in scientometrics A plea for an explicit pragmatic approach.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Classification,Epistemology,Pragmatism,Proximity,Theory of the firm,Unit of analysis},
number = {3},
pages = {1175--1194},
pmid = {23419790},
title = {{Organization level research in scientometrics: A plea for an explicit pragmatic approach}},
volume = {94},
year = {2013}
}
@book{Harzing2011,
address = {Melbourne, Australia},
author = {Harzing, Anne Wil},
doi = {10.1007/s11192-011-0388-8},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bensman - 2011 - Anne-Wil Harzing The publish or perish book Your guide to effective and responsible citation analysis.pdf:pdf},
isbn = {9780980648502},
issn = {01389130},
publisher = {Tarma Software Research Pty Ltd},
title = {{The publish or perish book: Your guide to effective and responsible citation analysis}},
url = {http://www.harzing.com/publications/publish-or-perish-book},
year = {2011}
}
@article{Harzing2016,
abstract = {This article aims to provide a systematic and comprehensive comparison of the coverage of the three major bibliometric databases: Google Scholar, Scopus and the Web of Science. Based on a sample of 146 senior academics in five broad disciplinary areas, we therefore provide both a longitudinal and a cross-disciplinary comparison of the three databases. Our longitudinal comparison of eight data points between 2013 and 2015 shows a consistent and reasonably stable quarterly growth for both publications and citations across the three databases. This suggests that all three databases provide sufficient stability of coverage to be used for more detailed cross-disciplinary comparisons. Our cross-disciplinary comparison of the three databases includes four key research metrics (publications, citations, h-index, and hI, annual, an annualised individual h-index) and five major disciplines (Humanities, Social Sciences, Engineering, Sciences and Life Sciences). We show that both the data source and the specific metrics used change the conclusions that can be drawn from cross-disciplinary comparisons.},
author = {Harzing, Anne Wil and Alakangas, Satu},
doi = {10.1007/s11192-015-1798-9},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harzing, Alakangas - 2016 - Google Scholar, Scopus and the Web of Science a longitudinal and cross-disciplinary comparison.pdf:pdf},
issn = {15882861},
journal = {Scientometrics},
keywords = {Citation analysis,Google Scholar,H-index,Research metrics,Scopus,Web of Science,hIa},
number = {2},
pages = {787--804},
publisher = {Springer Netherlands},
title = {{Google Scholar, Scopus and the Web of Science: a longitudinal and cross-disciplinary comparison}},
url = {"http://dx.doi.org/10.1007/s11192-015-1798-9},
volume = {106},
year = {2016}
}
@article{Hendrix2008,
abstract = {OBJECTIVE: The objective of this study was to analyze bibliometric data from ISI, National Institutes of Health (NIH)-funding data, and faculty size information for Association of American Medical Colleges (AAMC) member schools during 1997 to 2007 to assess research productivity and impact. METHODS: This study gathered and synthesized 10 metrics for almost all AAMC medical schools(n=123): (1) total number of published articles per medical school, (2) total number of citations to published articles per medical school, (3) average number of citations per article, (4) institutional impact indices, (5) institutional percentages of articles with zero citations, (6) annual average number of faculty per medical school, (7) total amount of NIH funding per medical school, (8) average amount of NIH grant money awarded per faculty member, (9) average number of articles per faculty member, and (10)average number of citations per faculty member. Using principal components analysis, the author calculated the relationships between measures, if they existed. RESULTS: Principal components analysis revealed 3 major clusters of variables that accounted for 91{\%} of the total variance: (1) institutional research productivity, (2) research influence or impact, and (3)individual faculty research productivity. Depending on the variables in each cluster, medical school research may be appropriately evaluated in a more nuanced way. Significant correlations exist between extracted factors, indicating an interrelatedness of all variables. Total NIH funding may relate more strongly to the quality of the research than the quantity of the research. The elimination of medical schools with outliers in 1 or more indicators (n=20)altered the analysis considerably. CONCLUSIONS: Though popular, ordinal rankings cannot adequately describe the multidimensional nature of a medical school's research productivity and impact. This study provides statistics that can be used in conjunction with other sound methodologies to provide a more authentic view of a medical school's research. The large variance of the collected data suggests that refining bibliometric data by discipline, peer groups, or journal information may provide a more precise assessment.},
author = {Hendrix, Dean},
doi = {10.3163/1536-5050.96.4.007},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hendrix - 2008 - An analysis of bibliometric indicators, National Institutes of Health funding, and faculty size at Association of Ameri.pdf:pdf},
isbn = {1558-9439 (Electronic)$\backslash$r1536-5050 (Linking)},
issn = {1536-5050},
journal = {Journal of the Medical Library Association},
number = {4},
pages = {324--334},
pmid = {18979684},
title = {{An analysis of bibliometric indicators, National Institutes of Health funding, and faculty size at Association of American Medical Colleges medical schools, 1997-2007.}},
volume = {96},
year = {2008}
}
@article{Heneberg2013,
abstract = {BACKGROUND: Publication lag between manuscript submission and its final publication is considered as an important factor affecting the decision to submit, the timeliness of presented data, and the scientometric measures of the particular journal. Dual-format peer-reviewed journals (publishing both print and online editions of their content) adopted a broadly accepted strategy to shorten the publication lag: to publish the accepted manuscripts online ahead of their print editions, which may follow days, but also years later. Effects of this widespread habit on the immediacy index (average number of times an article is cited in the year it is published) calculation were never analyzed.$\backslash$n$\backslash$nMETHODOLOGY/PRINCIPAL FINDINGS: Scopus database (which contains nearly up-to-date documents in press, but does not reveal citations by these documents until they are finalized) was searched for the journals with the highest total counts of articles in press, or highest counts of articles in press appearing online in 2010-2011. Number of citations received by the articles in press available online was found to be nearly equal to citations received within the year when the document was assigned to a journal issue. Thus, online publication of in press articles affects severely the calculation of immediacy index of their source titles, and disadvantages online-only and print-only journals when evaluating them according to the immediacy index and probably also according to the impact factor and similar measures.$\backslash$n$\backslash$nCONCLUSIONS/SIGNIFICANCE: Caution should be taken when evaluating dual-format journals supporting long publication lag. Further research should answer the question, on whether the immediacy index should be replaced by an indicator based on the date of first publication (online or in print, whichever comes first) to eliminate the problems analyzed in this report. Information value of immediacy index is further questioned by very high ratio of authors' self-citations among the citation window used for its calculation.},
author = {Heneberg, Petr},
doi = {10.1371/journal.pone.0059877},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heneberg - 2013 - Effects of Print Publication Lag in Dual Format Journals on Scientometric Indicators.pdf:pdf},
isbn = {1932-6203},
issn = {19326203},
journal = {PLoS ONE},
number = {4},
pmid = {23573216},
title = {{Effects of Print Publication Lag in Dual Format Journals on Scientometric Indicators}},
volume = {8},
year = {2013}
}
@phdthesis{Hercova2005,
abstract = {T{\'{e}}matem pr{\'{a}}ce je cita{\v{c}}n{\'{i}} anal{\'{y}}za, citace a v{\v{e}}deck{\'{a}} komunikace v ti{\v{s}}t{\v{e}}n{\'{e}}m a elektronick{\'{e}}m prostřed{\'{i}}. Pr{\'{a}}ce se zam{\v{e}}řuje na problematiku bibliometrie, infometrie, cita{\v{c}}n{\'{i}} anal{\'{y}}zu, definuje pojem impakt faktor. Stru{\v{c}}n{\v{e}} popisuje prostřed{\'{i}} Web of knowledge. Pr{\'{a}}ce se pojedn{\'{a}}v{\'{a}} o kritice citac{\'{i}}, autocitac{\'{i}}ch a odm{\v{e}}ňov{\'{a}}n{\'{i}} ve v{\v{e}}d{\v{e}} a zam{\v{e}}řuje se d{\'{a}}le na cita{\v{c}}n{\'{i}} rejstř{\'{i}}ky jako jsou Taiwan Humanities Citation Index, Scopus, Index Copernicus. V pr{\'{a}}ci je zpracov{\'{a}}na oblast patentov{\'{y}}ch citac{\'{i}} a tak{\'{e}} problematika cita{\v{c}}n{\'{i}} anal{\'{y}}zy v elektronick{\'{e}}m prostřed{\'{i}} - webometrie.},
author = {Hercov{\'{a}}, Ludmila},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tobergte, Curtis - 2013 - No Title No Title.pdf:pdf},
keywords = {Index Copernicus,Journal Citation Reports,Matthewův efekt,Scopus,Taiwan Humanities Citation Index (THCI),Web of Knowledge,Web of Science,autocitace,bibliometrie,cita{\v{c}}n{\'{i}} anal{\'{y}}za,cita{\v{c}}n{\'{i}} indexy,cita{\v{c}}n{\'{i}} rejstř{\'{i}}ky,cited half-life,citing half-life,immediacy index,impakt faktor,infometrie,patentov{\'{e}} citace,webometrie},
school = {Univerzita Karlova, Filozofick{\'{a}} fakulta},
title = {{Cita{\v{c}}n{\'{i}} anal{\'{y}}za a komunikace v{\v{e}}deck{\'{y}}ch znalost{\'{i}}}},
year = {2005}
}
@article{Herranz2012,
abstract = {This paper investigates the citation impact of three large geographical areas - the U.S., the European Union (EU), and the rest of the world (RW) - at different aggregation levels. The difficulty is that 42{\%} of the 3.6 million articles in our Thomson Scientific dataset are assigned to several sub-fields among a set of 219 Web of Science categories. We follow a multiplicative approach in which every article is wholly counted as many times as it appears at each aggregation level. We compute the crown indicator and the Mean Normalized Citation Score (MNCS) using for the first time sub-field normalization procedures for the multiplicative case. We also compute a third indicator that does not correct for differences in citation practices across sub-fields. It is found that: (1) No geographical area is systematically favored (or penalized) by any of the two normalized indicators. (2) According to the MNCS, only in six out of 80 disciplines - but in none of 20 fields - is the EU ahead of the U.S. In contrast, the normalized U.S./EU gap is greater than 20{\%} in 44 disciplines, 13 fields, and for all sciences as a whole. The dominance of the EU over the RW is even greater. (3) The U.S. appears to devote relatively more - and the RW less - publication effort to sub-fields with a high mean citation rate, which explains why the U.S./EU and EU/RW gaps for all sciences as a whole increase by 4.5 and 5.6 percentage points in the un-normalized case. The results with a fractional approach are very similar indeed. ?? 2012 Elsevier Ltd.},
author = {Herranz, Neus and Ruiz-Castillo, Javier},
doi = {10.1093/reseval/rvs006},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Herranz, Ruiz-Castillo - 2012 - Sub-field normalization in the multiplicative case High- and low-impact citation indicators.pdf:pdf},
issn = {09582029},
journal = {Research Evaluation},
keywords = {Citation analysis,High- and low-impact indicators,Multiplicative approach,Subfield normalization,US/EU scientific gap},
number = {2},
pages = {113--125},
publisher = {Elsevier Ltd},
title = {{Sub-field normalization in the multiplicative case: High- and low-impact citation indicators}},
url = {http://dx.doi.org/10.1016/j.joi.2012.02.006},
volume = {21},
year = {2012}
}
@article{Hirsch2005,
abstract = {I propose the index h, defined as the number of papers with citation number {\textgreater} or =h, as a useful index to characterize the scientific output of a researcher.},
archivePrefix = {arXiv},
arxivId = {physics/0509048},
author = {Hirsch, J E},
doi = {10.1073/pnas.0507655102},
eprint = {0509048},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hirsch - 2005 - An index to quantify an individual's scientific research output.pdf:pdf},
isbn = {0027-8424 (Print)$\backslash$r0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proc Natl Acad Sci U S A},
number = {46},
pages = {16569--16572},
pmid = {16275915},
primaryClass = {physics},
title = {{An index to quantify an individual's scientific research output}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16275915},
volume = {102},
year = {2005}
}
@article{Hood2001,
abstract = {Since Vassily V. Nalimov coined the term 'scientometrics' in the 1960s, this term has grown in popularity and is used to describe the study of science: growth, structure, interrelationships and productivity. Scientometrics is related to and has overlapping interests with bibliometrics and informetrics. The terms bibliometrics, scientometrics, and informetrics refer to component fields related to the study of the dynamics of disciplines as reflected in the production of their literature, Areas of study range from charting changes in the output of a scholarly field through time and across countries, to the library collection problem of maintaining control of the output, and to the low publication productivity of most researchers. These terms are used to describe similar and overlapping methodologies. The origins and historical survey of the development of each of these terms are presented. Profiles of the usage of each of these terms over time are presented, using an appropriate subject category of databases on the DIALOG information service. Various definitions of each of the terms are provided from an examination of the literature. The size of the overall literature of these fields is determined and the growth and stabilisation of both the dissertation and non-dissertation literature are shown. A listing of the top journals in the three fields are given, as well as a list of the major reviews and bibliographies that have been published over the years.},
author = {Hood, William W. and Wilson, Concepci{\'o}n S.},
doi = {10.1023/A:1017919924342},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hood, Wilson - 2001 - The literature of bibliometrics, scientometrics, and informetrics.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {2},
pages = {291--314},
pmid = {1284},
title = {{The literature of bibliometrics, scientometrics, and informetrics}},
volume = {52},
year = {2001}
}
@article{Horlings2013,
abstract = {Understanding how individual scientists build a personal portfolio of research is key to understanding outcomes on the level of scientific fields, institutions, and systems. We lack the scientometric and statistical instruments to examine the development over time of the involvement of researchers in different problem areas. In this paper we present a scientometric method to map, measure, and compare the entire corpus of individual scientists. We use this method to analyse the search strategies of 43 condensed matter physicists along their academic lifecycle. We formulate six propositions that summarise our theoretical expectations and are empirically testable: (1) a scientist's work consists of multiple finite research trails; (2) a scientist will work in several parallel research trails; (3) a scientist's role in research trail selection changes along the lifecycle; (4) a scientist's portfolio will converge before it diverges; (5) the rise and fall of research trails is associated with career changes; and (6) the rise and fall of research trails is associated with the potential for reputational gain. Four propositions are confirmed, the fifth is rejected, and the sixth could not be confirmed or rejected. In combination, the results of the four confirmed propositions reveal specific search strategies along the academic lifecycle. In the PhD phase scientists work in one problem area that is often unconnected to the later portfolio. The postdoctoral phase is where scientists diversify their portfolio and their social network, entering various problem areas and abandoning low-yielding ones. A professor has a much more stable portfolio, leading the work of PhDs and postdoctoral researchers. We present an agenda for future research and discuss theoretical and policy implications.},
author = {Horlings, Edwin and Gurney, Thomas},
doi = {10.1007/s11192-012-0789-3},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Horlings, Gurney - 2013 - Search strategies along the academic lifecycle.pdf:pdf},
isbn = {1119201207893},
issn = {01389130},
journal = {Scientometrics},
keywords = {Academic careers,Agenda setting,Complex adaptive system,Lifecycle,Mapping science,Problem choice},
number = {3},
pages = {1137--1160},
pmid = {23420456},
title = {{Search strategies along the academic lifecycle}},
volume = {94},
year = {2013}
}
@article{Hsieh2011,
abstract = {Inventions combine technological features. When features are barely related, burdensomely broad knowledge is required to identify the situations that they share. When features are overly related, burdensomely broad knowledge is required to identify the situations that distinguish them. Thus, according to my first hypothesis, when features are moderately related, the costs of connecting and costs of synthesizing are cumulatively minimized, and the most useful inventions emerge. I also hypothesize that continued experimentation with a specific set of features is likely to lead to the discovery of decreasingly useful inventions; the earlier-identified connections reflect the more common consumer situations. Covering data from all industries, the empirical analysis provides broad support for the first hypothesis. Regressions to test the second hypothesis are inconclusive when examining industry types individually. Yet, this study represents an exploratory investigation, and future research should test refined hypotheses with more sophisticated data, such as that found in literature-based discovery research.},
author = {Hsieh, Chihmao},
doi = {10.1007/s11192-010-0290-9},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hsieh - 2011 - Explicitly searching for useful inventions Dynamic relatedness and the costs of connecting versus synthesizing.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Connections,Inventions,Linkage,Patents,Relatedness,Search},
number = {2},
pages = {381--404},
pmid = {21297855},
title = {{Explicitly searching for useful inventions: Dynamic relatedness and the costs of connecting versus synthesizing}},
volume = {86},
year = {2011}
}
@article{Ivancheva2008,
abstract = {The paper considers the current state of scientometrics, in methodological context, as a branch of the discipline “science of science”. Discusses its fields of study; the wider thematic scope of scientometrics; the specific research instruments, objects /and indicators, related to them – “input” and “output” ones/, the empirical basis, and explanatory abilities of scientometrics. Some classifications of scientometric methods are also introduced},
author = {Ivancheva, Ludmila},
doi = {10.1080/09737766.2008.10700853},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ivancheva - 2008 - Scientometrics Today A Methodological Overview.pdf:pdf},
issn = {0973-7766},
journal = {Collnet Journal of Scientometrics and Information {\ldots}},
keywords = {history,research,science of science,science policy,scientometrics},
number = {2},
pages = {47--57},
title = {{Scientometrics Today: A Methodological Overview}},
url = {http://www.collnet.de/Berlin-2008/IvanchevaWIS2008stm.pdf},
volume = {2},
year = {2008}
}
@article{JakariaRahman2015,
abstract = {Discipline-specific research evaluation exercises are typically carried out by panels of peers, known as expert panels. To the best of our knowledge, no methods are available to measure overlap in expertise between an expert panel and the units under evaluation. This paper explores bibliometric approaches to determine this overlap, using two research evaluations of the departments of Chemistry (2009) and Physics (2010) of the University of Antwerp as a test case. We explore the usefulness of overlay mapping on a global map of science (with Web of Science subject categories) to gauge overlap of expertise and introduce a set of methods to determine an entity's barycenter according to its publication output. Barycenters can be calculated starting from a similarity matrix of subject categories (N dimensions) or from a visualization thereof (2 dimensions). We compare the results of the N-dimensional method with those of two 2-dimensional ones (Kamada-Kawai maps and VOS maps) and find that they yield very similar results. The distance between barycenters is used as an indicator of expertise overlap. The results reveal that there is some discrepancy between the panel's and the groups' publications in both the Chemistry and the Physics departments. The panels were not as diverse as the groups that were assessed. The match between the Chemistry panel and the Department was better than that between the Physics panel and the Department.},
author = {{Jakaria Rahman}, A. I M and Guns, Raf and Rousseau, Ronald and Engels, Tim C E},
doi = {10.1016/j.joi.2015.07.009},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jakaria Rahman et al. - 2015 - Is the expertise of evaluation panels congruent with the research interests of the research groups A quan.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Barycenter,Expert panel,Matching research expertise,Overlay map,Research evaluation,Similarity matrix},
number = {4},
pages = {704--721},
publisher = {Elsevier Ltd},
title = {{Is the expertise of evaluation panels congruent with the research interests of the research groups: A quantitative approach based on barycenters}},
url = {http://dx.doi.org/10.1016/j.joi.2015.07.009},
volume = {9},
year = {2015}
}
@article{Jasienski2013,
abstract = {Entrepreneurs often face the challenge of hiring academic researchers who could provide know-how or serve as potential business partners, collaborators or expert consultants. Since hiring experts may be costly, it is essential that only the best specialists be used. I describe some quantitative scientometric tools (such as h-index and g- index) aimed at evaluating academic quality of institutions or of individual researchers. Such tools provide information that is easily accessible, comprehensible and merit-based, although they must be used with caution, since disciplines differ in the absolute values of indexes. I show how to use scientometrics in a comparative manner to document low output and poor quality of the publications of Polish academic authors in the area of business and management. I also argue that some governmental procedures for rewarding academic excellence are not effective because they reduce incentives for publishing academic papers in English.},
author = {Jasie{\'{n}}ski, Micha{\l}},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wy - 2013 - Micha {\l} Jasie {\'{n}} ski Center for Innovatics , Nowy S {\c{a}} cz Business School – National-Louis University , ul . Zielona 27.pdf:pdf},
issn = {1426-9724},
journal = {Zeszyty Naukowe Wy{\.{z}}szej Szko{\l}y Bankowej w Poznaniu},
keywords = {bibliometrics,citation analysis,consulting,entrepreneurship,h-index,management,scientometrics},
pages = {151--167},
title = {{Citation analysis as a practical tool for managers and entrepreneurs: selected scientometric concepts relevant for business model improvement}},
volume = {51},
year = {2013}
}
@article{Jiang2014,
abstract = {Two fundamental issues surrounding research on Zipf's law regarding city sizes are whether and why this law holds. This paper does not deal with the latter issue with respect to why, and instead investigates whether Zipf's law holds in a global setting, thus involving all cities around the world. Unlike previous studies, which have mainly relied on conventional census data, and census- bureau-imposed definitions of cities, we adopt naturally and objectively delineated cities, or natural cities, to be more precise, in order to examine Zipf's law. We find that Zipf's law holds remarkably well for all natural cities at the global level, and remains almost valid at the continental level except for Africa at certain time instants. We further examine the law at the country level, and note that Zipf's law is violated from country to country or from time to time. This violation is mainly due to our limitations; we are limited to individual countries, or to a static view on city-size distributions. The central argument of this paper is that Zipf's law is universal, and we therefore must use the correct scope in order to observe it. We further find Zipf's law applied to city numbers: the number of cities in individual countries follows an inverse power relationship; the number of cities in the first largest country is twice as many as that in the second largest country, three times as many as that in the third largest country, and so on. Keywords: Cities, night-time imagery, city-size distributions, head/tail breaks, big data},
archivePrefix = {arXiv},
arxivId = {1402.2965},
author = {Jiang, B and Yin, J and Liu, Q},
doi = {10.1080/13658816.2014.988715},
eprint = {1402.2965},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang, Yin, Liu - 2014 - Zipf's Law for All the Natural Cities around the World.pdf:pdf},
issn = {1362-3087},
journal = {International Journal of Geographical Information Science},
keywords = {big data,cities,city-size distributions,head,night-time imagery,tail breaks},
number = {3},
pages = {498--522},
title = {{Zipf's Law for All the Natural Cities around the World}},
url = {http://arxiv.org/abs/1402.2965},
volume = {29},
year = {2015}
}
@article{Jin2007,
abstract = {Based on the foundation laid by the h-index we introduce and study the R- and AR-indices. These new indices eliminate some of the disadvantages of the h-index, especially when they are used in combination with the h-index. The R-index measures the h-core's citation intensity, while AR goes one step further and takes the age of publications into account. This allows for an index that can actually increase and decrease over time. We propose the pair (h, AR) as a meaningful indicator for research evaluation. We further prove a relation characterizing the h-index in the power law model.},
author = {Jin, BiHui and Liang, LiMing and Rousseau, Ronald and Egghe, Leo},
doi = {10.1007/s11434-007-0145-9},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jin et al. - 2007 - The R- and AR-indices Complementing the h-index.pdf:pdf},
isbn = {1001-6538},
issn = {10016538},
journal = {Chinese Science Bulletin},
keywords = {A-index,AR-index,Performance evaluation,Power law,R-index,g-index,h-index},
number = {6},
pages = {855--863},
title = {{The R- and AR-indices: Complementing the h-index}},
volume = {52},
year = {2007}
}
@article{Jipa2011,
abstract = {The paper describes different new indicators measuring research output by application to Chemistry Department of the Faculty of Sciences and Arts from Valahia University of Targoviste. We have also analyzed the Hirsch indices calculated with different relations proposed in literature. We have compared the data obtained in our study with the results of other studies done in other universities and circumstances.},
author = {Jipa, Silviu and Gorgiu, Laura Monica and Dumitrescu, Crinela and Oros, Calin},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oros - 2011 - Applying New Scientometric Indicators To Evaluate the Scientific Performance of Chemistry Group From Valachia University o.pdf:pdf},
journal = {Journal of Science and Arts},
keywords = {hirsch index,research,scientometric indices,scientometry},
number = {4},
pages = {491--498},
title = {{Applying New Scientometric Indicators To Evaluate the Scientific Performance of Chemistry Group From Valachia University of Targoviste}},
volume = {17},
year = {2011}
}
@article{Jones2012,
abstract = {There is an increasing need both to understand the translation of biomedical research into improved healthcare and to assess the range of wider impacts from health research such as improved health policies, health practices and healthcare. Conducting such assessments is complex and new methods are being sought. Our new approach involves several steps. First, we developed a qualitative citation analysis technique to apply to biomedical research in order to assess the contribution that individual papers made to further research. Second, using this method, we then proposed to trace the citations to the original research through a series of generations of citing papers. Third, we aimed eventually to assess the wider impacts of the various generations. This article describes our comprehensive literature search to inform the new technique. We searched various databases, specific bibliometrics journals and the bibliographies of key papers. After excluding irrelevant papers we reviewed those remaining for either general or specific details that could inform development of our new technique. Various characteristics of citations were identified that had been found to predict their importance to the citing paper including the citation's location; number of citation occasions and whether the author(s) of the cited paper were named within the citing paper. We combined these objective characteristics with subjective approaches also identified from the literature search to develop a citation categorisation technique that would allow us to achieve the first of the steps above, i.e., being able routinely to assess the contribution that individual papers make to further research.},
author = {Jones, Teresa H. and Donovan, Claire and Hanney, Steve},
doi = {10.1007/s11192-012-0642-8},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jones, Donovan, Hanney - 2012 - Tracing the wider impacts of biomedical research A literature search to develop a novel citation categor.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Citation categorisation,Citation generations,Methodology,Research assessment,Wider impacts of research},
number = {1},
pages = {125--134},
pmid = {23024423},
title = {{Tracing the wider impacts of biomedical research: A literature search to develop a novel citation categorisation technique}},
volume = {93},
year = {2012}
}
@article{Jung2015,
abstract = {In this study, we analysed the statistical association between e-journal$\backslash$nuse and research output at the institution level in South Korea by$\backslash$nperforming comparative and diachronic analyses, as well as the analysis$\backslash$nby field. The datasets were compiled from four different sources:$\backslash$nnational reports on research output indicators in science fields, two$\backslash$nstatistics databases on higher education institutions open to the$\backslash$npublic, and e-journal usage statistics generated by 47 major publishers.$\backslash$nDue to the different data sources utilized, a considerable number of$\backslash$nmissing values appeared in our datasets and various mapping issues$\backslash$nrequired corrections prior to the analysis. Two techniques for handling$\backslash$nmissing data were applied and the impact of each technique was$\backslash$ndiscussed. In order to compile the institutional data by field, journals$\backslash$nwere first mapped, and then the statistics were summarized according to$\backslash$nsubject field. We observed that e-journal use exhibited stronger$\backslash$ncorrelations with the number of publications and the times cited, in$\backslash$ncontrast to the number of undergraduates, graduates, faculty members and$\backslash$nthe amount of research funds, and this was the case regardless of the NA$\backslash$nhandling method or author type. The difference between the maximum$\backslash$ncorrelation for the amount of external research funding with two average$\backslash$nindicators and that of the correlation for e-journal use were not$\backslash$nsignificant. Statistically, the accountability of e-journal use for the$\backslash$naverage times cited per article and the average JIF was quite similar$\backslash$nwith external research funds. It was found that the number of e-journal$\backslash$narticles used had a strong positive correlation (Pearson's correlation$\backslash$ncoefficients of r {\textgreater} 0.9, p {\textless} 0.05) with the number of articles published$\backslash$nin SCI(E) journals and the times cited regardless of the author type, NA$\backslash$nhandling method or time period. We also observed that the top-five$\backslash$ninstitutions in South Korea, with respect to the number of publications$\backslash$nin SCI(E) journals, were generally across a balanced range of academic$\backslash$nactivities, while producing significant research output and using$\backslash$npublished material. Finally, we confirmed that the association of$\backslash$ne-journal use with the two quantitative research indicators is strongly$\backslash$npositive, even for the analyses by field, with the exception of the Arts$\backslash$nand Humanities.},
author = {Jung, Youngim and Kim, Jayhoon and So, Minho and Kim, Hwanmin},
doi = {10.1007/s11192-015-1563-0},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jung et al. - 2015 - Statistical relationships between journal use and research output at academic institutions in south korea.pdf:pdf},
isbn = {01389130 (ISSN)},
issn = {01389130},
journal = {Scientometrics},
keywords = {Comparative analysis,Correlation analysis,Diachronic analysis,E-Journaluse,Research output},
number = {3},
pages = {751--777},
pmid = {25995527},
title = {{Statistical relationships between journal use and research output at academic institutions in south korea}},
volume = {103},
year = {2015}
}
@article{Kaur2015,
abstract = {Citation metrics are becoming pervasive in the quantitative evaluation of scholars, journals, and institutions. Hiring, promotion, and funding decisions increasingly rely on a variety of impact metrics that cannot disentangle quality from quantity of scientific output, and are biased by factors such as discipline and academic age. Biases affecting the evaluation of single papers are compounded when one aggregates citation-based metrics across an entire publication record. It is not trivial to compare the quality of two scholars that during their careers have published at different rates, in different disciplines, and in different periods of time. Here we evaluate a method based on the generation of a statistical baseline specifically tailored on the academic profile of each researcher. We demonstrate the effectiveness of the approach in decoupling the roles of quantity and quality of publications to explain how a certain level of impact is achieved. The method can be extended to simultaneously suppress any source of bias. As an illustration, we use it to capture the quality of the work of Nobel laureates irrespective of number of publications, academic age, and discipline, even when traditional metrics indicate low impact in absolute terms. The procedure is flexible enough to allow for the evaluation of, and fair comparison among, arbitrary collections of papers - scholar publication records, journals, and institutions; in fact, it extends a similar technique that was previously applied to the ranking of research units and countries in specific disciplines (Crespo, Ortu??o-Ort??, {\&} Ruiz-Castillo, 2012). We further apply the methodology to almost a million scholars and over six thousand journals to measure the impact that cannot be explained by the volume of publications alone.},
archivePrefix = {arXiv},
arxivId = {1411.7357},
author = {Kaur, Jasleen and Ferrara, Emilio and Menczer, Filippo and Flammini, Alessandro and Radicchi, Filippo},
doi = {10.1016/j.joi.2015.07.008},
eprint = {1411.7357},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaur et al. - 2015 - Quality versus quantity in scientific impact.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Citation analysis,Quality,Quantity,Research evaluation,Scientific impact},
number = {4},
pages = {800--808},
publisher = {Elsevier Ltd},
title = {{Quality versus quantity in scientific impact}},
url = {http://dx.doi.org/10.1016/j.joi.2015.07.008},
volume = {9},
year = {2015}
}
@article{Kaur2013,
abstract = {Given the growing use of impact metrics in the evaluation of scholars, journals, academic institutions, and even countries, there is a critical need for means to compare scientific impact across disciplinary boundaries. Unfortunately, citation-based metrics are strongly biased by diverse field sizes and publication and citation practices. As a result, we have witnessed an explosion in the number of newly proposed metrics that claim to be "universal." However, there is currently no way to objectively assess whether a normalized metric can actually compensate for disciplinary bias. We introduce a new method to assess the universality of any scholarly impact metric, and apply it to evaluate a number of established metrics. We also define a very simple new metric hs, which proves to be universal, thus allowing to compare the impact of scholars across scientific disciplines. These results move us closer to a formal methodology in the measure of scholarly impact. ?? 2013 .},
archivePrefix = {arXiv},
arxivId = {1305.6339},
author = {Kaur, Jasleen and Radicchi, Filippo and Menczer, Filippo},
doi = {10.1016/j.joi.2013.09.002},
eprint = {1305.6339},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaur, Radicchi, Menczer - 2013 - Universality of scholarly impact metrics.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliometrics,Discipline bias,Impact metrics,Universality},
number = {4},
pages = {924--932},
publisher = {Elsevier Ltd},
title = {{Universality of scholarly impact metrics}},
url = {http://dx.doi.org/10.1016/j.joi.2013.09.002},
volume = {7},
year = {2013}
}
@article{Kazakis2015,
abstract = {The object of the present study is the evaluation of the research$\backslash$nquality of the three Greek chemical engineering departments (Athens,$\backslash$nThessaloniki, Patras) by means of several advanced bibliometric indices$\backslash$ncalculated separately for each academic using a twofold approach, namely$\backslash$nin department and academic rank level. This allows the ranking of the$\backslash$nstudied departments, but also sheds light on the distribution of the$\backslash$nresearch activity among the various ranks. In addition, to assess the$\backslash$nresearch profile and background of the current faculty of the Greek$\backslash$nchemical engineering departments in International context their research$\backslash$noutput is compared with that of Massachusetts chemical engineering$\backslash$ndepartment, Massachusetts Institute of Technology (MIT). Dependency of$\backslash$nthe bibliometric indices on seniority is also investigated, conducting$\backslash$nthe bibliometric analysis using a common time basis for all academics,$\backslash$ni.e., research performance during the last decade. Available data are$\backslash$nalso used to investigate the temporal progress of the research$\backslash$nproductivity. Finally, gender distribution among the academics of the$\backslash$nvarious ranks is also studied to explore the gender balance in research.$\backslash$nIn general, bibliometrics demonstrate that Patras department host$\backslash$nacademics of better quality, with higher scientific activity over the$\backslash$nlast decade, but superiority of MIT department against the Greek$\backslash$ndepartments is also evident. Results also indicate that no common$\backslash$nstandards in hiring/promotion of academics are established between the$\backslash$ndepartments. The negative impact of the European socio-economic crisis$\backslash$non the research productivity is also highlighted, while the university$\backslash$nsystem suffers from unequal gender distribution with pronounced male$\backslash$ndominance.},
author = {Kazakis, Nikolaos A.},
doi = {10.1007/s11192-014-1523-0},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazakis - 2015 - The research activity of the current faculty of the Greek chemical engineering departments a bibliometric study in nati.pdf:pdf},
isbn = {1119201413263},
issn = {01389130},
journal = {Scientometrics},
keywords = {Academic rank,Bibliometrics,Chemical engineering,Gender,Greece,Research evaluation,h-index},
number = {1},
pages = {229--250},
title = {{The research activity of the current faculty of the Greek chemical engineering departments: a bibliometric study in national and international context}},
volume = {103},
year = {2015}
}
@article{Kazakis2014a,
abstract = {Quality in Higher Education Institutions is the subject of several debates in the academic community in a worldwide basis and various efforts are made towards identifying ways to quantify it. In this respect, the use of bibliometrics gains significant ground as an effective tool for the evaluation of universities' research output. In the present study, the research performance of the seven Greek medical schools is assessed by means of widely accepted and advanced bibliometric indices, such as total and average publications and citations, average and median h- and g-index with and without self-citations for all the 1,803 academics, while statistical analysis of the data was also performed in order to compare the observed differences in the mean values of the calculated indices. Considerable effort was exerted to overcome all inherent limitations of a bibliometric analysis through a meticulous data collection. This large-scale work was conducted both in school and academic rank level leading to interesting results concerning the scientific activity of the medical schools studied as units and of the various academic ranks separately, which can be partially justified with geographic and socioeconomic criteria. In general, bibliometrics demonstrate statistically significant difference in favour of Crete University medical school, while it was also found that self-citations have only marginal effect on the individual's research profile and the average indices. Finally, the useful findings of the present study render the methodology adopted of high viability for assessing the research performance of Higher Education Institutions even in a broader context.},
author = {Kazakis, Nikolaos A. and Diamantidis, Anastasios D. and Fragidis, Leonidas L. and Lazarides, Miltos K.},
doi = {10.1007/s11192-013-1049-x},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazakis et al. - 2014 - Evaluating the research performance of the Greek medical schools using bibliometrics.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {ANOVA,Bibliometrics,Medical school,Research evaluation,Self-citations,g-index,h-index},
number = {2},
pages = {1367--1384},
title = {{Evaluating the research performance of the Greek medical schools using bibliometrics}},
volume = {98},
year = {2014}
}
@article{Kelly2000,
abstract = {The purpose of this paper is to examine how instruction in scientific writing in a university oceanography course communicated epistemological positions of this discipline. Drawing from sociological and anthropological studies of scientific communities, this study uses an ethnographic perspective to explore how teachers and students came to define particular views of disciplinary knowledge through the everyday practices associated with teaching and learning oceanography. Writing in a scientific genre was supported by interactive CD-ROM which allowed students to access data representations from geological databases. In our analysis of the spoken and written discourse of the members of this course, we identified epistemological issues such as uses of evidence, role of expertise, relevance of point of view, and limits to the authority of disciplinary inquiry. Implications for college science teaching are drawn. (C) 2000 John Wiley {\&} Sons, Inc.},
author = {Kelly, G J and Chen, C and Prothero, W},
doi = {10.1002/1098-2736(200009)37:7<691::AID-TEA5>3.0.CO;2-G},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kelly, Chen, Prothero - 2000 - The epistemological framing of a discipline Writing science in university oceanography.pdf:pdf},
isbn = {0022-4308},
issn = {0022-4308},
journal = {Journal of Research in Science Teaching},
keywords = {discourse,education,learn,physics,school science,sociology,students preconceptions},
number = {7},
pages = {691--718},
title = {{The epistemological framing of a discipline: Writing science in university oceanography}},
url = {{\textless}Go to ISI{\textgreater}://000089082000005},
volume = {37},
year = {2000}
}
@article{Kim2014,
abstract = {This study presents an in-depth survey of research and citation performance of the School of Biological Sciences (SBS) 39-member faculty at Seoul National University (SNU), the most prestigious university in South Korea, for the years 2004-2009. Thirty-nine faculty members published a total of 640 publications during the period, representing an average of 16.4 publications per scientist. Among the 640 publications, 521 (81.4 {\%}) were cited 9,204 times, an average of 14.4 citations per publication. More publications co-authored by the SBS faculty with foreign researchers (mostly from the U.S.A.) were published in mainstream journals than publications by three other co-authorship types. Accordingly, publications by international co-authorships received more citations compared to citation levels of three other co-authorship types in terms of the average citations per publication. The study has found a concentration effect, whereby quite a small number of publications received approximately one-third of the citation performance generated by the SBS faculty at SNU. The results demonstrate that the citation performance of the SBS at SNU can be influenced considerably by the presence and productivity of 'star' scientists.},
author = {Kim, M J},
doi = {10.1007/s11192-013-1084-7},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim - 2014 - A bibliometric analysis of publications by the School of Biological Sciences, Seoul National University, South Korea.pdf:pdf},
isbn = {0138-9130},
issn = {0138-9130},
journal = {Scientometrics},
keywords = {BIOTECHNOLOGY,Biological sciences,Biotechnology,Citation patterns,Citation performance,Publication patterns,RESEARCH PERFORMANCE,Research performance,SCIENTIFIC-RESEARCH,SPANISH-COUNCIL,South Korea},
number = {2},
pages = {999--1019},
title = {{A bibliometric analysis of publications by the School of Biological Sciences, Seoul National University, South Korea}},
url = {{\textless}Go to ISI{\textgreater}://WOS:000330622600013$\backslash$nhttp://download.springer.com/static/pdf/136/art:10.1007/s11192-013-1084-7.pdf?auth66=1422546949{\_}544a8cf815c742cb56ef93185bf57186{\&}ext=.pdf},
volume = {98},
year = {2014}
}
@article{Kinouchi2014,
abstract = {This paper discusses the intellectual justification of scientometrics through the claim that it is part of the quest for a quantitative science of science. Initially, I will make a brief description of scientometrics' his- torical background. Next, I will explain that those disciplines that have been satisfactorily mathematized always contain two distinct basic components: an axiomatic, defining the operations that can be realized with the available data, and an interpretation of their meaning. Counting papers and citations is a way to collect statistical data about scientific activities, and therefore the axiomatic basis of scientometrics comes from statistics. Regarding the interpretation of scientometrics, I will argue that the meanings attributed to their key concepts are usually borrowed from economics. Then I discuss how the promise of a science of science becomes a too well adjusted historical narrative that apparently justifies the economic con- cerns of governments and private corporations. Keywords},
author = {Kinouchi, Renato Rodrigues},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kinouchi - 2014 - Scientometrics the project for a science of science transformed into an industry of measurements.pdf:pdf},
isbn = {1400040000},
journal = {Scientiae Studia, Sao Paulo},
keywords = {citation analysis,commoditization,quantitative methods,scientometrics},
number = {Special},
pages = {147--159},
title = {{Scientometrics : the project for a science of science transformed into an industry of measurements}},
volume = {12},
year = {2014}
}
@article{Klimek2016,
author = {Klimek, Peter and {S. Jovanovic}, Aleksandar and Egloff, Rainer and Schneider, Reto},
doi = {10.1007/s11192-016-1926-1},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klimek et al. - 2016 - Successful fish go with the flow citation impact prediction based on centrality measures for termdocument network.pdf:pdf},
issn = {15882861},
journal = {Scientometrics},
keywords = {Bipartite networks,Citation impact prediction,Network theory,Term???document matrix},
pages = {1--18},
publisher = {Springer Netherlands},
title = {{Successful fish go with the flow: citation impact prediction based on centrality measures for term-document networks}},
url = {"http://dx.doi.org/10.1007/s11192-016-1926-1},
year = {2016}
}
@article{Kosmulski2013,
abstract = {A new method of assessment of scientific papers, scientists, and scientific institutions was defined. The significance of a paper was assessed by the definition of the largest (the most prestigious) set, including that paper in its h-core. The sets of papers were defined by affiliation (country, city, university, department) or by subject (branches and sub-branches of science, journal). The inclusion of a paper in the h-core of certain set(s) was used as an indicator of the significance of that paper, and of the scientific output of its author(s), of their scientific institution(s), etc. An analogous procedure was used to assess the contribution of an individual to the scientific output of his/her scientific institution, branch of science, etc.},
author = {Kosmulski, Marek},
doi = {10.1016/j.joi.2013.04.007},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kosmulski - 2013 - Are you in h.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Ranking of scientists,Ranking of universities,Scientific output,h-index},
number = {3},
pages = {693--698},
title = {{Are you in h?}},
url = {http://www.sciencedirect.com/science/article/pii/S1751157713000436},
volume = {7},
year = {2013}
}
@article{Kosmulski2012,
abstract = {Newly introduced bibliometric indices may be biased by the preference of scientists for bibliometric indices, in which their own research receives a high score. To test such a hypothesis, the publication and citation records of nine scientists who recently proposed new bibliometric indices were analyzed in terms of standard indicators, their own indicators, and indicators recently proposed by other scientists. The result of the test was negative, that is, newly introduced bibliometric indices did not favor their authors. {\textcopyright} 2012 Elsevier Ltd.},
author = {Kosmulski, Marek},
doi = {10.1016/j.joi.2012.06.003},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kosmulski - 2012 - Nemo iudex in causa sua.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bias in assessment of research,H-Index},
number = {4},
pages = {611--614},
publisher = {Elsevier Ltd},
title = {{Nemo iudex in causa sua?}},
url = {http://dx.doi.org/10.1016/j.joi.2012.06.003},
volume = {6},
year = {2012}
}
@article{Kozak2014,
abstract = {Did the demise of the Soviet Union in 1991 influence the scientific performance of the researchers in Eastern European countries? Did this historical event affect international collaboration by researchers from the Eastern European countries with those of Western countries? Did it also change international collaboration among researchers from the Eastern European countries? Trying to answer these questions, this study aims to shed light on international collaboration by researchers from the Eastern European countries (Russia, Ukraine, Belarus, Moldova, Bulgaria, the Czech Republic, Hungary, Poland, Romania, and Slovakia). The number of publications and normalized citation impact values are compared for these countries based on InCites (Thomson Reuters), from 1981 up to 2011. The international collaboration by researchers affiliated to institutions in Eastern European countries at the time points of 1990, 2000 and 2011 was studied with the help of Pajek and VOSviewer software, based on data from the Science Citation Index (Thomson Reuters). Our results show that the breakdown of the communist regime did not lead, on average, to a huge improvement in the publication performance of the Eastern European countries and that the increase in international co-authorship relations by the researchers affiliated to institutions in these countries was smaller than expected. Most of the Eastern European countries are still subject to changes and are still awaiting their boost in scientific development.},
author = {Kozak, Marcin and Bornmann, Lutz and Leydesdorff, Loet},
doi = {10.1007/s11192-014-1439-8},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kozak, Bornmann, Leydesdorff - 2014 - How have the Eastern European countries of the former Warsaw Pact developed since 1990 A bibliomet.pdf:pdf},
isbn = {0138-9130 (Print)$\backslash$r0138-9130 (Linking)},
issn = {01389130},
journal = {Scientometrics},
keywords = {Co-authorship,InCites,National comparison,Normalized citation impact,Warsaw pact},
number = {2},
pages = {1101--1117},
pmid = {25632165},
title = {{How have the Eastern European countries of the former Warsaw Pact developed since 1990? A bibliometric study}},
volume = {102},
year = {2014}
}
@article{Krampen2008,
abstract = {In reference to an exemplary bibliometric publication and citation analysis for a University Department of Psychology, some general conceptual and methodological considerations on the evaluation of university departments and their scientists are presented. Data refer to publication and citation-by-others analyses (PsycINFO, PSYNDEX, SSCI, and SCI) for 36 professorial and non-professorial scientists from the tenure staff of the department under study, as well as confidential interviews on self- and colleagues-perceptions with seven of the sample under study. The results point at (1) skewed (Pareto-) distributions of all bibliometric variables demanding non- parametrical statistical analyses, (2) three personally identical outliers which must be excluded from some statistical analyses, (3) rather low rank-order correlations of publication and citation frequencies having approximately 15{\%} common variance, (4) only weak interdependences of bibliometric variables with age, occupational experience, gender, academic status, and engagement in basic versus applied research, (5) the empirical appropriateness and utility of a normative typological model for the evaluation of scientists' research productivity and impact, which is based on cross-classifications with reference to the number of publications and the frequency of citations by other authors, and (6) low interrater reliabilities and validity of ad hoc evaluations within the departments' staff. Conclusions refer to the utility of bibliometric data for external peer reviewing and for feedback within scientific departments, in order to make colleague-perceptions more reliable and valid.},
author = {Krampen, G??nter},
doi = {10.1007/s11192-007-1900-z},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krampen - 2008 - The evaluation of university departments and their scientists Some general considerations with reference to exemplary b.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {1},
pages = {3--21},
title = {{The evaluation of university departments and their scientists: Some general considerations with reference to exemplary bibliometric publication and citation analyses for a Department of psychology}},
volume = {76},
year = {2008}
}
@phdthesis{Kudlickova2008,
abstract = {Information analysis in the subject field of agriculture, environment and food is the aim of this diploma thesis. The work is specialised in bibliometrics, informetrics, scientometrics, citation index, quantitative methods and sources of information in agriculture. The practical part of this paper is an analysis of the scientific journal JFAE (Journal of food, agriculture and environment), its registration in the citation index, the application of Lotka´s law, and matching key words with the thesaurus Agrovoc.},
author = {Kudli{\v{c}}kov{\'{a}}, Zuzana},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karlova - 2008 - Zuzana Kudli{\v{c}}kov{\'{a}} Informa{\v{c}}n{\'{i}} anal{\'{y}}za zvolen{\'{e}}ho oboru - přehled zdrojů informac{\'{i}} ( bibliometrick{\'{a}} anal{\'{y}}za ).pdf:pdf},
keywords = {Information analysis,Lotka´s law,agricultural databases,bibliometrics,bibliometrics laws,citation index,impact factor,informetrics,quantitative methods,science information,scientometrics},
pages = {46},
school = {Univerzita Karlova, Filozofick{\'{a}} fakulta},
title = {{Informa{\v{c}}n{\'{i}} anal{\'{y}}za zvolen{\'{e}}ho oboru - přehled zdrojů informac{\'{i}} (bibliometrick{\'{a}} anal{\'{y}}za)}},
year = {2008}
}
@article{Lariviere2011,
abstract = {In the recent debate on the use of averages of ratios (AoR) and ratios of averages (RoA) for the compilation of field-normalized citation rates, little evidence has been provided on the different results obtained by the two methods at various levels of aggregation. This paper provides such an empirical analysis at the level of individual researchers, departments, institutions and countries. Two datasets are used: 147,547 papers published between 2000 and 2008 and assigned to 14,379 Canadian university professors affiliated to 508 departments, and all papers indexed in the Web of Science for the same period (N= 8,221,926) assigned to all countries and institutions. Although there is a strong relationship between the two measures at each of these levels, a pairwise comparison of AoR and RoA shows that the differences between all the distributions are statistically significant and, thus, that the two methods are not equivalent and do not give the same results. Moreover, the difference between both measures is strongly influenced by the number of papers published as well as by their impact scores: the difference between AoR and RoA is greater for departments, institutions and countries with low RoA scores. Finally, our results show that RoA relative impact indicators do not add up to unity (as they should by definition) at the level of the reference dataset, whereas the AoR does have that property. {\textcopyright} 2011 Elsevier Ltd.},
author = {Larivi{\`{e}}re, Vincent and Gingras, Yves},
doi = {10.1016/j.joi.2011.02.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Larivi{\`{e}}re, Gingras - 2011 - Averages of ratios vs. ratios of averages An empirical analysis of four levels of aggregation.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Citations,Normalization,Research evaluation},
number = {3},
pages = {392--399},
title = {{Averages of ratios vs. ratios of averages: An empirical analysis of four levels of aggregation}},
volume = {5},
year = {2011}
}
@article{Lazaridis2010,
abstract = {Ranking of universities has lately received considerable attention. However, ranking of departments would give a higher resolution picture of the distribution of quality within each university. In this work the Hirsch (h) index of each faculty in Greek Chemistry, Chemical Engineering, Materials Science, and Physics departments was cal- culated using the Web of Science and the mean value was used to rank them. This ranking refers to the research performance of each department and thus is most relevant to its doctoral program. The results seem highly meaningful. If performed on a pan-European basis, such rankings could spur healthy competition and could provide a strong motive for meritocratic hiring practices. Technical difficulties and possible extension of this approach to social science and humanities departments are discussed.},
author = {Lazaridis, Themis},
doi = {10.1007/s11192-009-0048-4},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lazaridis - 2010 - Ranking university departments using the mean h-index.pdf:pdf},
isbn = {0138-9130$\backslash$r1588-2861},
issn = {01389130},
journal = {Scientometrics},
keywords = {Chemical engineering,Chemistry,Greece,Materials science,Physics,Ranking,h index},
number = {2},
pages = {211--216},
title = {{Ranking university departments using the mean h-index}},
volume = {82},
year = {2010}
}
@article{Leydesdorff2011,
abstract = {Using aggregated journal–journal citation networks, the measurement of the knowledge base in empirical systems is factor-analyzed in two cases of interdisciplinary developments during the period 1995–2005: (i) the development of nanotechnology in the natural sciences and (ii) the development of communication studies as an interdiscipline between social psychology and political science. The results are compared with a case of stable development: the citation networks of core journals in chemistry. These citation networks are intellectually organized by networks of expectations in the knowledge base at the specialty (that is, above-journal) level. The “structuration” of structural components (over time) can be measured as configurational information. The latter is compared with the Shannon-type information generated in the interactions among structural components: the difference between these two measures provides us with a measure for the redundancy generated by the specification of a model in the knowledge base of the system. This knowledge base incurs (against the entropy law) to variable extents on the knowledge infrastructures provided by the observable networks of relations.},
archivePrefix = {arXiv},
arxivId = {1012.5735},
author = {Leydesdorff, Loet},
doi = {10.1007/s11192-011-0397-7},
eprint = {1012.5735},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leydesdorff - 2011 - Structuration by intellectual organization The configuration of knowledge in relations among structural components.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Citation,Configuration,Dynamics,Journal,Knowledge,Meaning,Redundancy,Synergy},
number = {2},
pages = {499--520},
pmid = {21836763},
title = {{"Structuration" by intellectual organization: The configuration of knowledge in relations among structural components in networks of science}},
volume = {88},
year = {2011}
}
@article{Leydesdorff2012,
abstract = {Journal impact factors (IFs) can be considered historically as the first attempt to normalize citation distributions by using averages over 2 years. However, it has been recognized that citation distributions vary among fields of science and that one needs to normalize for this. Furthermore, the mean-or any central-tendency statistics-is not a good representation of the citation distribution because these distributions are skewed. Important steps have been taken to solve these two problems during the last few years. First, one can normalize at the article level using the citing audience as the reference set. Second, one can use non-parametric statistics for testing the significance of differences among ratings. A proportion of most-highly cited papers (the top-10{\%} or top-quartile) on the basis of fractional counting of the citations may provide an alternative to the current IF. This indicator is intuitively simple, allows for statistical testing, and accords with the state of the art.},
author = {Leydesdorff, Loet},
doi = {10.1007/s11192-012-0660-6},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leydesdorff - 2012 - Alternatives to the journal impact factor I3 and the top-10{\%} (or top-25{\%}) of the most-highly cited papers.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Citation,Impact,Journal,Nonparametric,Source normalization},
number = {2},
pages = {355--365},
pmid = {22844165},
title = {{Alternatives to the journal impact factor: I3 and the top-10{\%} (or top-25{\%}?) of the most-highly cited papers}},
volume = {92},
year = {2012}
}
@article{Leydesdorff2012a,
abstract = {The Leiden ranking 2011/2012 provides the Proportion top-10{\%} publications (PP top-10{\%}) as a new indicator. This indicator allows for testing performance differences between two universities for statistical significance. 2012 The Author(s).},
author = {Leydesdorff, Loet and Bornmann, Lutz},
doi = {10.1007/s11192-012-0636-6},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leydesdorff, Bornmann - 2012 - Testing differences statistically with the Leiden ranking.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Comparison,Expectation,Ranking,Test,University},
number = {3},
pages = {781--783},
pmid = {22904580},
title = {{Testing differences statistically with the Leiden ranking}},
volume = {92},
year = {2012}
}
@article{Leydesdorff2015,
abstract = {Abstract This article provides an overview of the field of scientometrics, that is, the study of science, technology, and innovation from a quantitative perspective. We cover major historical milestones in the development of this specialism from the 1960s to today and discuss its relationship with the sociology of scientific knowledge, the library and information sciences, and science policy issues such as indicator development. The disciplinary organization of scientometrics is analyzed both conceptually and empirically. A state-of-the-art review of five major research threads is provided.},
archivePrefix = {arXiv},
arxivId = {1208.4566},
author = {Leydesdorff, Loet and Milojevi{\'{c}}, Sta{\v{s}}a},
doi = {http://dx.doi.org/10.1016/B978-0-08-097086-8.85030-8},
eprint = {1208.4566},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leydesdorff, Milojevi{\'{c}} - 2015 - Scientometrics.pdf:pdf},
isbn = {978-0-08-097087-5},
journal = {International Encyclopedia of the Social {\&} Behavioral Sciences (Second Edition)},
keywords = {Bibliometrics,Citation,Impact,Indicator,Library,Mapping,Research management,Science policy,Science studies,Scientometrics,Sociology of science,Visualization},
pages = {322--327},
title = {{Scientometrics}},
url = {http://www.sciencedirect.com/science/article/pii/B9780080970868850308},
year = {2015}
}
@article{Leydesdorff2012b,
abstract = {Citation distributions are so skewed that using the mean or any other central tendency measure is ill-advised. Unlike G. Prathap's scalar measures (Energy, Exergy, and Entropy or EEE), the Integrated Impact Indicator (I3) is based on non-parametric statistics using the (100) percentiles of the distribution. Observed values can be tested against expected ones; impact can be qualified at the article level and then aggregated.},
archivePrefix = {arXiv},
arxivId = {1108.5845},
author = {Leydesdorff, Loet and Opthof, Tobias},
doi = {10.1007/s11192-011-0502-y},
eprint = {1108.5845},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leydesdorff, Opthof - 2012 - A rejoinder on energy versus impact indicators.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Citation,EEE,I3,Integration,Quality,Scalar},
number = {2},
pages = {745--748},
pmid = {22267881},
title = {{A rejoinder on energy versus impact indicators}},
volume = {90},
year = {2012}
}
@article{Li2002,
author = {Li, Wentian},
issn = {1617-8351},
journal = {Glottometrics},
pages = {14--21},
title = {{Zipf's Law everywhere}},
volume = {5},
year = {2002}
}
@article{Li2013,
abstract = {Wide differences in publication and citation practices make impossible the direct comparison of raw citation counts across scientific disciplines. Recent research has studied new and traditional normalization procedures aimed at suppressing as much as possible these disproportions in citation numbers among scientific domains. Using the recently introduced IDCP (Inequality due to Differences in Citation Practices) method, this paper rigorously tests the performance of six cited-side normalization procedures based on the Thomson Reuters classification system consisting of 172 sub-fields. We use six yearly datasets from 1980 to 2004, with widely varying citation windows from the publication year to May 2011. The main findings are the following three. Firstly, as observed in previous research, within each year the shapes of sub-field citation distributions are strikingly similar. This paves the way for several normalization procedures to perform reasonably well in reducing the effect on citation inequality of differences in citation practices. Secondly, independently of the year of publication and the length of the citation window, the effect of such differences represents about 13{\%} of total citation inequality. Thirdly, a recently introduced two-parameter normalization scheme outperforms the other normalization procedures over the entire period, reducing citation disproportions to a level very close to the minimum achievable given the data and the classification system. However, the traditional procedure of using sub-field mean citations as normalization factors yields also good results. {\textcopyright} 2013 Elsevier Ltd.},
author = {Li, Yunrong and Radicchi, Filippo and Castellano, Claudio and Ruiz-Castillo, Javier},
doi = {10.1016/j.joi.2013.06.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2013 - Quantitative evaluation of alternative field normalization procedures.pdf:pdf},
isbn = {9783200031357 (ISBN)},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Citation analysis,Citation inequality,Citation practices,Normalization procedures},
number = {3},
pages = {746--755},
publisher = {Elsevier Ltd},
title = {{Quantitative evaluation of alternative field normalization procedures}},
url = {http://dx.doi.org/10.1016/j.joi.2013.06.001},
volume = {7},
year = {2013}
}
@article{Liang2015,
abstract = {In this article we study three types of uncitedness in Library and Information Science journals: uncitedness for articles, authors and topics. One important aspect in this study is giving accurate definitions of the indicators for measuring uncited papers, uncited authors and uncited topics. It is found that for the period 1991-2010 ratios of uncited papers fluctuate within the interval [0,0.1]. This ratio is relatively stable and not very high. Comparison of average number of pages, average number of references, average number of authors per paper and percentage of single-authored papers between cited and uncited papers shows that no matter the journal, the first three indicators' values for uncited papers are lower, while the values of the fourth indicator are higher, than the corresponding values for cited papers. The fact that almost all uncited authors in a journal published only one paper in this journal illustrates that a journal's uncited authors are the least productive authors in this journal. Yet, productive and highly cited authors also publish uncited papers. As to why some topics fall into the group of uncited topics, the hypothesis is that the combination of unfamiliar keywords forms an unfamiliar topic, a topic authors have elected not to study further. Another assumption is that some uncited topics fall outside the field of Library and Information Science. Retrieval results in the Web of Science for a set of uncited keywords and keyword combinations support this assumption.},
author = {Liang, Liming and Zhong, Zhen and Rousseau, Ronald},
doi = {10.1016/j.joi.2014.11.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang, Zhong, Rousseau - 2015 - Uncited papers, uncited authors and uncited topics A case study in library and information science.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Scope of a journal,Uncited articles,Uncited authors,Uncited topics and their definitions,Uncitedness},
number = {1},
pages = {50--58},
publisher = {Elsevier Ltd},
title = {{Uncited papers, uncited authors and uncited topics: A case study in library and information science}},
url = {http://dx.doi.org/10.1016/j.joi.2014.11.001},
volume = {9},
year = {2015}
}
@article{Liu2014,
abstract = {Most current h-type indicators use only a single number to measure a scientist's productivity and impact of his/her published works. Although a single number is simple to calculate, it fails to outline his/her academic performance varying with time. We empirically study the basic h-index sequence for cumulative publications with consideration of the yearly citation performance (for convenience, referred as L-Sequence). L-Sequence consists of a series of L factors. Based on the citations received in the corresponding individual year, every factor along a scientist's career span is calculated by using the h index formula. Thus L-Sequence shows the scientist's dynamic research trajectory and provides insight into his/her scientific performance at different periods. Furthermore, L∝, summing up all factors of L-Sequence, is for the evaluation of the whole research career as alternative to other h-index variants. Importantly, the partial factors of the L-Sequence can be adapted for different evaluation tasks. Moreover, L-Sequence could be used to highlight outstanding scientists in a specific period whose research interests can be used to study the history and trends of a specific discipline.},
author = {Liu, Yu and Yang, Yongliang},
doi = {10.1016/j.joi.2014.03.002},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Yang - 2014 - Empirical study of L-Sequence The basic h-index sequence for cumulative publications with consideration of the yearly.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliometrics,Citations,H-index sequence,Research evaluation},
number = {3},
pages = {478--485},
publisher = {Elsevier Ltd},
title = {{Empirical study of L-Sequence: The basic h-index sequence for cumulative publications with consideration of the yearly citation performance}},
url = {http://www.sciencedirect.com/science/article/pii/S1751157714000303},
volume = {8},
year = {2014}
}
@article{Liu2012,
abstract = {This paper examines the relationships between the journal impact factor and the h-type indices in virology journals. The virology journals and their 2010 journal impact factors were retrieved from Journal Citation Reports. The h-index and the g-index values of the journals for 2007-2011 were obtained from Web of Science and Google Scholar. The journals were ranked by their journal impact factor and h-indices. The correlation analysis of the measures found a strong relationship between the journal impact factor and the h-type indices, and a stronger tie between the h-indices themselves. Despite the strong correlations between the measures, differences in rankings of the journals with the journal impact factor and the h-type indices were found, and possible explanations for the differences were provided.},
annote = {Library Philosophy and Practice (LPP) (ISSN 1522-0222)},
author = {Liu, Zao},
doi = {papers2://publication/uuid/CA8E7D96-F503-4048-9737-1F25E1323043},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu - 2012 - Comparing Journal Impact Factor and H-type Indices in Virology Journals.pdf:pdf},
journal = {Library Philosophy and Practice},
keywords = {citation analysis,correlation analysis,journal h indices,journal impact factor,virology journals},
title = {{Comparing Journal Impact Factor and H-type Indices in Virology Journals}},
url = {http://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=2126{\&}context=libphilprac},
volume = {891},
year = {2012}
}
@article{Lortie2013,
abstract = {Metrics of success or impact in academia may do more harm than good. To explore the value of citations, the reported efficacy of treatments in ecology and evolution from close to 1,500 publications was examined. If citation behavior is rationale, i.e. studies that successfully applied a treatment and detected greater biological effects are cited more frequently, then we predict that larger effect sizes increases study relative citation rates. This prediction was not supported. Citations are likely thus a poor proxy for the quantitative merit of a given treatment in ecology and evolutionary biology-unlike evidence-based medicine wherein the success of a drug or treatment on human health is one of the critical attributes. Impact factor of the journal is a broader metric, as one would expect, but it also unrelated to the mean effect sizes for the respective populations of publications. The interpretation by the authors of the treatment effects within each study differed depending on whether the hypothesis was supported or rejected. Significantly larger effect sizes were associated with rejection of a hypothesis. This suggests that only the most rigorous studies reporting negative results are published or that authors set a higher burden of proof in rejecting a hypothesis. The former is likely true to a major extent since only 29 {\%} of the studies rejected the hypotheses tested. These findings indicate that the use of citations to identify important papers in this specific discipline-at least in terms of designing a new experiment or contrasting treatments-is of limited value.},
author = {Lortie, Christopher J. and Aarssen, Lonnie W. and Budden, Amber E. and Leimu, Roosa},
doi = {10.1007/s11192-012-0822-6},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lortie et al. - 2013 - Do citations and impact factors relate to the real numbers in publications A case study of citation rates, impact.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Citations,Ecology,Effect size,Evolutionary biology,Hypothesis testing,Treatments},
number = {2},
pages = {675--682},
pmid = {23335827},
title = {{Do citations and impact factors relate to the real numbers in publications? A case study of citation rates, impact, and effect sizes in ecology and evolutionary biology}},
volume = {94},
year = {2013}
}
@article{Lotka1926,
author = {Lotka, Alfred J.},
issn = {0043-0439},
journal = {Journal of the Washington Academy of Sciences},
number = {16},
pages = {317--324},
title = {{The frequency distribution of scientific productivity}},
volume = {16},
year = {1926}
}
@article{Maabreh2012,
author = {Maabreh, Majdi and Alsmadi, Izzat M},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maabreh, Alsmadi - 2012 - A Survey of impact and citation indices Limitations and issues.pdf:pdf},
journal = {International Journal of Advanced Science and Technology},
keywords = {citation index,impact factor},
pages = {35--53},
title = {{A Survey of impact and citation indices: Limitations and issues}},
volume = {40},
year = {2012}
}
@phdthesis{Fakulta2006,
abstract = {Webometrics analysis is quite a young discipline. In general it is based on mathematical and statistical methods which are used for the research of information phenomena on the World Wide Web. In the initial part of the thesis there are defined the related terms and disciplines, especially from the area of bibliometrics. The study underlines close relationship to the bibliometrics, because the webometric analysis has essentially arisen from it. Following the bibliometric methods is indicated by the composition of the text. Webometric issues are discussed consequently after analogical themes of bibliometrics. This facilitates both the understanding this area and comparison of both disciplines. Next part of the thesis gives a brief introduction into the methodology of the bibliometric and webometric research. The crucial topic of this thesis deals with the recent research in the field of webometrics and shows possible future trends in this area.},
author = {Machkov{\'{a}}, Marie},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fakulta - 2006 - Sou {\v{c}} asn{\'{e}} trendy v oblasti webometrick{\'{e}} anal{\'{y}}zy.pdf:pdf},
keywords = {Journal Impact Factor,Web Impact Factor,World Wide Web,bibliometrics,cybermetrics,hypertext links,informetrics,scientometrics,trends,webometric analysis,webometrics},
pages = {114},
school = {Masarykova univerzita, Filozofick{\'{a}} fakulta},
title = {{Sou {\v{c}}asn{\'{e}} trendy v oblasti webometrick{\'{e}} anal{\'{y}}zy}},
year = {2006}
}
@article{McKerlich2013,
abstract = {(Open Nottingham OER report; survey of 51 undergraduates' use of OER.)},
archivePrefix = {arXiv},
arxivId = {0803.1716},
author = {McKerlich, Ross and Ives, Cindy and McGreal, Rory},
doi = {10.1002/asi},
eprint = {0803.1716},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McKerlich, Ives, McGreal - 2013 - Measuring use and creation of open educational resources in higher education.pdf:pdf},
isbn = {9783848215430},
issn = {14923831},
journal = {International Review of Research in Open and Distance Learning},
keywords = {OER,Open educational resources,Open learning,Open textbooks},
number = {4},
pages = {90--103},
pmid = {502955140},
title = {{Measuring use and creation of open educational resources in higher education}},
volume = {14},
year = {2013}
}
@article{Mingers2014,
author = {Mingers, John},
doi = {10.1016/j.joi.2014.09.004},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mingers - 2014 - Problems with the SNIP indicator.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
number = {4},
pages = {890--894},
title = {{Problems with the SNIP indicator}},
volume = {8},
year = {2014}
}
@article{Mingers2009,
abstract = {There is an increasing emphasis on the use of metrics for assessing the$\backslash$nresearch contribution of academics, departments, journals or$\backslash$nconferences. Contribution has two dimensions: quantity which can be$\backslash$nmeasured by number/size of the outputs, and quality which is most easily$\backslash$nmeasured by the number of citations. Recently, Hirsch proposed a new$\backslash$nmetric which is simple, combines both quality and quantity in one$\backslash$nnumber, and is robust to measurement problems. This paper applies the$\backslash$nHirsch-index (h-index) to three groups of management academics-BAM$\backslash$nFellows, INFORMS Fellows and members of COPIOR-in order to evaluate the$\backslash$nextent to which the h-index would serve as a reliable measure of the$\backslash$ncontribution of researchers in the management field. Journal of the$\backslash$nOperational Research Society (2009) 60, 1143-1153.$\backslash$ndoi:10.1057/jors.2008.94 Published online 24 September 2008},
author = {Mingers, John},
doi = {10.1057/jors.2008.94},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mingers - 2009 - Measuring the research contribution of management academics using the Hirsch-index.pdf:pdf},
isbn = {01605682},
issn = {0160-5682},
journal = {Journal of the Operational Research Society},
keywords = {Hirsch,citations,h-index,metrics,research prod},
number = {9},
pages = {1143--1153},
title = {{Measuring the research contribution of management academics using the Hirsch-index}},
volume = {60},
year = {2009}
}
@article{Mingers2015,
abstract = {Scientometrics is the study of the quantitative aspects of the process of science as a communication},
author = {Mingers, John and Leydesdorff, Loet},
doi = {10.1016/j.ejor.2015.04.002},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mingers, Leydesdorff - 2015 - A Review of Theory and Practice in Scientometrics A Review of Theory and Practice in Scientometrics 1.pdf:pdf},
journal = {European Journal of Operational Research},
keywords = {Altmetrics,Bibliometrics,Citations,H-index,Impact factor,Normalisation,Scientometrics},
number = {1934},
pages = {1--47},
title = {{A Review of Theory and Practice in Scientometrics A Review of Theory and Practice in Scientometrics 1}},
year = {2015}
}
@article{Moed2010,
author = {Moed, Henk F},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moed - 2010 - Measuring contextual citation ilnpact of scientific journals.pdf:pdf},
issn = {1751-1577},
journal = {Journal of Informetrics},
number = {3},
pages = {265--277},
title = {{Measuring contextual citation ilnpact of scientific journals}},
volume = {4},
year = {2010}
}
@article{Moed2013,
abstract = {An exploration is presented of Scopus as a data source for the study of international scientific migration or mobility for five study countries: Germany, Italy, the Netherlands, UK and USA. It is argued that Scopus author-affiliation linking and author profiling are valuable, crucial tools in the study of this phenomenon. It was found that the UK has the largest degree of outward international migration, followed by The Netherlands, and the USA the lowest. Language similarity between countries is a more important factor in international migration than it is in international co-authorship. During 1999–2010 the Netherlands showed a positive “migration balance” with the UK and a negative one with Germany, suggesting that in the Netherlands there were more Ph.D. students from Germany than there were from the UK, or that for Dutch post docs stage periods in the UK were more attractive than those in Germany. Comparison of bibliometric indicators with OECD statistics provided evidence that differences exist in the way the various study countries measured their number of researchers. The authors conclude that a bibliometric study of scientific migration using Scopus is feasible and provides significant outcomes. They make suggestions for further research. TS  - CrossRef},
author = {Moed, Henk F. and Aisati, M'hamed and Plume, Andrew},
doi = {10.1007/s11192-012-0783-9},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moed, Aisati, Plume - 2013 - Studying scientific migration in Scopus.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Author profiling,Author-affiliation links,Brain circulation,OECD input statistics,Scientific migration,Scopus},
number = {3},
pages = {929--942},
title = {{Studying scientific migration in Scopus}},
volume = {94},
year = {2013}
}
@article{Moed2016,
abstract = {A new methodology is proposed for comparing Google Scholar (GS) with other citation indexes. It focuses on the coverage and citation impact of sources, indexing speed, and data quality, including the effect of duplicate citation counts. The method compares GS with Elsevier's Scopus, and is applied to a limited set of articles published in 12 journals from six subject fields, so that its findings cannot be generalized to all journals or fields. The study is exploratory, and hypothesis generating rather than hypothesis-testing. It confirms findings on source coverage and citation impact obtained in earlier studies. The ratio of GS over Scopus citation varies across subject fields between 1.0 and 4.0, while Open Access journals in the sample show higher ratios than their non-OA counterparts. The linear correlation between GS and Scopus citation counts at the article level is high: Pearson's R is in the range of 0.8–0.9. A median Scopus indexing delay of two months compared to GS is largely though not exclusively due to missing cited references in articles in press in Scopus. The effect of double citation counts in GS due to multiple citations with identical or substantially similar meta-data occurs in less than 2{\%} of cases. Pros and cons of article-based and what is termed as concept-based citation indexes are discussed.},
archivePrefix = {arXiv},
arxivId = {1512.05741},
author = {Moed, Henk F. and Bar-Ilan, Judit and Halevi, Gali},
doi = {10.1016/j.joi.2016.04.017},
eprint = {1512.05741},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moed, Bar-Ilan, Halevi - 2016 - A new methodology for comparing Google Scholar and Scopus.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Citation counts,Document versions,Duplicate citations,Google Scholar,Indexing delay,Open Access journals,Scopus,Source coverage},
number = {2},
pages = {533--551},
publisher = {Elsevier Ltd},
title = {{A new methodology for comparing Google Scholar and Scopus}},
url = {http://www.sciencedirect.com/science/article/pii/S1751157715302285},
volume = {10},
year = {2016}
}
@article{Mongeon2016,
abstract = {Bibliometric methods are used in multiple fields for a variety of purposes, namely for research evaluation. Most bibliometric analyses have in common their data sources: Thomson Reuters' Web of Science (WoS) and Elsevier's Scopus. This research compares the journal coverage of both databases in terms of fields, countries and languages, using Ulrich's extensive periodical directory as a base for comparison. Results indicate that the use of either WoS or Scopus for research evaluation may introduces biases that favor Natural Sciences and Engineering as well as Biomedical Research to the detriment of Social Sciences and Arts and Humanities. Similarly, English-language journals are overrepresented to the detriment of other languages. While both databases share these biases, their coverage differs substantially. As a consequence, the results of bibliometric analyses may vary depending on the database used.},
archivePrefix = {arXiv},
arxivId = {1511.08096},
author = {Mongeon, Philippe and Paul-Hus, Ad??le},
doi = {10.1007/s11192-015-1765-5},
eprint = {1511.08096},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mongeon, Paul-Hus - 2016 - The journal coverage of Web of Science and Scopus a comparative analysis.pdf:pdf},
issn = {15882861},
journal = {Scientometrics},
keywords = {Bibliometrics,Citation indexes,Research evaluation,Scopus,Web of Science},
number = {1},
pages = {213--228},
title = {{The journal coverage of Web of Science and Scopus: a comparative analysis}},
volume = {106},
year = {2016}
}
@book{Nalimov1969,
address = {Moscow},
author = {Nalimov, Vasily and Mul{\v{c}}enko, Z.M.},
isbn = {5458463552},
pages = {198},
publisher = {Nauka},
title = {{Naukometrija. Izu{\v{c}}enie Razvitija Nauki kak Informacionnogo Processa. [Scientometrics. Study of the Development of Science as an Information Process]}},
year = {1969}
}
@article{Nassiri2013,
abstract = {One of the main applications of citation is to find articles that are relevant to a particular article. However, not all citations are equally relevant to the target article. This paper presents an approach to identify the most relevant citation(s). To this end, the Normalized Similarity Index (NSI) is proposed to quantify the similarity between the source and target of a citation base on the co-citations and references shared by them. To validate the method, NSI was calculated for five citation networks and was compared with the peer review grades for the relevancy between the source and the target articles. The results showed a significant correlation between the NSI ranks and those of peer review. Also, combined linkage (CL) and weighted direct citation (WDC) were calculated from the same data. According to the results of comparison between the NSI with other similarity measures, in most cases, NSI did better than others at reproducing the peer rankings. Our principal conclusion is that the NSI can be used to prioritize the citations of given highly cited article, and represent knowledge flow from the target article. ?? 2012 Elsevier Ltd.},
author = {Nassiri, Isar and Masoudi-Nejad, Ali and Jalili, Mahdi and Moeini, Ali},
doi = {10.1016/j.joi.2012.08.006},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nassiri et al. - 2013 - Normalized Similarity Index An adjusted index to prioritize article citations.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliographic coupling,Citation network,Co-citation,Similarity index,Weighted citation},
number = {1},
pages = {91--98},
publisher = {Elsevier Ltd},
title = {{Normalized Similarity Index: An adjusted index to prioritize article citations}},
url = {http://dx.doi.org/10.1016/j.joi.2012.08.006},
volume = {7},
year = {2013}
}
@article{Nicolaisen2007,
abstract = {Purpose - The purpose of this research is to examine the practical potentials of Bradford's law in relation to core-journal identification. Design/methodology/approach - Literature studies and empirical tests (Bradford analyses). Findings - Literature studies reveal that the concept of ‘subject' has never been explicitly addressed in relation to Bradford's law. The results of two empirical tests (Bradford analyses) demonstrate that different operationalizations of the concept of ‘subject' produce quite different lists of core-journals. Further, an empirical test reveals that Bradford analyses function discriminatorily against minority views. Practical implications - Bradford analysis can no longer be regarded as an objective and neutral method. The received view on Bradford's law needs to be revised. Originality/value - The paper questions one of the old dogmas of the field. [ABSTRACT FROM AUTHOR] Copyright of Journal of Documentation is the property of Emerald and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
author = {Nicolaisen, Jeppe and Hj{\o}rland, Birger and Hjorland, Birger},
doi = {10.1108/00220410710743298},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nicolaisen, Hj{\o}rland, Hjorland - 2007 - Practical potentials of Bradford's law a critical examination of the received view.pdf:pdf},
isbn = {0022-0418 U6 - ctx{\_}ver=Z39.88-2004{\&}ctx{\_}enc=info{\%}3Aofi{\%}2Fenc{\%}3AUTF-8{\&}rfr{\_}id=info:sid/summon.serialssolutions.com{\&}rft{\_}val{\_}fmt=info:ofi/fmt:kev:mtx:journal{\&}rft.genre=article{\&}rft.atitle=Practical+potentials+of+Bradford{\%}27s+law{\%}3A+a+critical+examinat(TRUNCATED)},
issn = {0022-0418},
journal = {Journal of Documentation},
keywords = {Bibliography,Bibliometrics,Documentation,INFORMATION organization,INFORMATION resources,Information Retrieval,Periodicals,Serial Publications,bibliographies,identification,information science,paper type research paper,serials},
number = {3},
pages = {359--377},
title = {{Practical potentials of Bradford's law: a critical examination of the received view}},
url = {http://www.emeraldinsight.com/10.1108/00220410710743298},
volume = {63},
year = {2007}
}
@article{Norris2010,
abstract = {Research was undertaken that examined what, if any, correlation there was between the h-index and rankings by peer assessment, and what correlation there was between the 2008 UK RAE rankings and the collective h-index of submitting departments. About 100 international scholars in Library and Information Science were ranked by their peers on the quality of their work. These rankings were correlated with the h and g scores the scholars had achieved. The results showed that there was a correlation between their median rankings and the indexes. The 2008 RAE grade point averages (GPA) achieved by departments from three UoAs - Anthropology, Library and Information Management and Pharmacy were compared with each of their collective h and g index scores. Results were mixed, with a strong correlation between pharmacy departments and index scores, followed by library and information management to anthropology where negative and non-significant results were found. Taken together, the findings from the research indicate that individual ranking by peer assessment and their h-index or variants was generally good. Results for the RAE 2008 gave correlations between GPA and successive versions of the h-index which varied in strength, except for anthropology where, it is suggested detailed cited reference searches must be undertaken to maximise citation counts. ?? 2009 Charles Oppenheim.},
author = {Norris, Michael and Oppenheim, Charles},
doi = {10.1016/j.joi.2009.11.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Norris, Oppenheim - 2010 - Peer review and the h-index Two studies.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Anthropology,G-index,H-index,Library and information management,Pharmacy,Research assessment exercise},
number = {3},
pages = {221--232},
publisher = {Elsevier Ltd},
title = {{Peer review and the h-index: Two studies}},
url = {http://dx.doi.org/10.1016/j.joi.2009.11.001},
volume = {4},
year = {2010}
}
@article{O???Leary2015,
abstract = {Bibliometr{\'{i}}a se utilizan a menudo como indicadores clave en la evaluaci{\'{o}}n de los grupos acad{\'{e}}micos e investigadores en la investigaci{\'{o}}n biom{\'{e}}dica. Estad{\'{i}}sticas de citas, cuando se utilizan como indicadores de rendimiento de la investigaci{\'{o}}n, requieren la evaluaci{\'{o}}n comparativa exacta para grupos homog{\'{e}}neos. Este estudio describe el rendimiento de la investigaci{\'{o}}n de los departamentos acad{\'{e}}micos en la Universidad de la Facultad de Medicina de Toronto utilizando bibliometr{\'{i}}a a nivel de art{\'{i}}culo para trabajos cient{\'{i}}ficos publicados entre 2008 y 2012. publicaciones elegibles de todos los miembros de la facultad acad{\'{e}}micos fueron verificados desde el curriculum vitae de cada investigador y Web of Science {\textregistered} (Thomson Reuters). Para 3792 los investigadores, se identificaron 26.845 documentos {\'{u}}nicos con 79,502 autores publicados entre 2008 y 2012. Las citas medios globales por el papel de la facultad fue 17.35. Los departamentos acad{\'{e}}micos con los m{\'{a}}s altos niveles de colaboraci{\'{o}}n y actividad de investigaci{\'{o}}n interdisciplinaria tambi{\'{e}}n tuvieron el mayor impacto de la investigaci{\'{o}}n. La ventana de citaci{\'{o}}n para trabajos cient{\'{i}}ficos biom{\'{e}}dicos segu{\'{i}}a activo a los 5 a{\~{n}}os despu{\'{e}}s de la publicaci{\'{o}}n, lo que indica que la ventana de la citaci{\'{o}}n de las publicaciones en la investigaci{\'{o}}n biom{\'{e}}dica est{\'{a}} activo ya que se pensaba anteriormente, y esto puede dificultar el uso fiable de la bibliometr{\'{i}}a en la evaluaci{\'{o}}n de las publicaciones cient{\'{i}}ficas recientes en la investigaci{\'{o}}n biom{\'{e}}dica .},
author = {O???Leary, James D. and Crawford, Mark W. and Jurczyk, Eva and Buchan, Alison},
doi = {10.1007/s11192-015-1676-5},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/OLeary et al. - 2015 - Benchmarking bibliometrics in biomedical research research performance of the University of Torontos Faculty of M.pdf:pdf},
issn = {01389130},
journal = {Scientometrics},
keywords = {Benchmarking,Biomedical research,Citation window,Research impact,Research productivity},
number = {1},
pages = {311--321},
publisher = {Springer Netherlands},
title = {{Benchmarking bibliometrics in biomedical research: research performance of the University of Toronto???s Faculty of Medicine, 2008???2012}},
url = {"http://dx.doi.org/10.1007/s11192-015-1676-5},
volume = {105},
year = {2015}
}
@book{Ondrisova2011,
address = {Bratislava, Slovakia},
author = {Ondri{\v{s}}ov{\'{a}}, Miriam},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ondri{\v{s}}ov{\'{a}} - Unknown - Bibliometria.pdf:pdf},
isbn = {9788081270352},
pages = {134},
publisher = {STIMUL},
title = {{Bibliometria}},
year = {2011}
}
@article{Ouimet2011,
abstract = {This exploratory study aims at answering the following research question: Are the h-index and some of its derivatives discriminatory when applied to rank social scientists with different epistemological beliefs and methodological preferences? This study reports the results of five Tobit and two negative binomial regression models taking as dependent variable the h-index and six of its derivatives, using a dataset combining bibliometric data collected with the PoP software with cross-sectional data of 321 Quebec social scientists in Anthropology, Sociology, Social Work, Political Science, Economics and Psychology. The results reveal an epistemological/methodological effect making positivists and quantitativists globally more productive than constructivists and qualitativists.},
author = {Ouimet, Mathieu and B??dard, Pierre Olivier and G??lineau, Fran??ois},
doi = {10.1007/s11192-011-0364-3},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ouimet, Bdard, Glineau - 2011 - Are the h-index and some of its alternatives discriminatory of epistemological beliefs and methodologica.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Cross-sectional survey,Epistemology,Google Scholar,Individual researchers,Publish or Perish,Research performance,Social sciences,h-index},
number = {1},
pages = {91--106},
pmid = {21765564},
title = {{Are the h-index and some of its alternatives discriminatory of epistemological beliefs and methodological preferences of faculty members? The case of social scientists in Quebec}},
volume = {88},
year = {2011}
}
@phdthesis{Pacakova2014,
abstract = {Bachelor's thesis „citation analysis - overview study“ deals with method of citation analysis and its evolution during the history, practical side of citation analysis, its metods, tools, (for example Scopus a Web of Science) and options of real use, which it gives us. Thesis is theoretical. The aim of the thesis is to present method of citation analysis and evaluate its benefits. Conclusions are telling how is the citation analysis useful.},
author = {Pac{\'{a}}kov{\'{a}}, Jana},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pac{\'{a}}kov{\'{a}} - 2014 - Bakal{\'{a}}řsk{\'{a}} pr{\'{a}}ce Cita{\v{c}}n{\'{i}} anal{\'{y}}za – přehledov{\'{a}} studie.pdf:pdf},
pages = {76},
school = {Masarykova univerzita},
title = {{Bakal{\'{a}}řsk{\'{a}} pr{\'{a}}ce Cita{\v{c}}n{\'{i}} anal{\'{y}}za – přehledov{\'{a}} studie}},
year = {2014}
}
@article{Panaretos2009,
abstract = {Abstract  We provide a comprehensive and critical review of the h-index and its most important modifications proposed in the literature, as well as of other similar indicators measuring research output and impact. Extensions of some of these indices are presented and illustrated.},
archivePrefix = {arXiv},
arxivId = {0812.4542},
author = {Panaretos, John and Malesios, Chrisovaladis},
doi = {10.1007/s11192-008-2174-9},
eprint = {0812.4542},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Panaretos, Malesios - 2009 - Assessing scientific research performance and impact with single indices.pdf:pdf},
isbn = {0138-9130$\backslash$r1588-2861},
issn = {01389130},
journal = {Scientometrics},
number = {3},
pages = {635--670},
title = {{Assessing scientific research performance and impact with single indices}},
volume = {81},
year = {2009}
}
@article{Paolucci2014,
abstract = {Peer review works as the hinge of the scientific process, mediating between research and the awareness/acceptance of its results. While it might seem obvious that science would regulate itself scientifically, the consensus on peer review is eroding; a deeper understanding of its workings and potential alternatives is sorely needed. Employing a theoretical approach supported by agent-based simulation, we examined computational models of peer review, performing what we propose to call redesign, that is, the replication of simulations using different mechanisms. Here, we show that we are able to obtain the high sensitivity to rational cheating that is present in literature. In addition, we also show how this result appears to be fragile against small variations in mechanisms. Therefore, we argue that exploration of the parameter space is not enough if we want to support theoretical statements with simulation, and that exploration at the level of mechanisms is needed. These findings also support prudence in the application of simulation results based on single mechanisms, and endorse the use of complex agent platforms that encourage experimentation of diverse mechanisms.},
author = {Paolucci, Mario and Grimaldo, Francisco},
doi = {10.1007/s11192-014-1239-1},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paolucci, Grimaldo - 2014 - Mechanism change in a simulation of peer review From junk support to elitism.pdf:pdf},
issn = {01389130},
journal = {Scientometrics},
keywords = {Agent-based simulation,BDI approach,Mechanism change,Peer review,Rational cheating,Restrained cheaters},
number = {3},
pages = {663--688},
pmid = {24829514},
title = {{Mechanism change in a simulation of peer review: From junk support to elitism}},
volume = {99},
year = {2014}
}
@article{Parolo2015,
abstract = {The exponential growth in the number of scientific papers makes it increasingly difficult for researchers to keep track of all the publications relevant to their work. Consequently, the attention that can be devoted to individual papers, measured by their citation counts, is bound to decay rapidly. In this work we make a thorough study of the life-cycle of papers in different disciplines. Typically, the citation rate of a paper increases up to a few years after its publication, reaches a peak and then decreases rapidly. This decay can be described by an exponential or a power law behavior, as in ultradiffusive processes, with exponential fitting better than power law for the majority of cases. The decay is also becoming faster over the years, signaling that nowadays papers are forgotten more quickly. However, when time is counted in terms of the number of published papers, the rate of decay of citations is fairly independent of the period considered. This indicates that the attention of scholars depends on the number of published items, and not on real time.},
archivePrefix = {arXiv},
arxivId = {1503.01881},
author = {Parolo, Pietro Della Briotta and Pan, Raj Kumar and Ghosh, Rumi and Huberman, Bernardo A. and Kaski, Kimmo and Fortunato, Santo},
doi = {10.1016/j.joi.2015.07.006},
eprint = {1503.01881},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parolo et al. - 2015 - Attention decay in science.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Citation count,Decay of attention,Time evolution},
number = {4},
pages = {734--745},
publisher = {Elsevier Ltd},
title = {{Attention decay in science}},
url = {http://dx.doi.org/10.1016/j.joi.2015.07.006},
volume = {9},
year = {2015}
}
@article{PereiraDeAraujo2008,
abstract = {We investigate possible effects from a strong encouragement for a large$\backslash$nnumber of publications on the scientific production of a Brazilian cell$\backslash$nbiology department. An average increase in individual absolute$\backslash$nproduction and a concomitant decrease in individual participation in$\backslash$neach paper were detected by traditional bibliometric parameters, such as$\backslash$nnumber of publications, citations, impact factors and h index, combined$\backslash$nto their ``effective{\{}''{\}} versions, in which co-authorship is taken into$\backslash$nconsideration. The observed situation, which might well represent a$\backslash$nnational trend, should be considered as a strong wanting against current$\backslash$ncriteria of scientific evaluation heavily based on uncritical counting$\backslash$nof publications.},
author = {{Pereira De Ara{\'{u}}jo}, Ant{\^{o}}nio F.},
doi = {10.1007/s11192-007-1817-6},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pereira De Ara{\'{u}}jo - 2008 - Increasing discrepancy between absolute and effective indexes of research output in a Brazilian academic dep.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {3},
pages = {425--437},
pmid = {32932359},
title = {{Increasing discrepancy between absolute and effective indexes of research output in a Brazilian academic department}},
volume = {74},
year = {2008}
}
@article{Perianes-Rodr??guez2009,
abstract = {Governmental initiatives around scientific policy have progressively raised collaboration to priority status. In this context, a need has arisen to broaden the traditional approach to the analysis and study of research results by descending to the group or even the individual scale and supplementing the output-, productivity-, visibility- and impact-based focus with new measures that emphasize collaboration from the vantage of structural analysis. To this end, the present paper proposes new hybrid indicators for the analysis and evaluation of individual research results, popularity and prestige, that combine bibliometric and structural aspects. A case study was conducted of the nine most productive departments in Carlos III University of Madrid. The findings showed hybridization to be a tool sensitive to traditional indicators, but also to the new demands of modern science as a self-organized system of interaction among individuals, furnishing information on researchers' environments and the behaviour and attitudes adopted within those environments. ?? 2008 Elsevier Ltd. All rights reserved.},
author = {Perianes-Rodr{\'{i}}guez, Antonio and Chinchilla-Rodr{\'{i}}guez, Zaida and Vargas-Quesada, Benjam{\'{i}}n and {Olmeda G{\'{o}}mez}, Carlos and Moya-Aneg{\'{o}}n, F{\'{e}}lix},
doi = {10.1016/j.joi.2008.12.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perianes-Rodrguez et al. - 2009 - Synthetic hybrid indicators based on scientific collaboration to quantify and evaluate individual rese.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliometric analysis,Hybrid indicators,Network analysis,Scientific collaboration},
number = {2},
pages = {91--101},
title = {{Synthetic hybrid indicators based on scientific collaboration to quantify and evaluate individual research results}},
volume = {3},
year = {2009}
}
@article{Perianes-Rodriguez2014,
abstract = {In the social sciences, university departments are the governance units$\backslash$nwhere the demand for and the supply of researchers interact. As a first$\backslash$nstep towards a formal model of this process, this paper investigates the$\backslash$ncharacteristics of productivity distributions in a unique dataset$\backslash$nconsisting of 2,530 faculty members with at least one publication who$\backslash$nwere working in the 81 top world Economics departments in 2007.$\backslash$nIndividual productivity is measured in two ways: as the number of$\backslash$npublications up to 2007, and as a quality index that weights differently$\backslash$nthe articles published in four journal equivalent classes. The academic$\backslash$nage of individuals, measured as the number of years since obtaining a$\backslash$nPh.D. up to 2007, is used to measure productivity per year.$\backslash$nIndependently of the two productivity measures, and both before and$\backslash$nafter age normalization, the five main findings of the paper are the$\backslash$nfollowing. Firstly, individuals within each department have very$\backslash$ndifferent productivities. Secondly, there is not a single pattern of$\backslash$nproductivity inequality and skewness at the department level. On the$\backslash$ncontrary, productivity distributions are very different across$\backslash$ndepartments. Thirdly, the effect on overall productivity inequality of$\backslash$ndifferences in productivity distributions between departments is greater$\backslash$nthan the analogous effect in other contexts. Fourth, to a large extent,$\backslash$nthis effect on overall productivity inequality is accounted for by scale$\backslash$nfactors well captured by departments' mean productivities. Fifth, this$\backslash$nhigh degree of departmental heterogeneity is found to be compatible with$\backslash$ngreater homogeneity across the members of a partition of the sample into$\backslash$nseven countries and a residual category.},
author = {Perianes-Rodriguez, Antonio and Ruiz-Castillo, Javier},
doi = {10.1007/s11192-014-1449-6},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perianes-Rodriguez, Ruiz-Castillo - 2014 - Within- and between-department variability in individual productivity the case of economics.pdf:pdf},
isbn = {978-90-817527-1-8},
issn = {01389130},
journal = {Scientometrics},
keywords = {Academic age,Economics departments,Scientific productivity distributions,Within- and between-group variability},
number = {2},
pages = {1497--1520},
title = {{Within- and between-department variability in individual productivity: the case of economics}},
volume = {102},
year = {2014}
}
@article{Perme2012,
abstract = {Evaluating the performance of institutions with different resources is not easy, any citation distribution comparisons are strongly affected by the differences in the number of articles published. The paper introduces a method for comparing citation distributions of research groups that differ in size. The citation distribution of a larger group is reduced by a certain factor and compared with the original distribution of a smaller group. Expected values and tolerance intervals of the reduced set of citations are calculated. A comparison of both distributions can be conveniently viewed in a graph. The size-independent reduced Hirsch index - a function of reducing factor that allows the comparison of groups within a scientific field - is calculated in the same way. The method can be used for comparing groups or units differing in full-time equivalent, funding or the number of researchers, for comparing countries by population, gross domestic product, etc. It is shown that for the calculation of the reduced Hirsch index, the upper part of the original citation distribution is sufficient. The method is illustrated through several case comparisons. {\textcopyright} 2012 Elsevier Ltd.},
author = {Perme, Maja Pohar and Stare, Janez and {\v{Z}}aucer, Rok and {\v{Z}}aucer, Matja{\v{z}}},
doi = {10.1016/j.joi.2012.07.007},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perme et al. - 2012 - Comparison of the citation distribution and h-index between groups of different sizes.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Citation distribution,Probability formulae,Reduced Hirsch index,Research performance,Size-independent comparison,Stochastic method},
number = {4},
pages = {712--720},
title = {{Comparison of the citation distribution and h-index between groups of different sizes}},
volume = {6},
year = {2012}
}
@article{Pinto2007,
abstract = {This work explores Social Networks map generation in the area of the Metric Studies,$\backslash$nBibliometry and Scientometry. This kind of map show (i) index of co-authors by area$\backslash$nISI, (ii) comparative of the documentary typology of registries source by citation, (iii)$\backslash$nwhich authors have made the biggest scientific contribution, (iv) authors which have$\backslash$nthe biggest citation, (v) the documents more mentioned and (vi) the more relevant$\backslash$nmagazines related to the information consumption. The evaluation had been$\backslash$nmodeled by centrality and frequency, inquired amongst 635 registers rescued on the$\backslash$nthematic. The main registers source has been the packages of the Institute for$\backslash$nScientific Information (Science Citation Index, Social Science Citation Index and Arts$\backslash$n{\&} Humanities), and the studied period goes from 1975 to 2005. To realize the data$\backslash$ntreatment we used CiteSpace application, which has given the relation maps, a$\backslash$nmethodology of documentary control, developed by Efrain-Garc{\'{i}}a.},
annote = {ISSN-e: 1981-1640},
author = {Pinto, Adilson Luiz and Efrain-Garc{\'{i}}a, Preiddy and {Rodr{\'{i}}guez Barqu{\'{i}}n}, Beatriz Ainhize and {Moreira Gonz{\'{a}}lez}, Jos{\'{e}} Antonio},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pinto et al. - 2007 - Scientific Indicators on Literature in Bibliometry and Scientometry Through Social Networks.pdf:pdf},
journal = {Brazilian Journal of Information Science},
number = {1},
pages = {55--73},
title = {{Scientific Indicators on Literature in Bibliometry and Scientometry Through Social Networks}},
volume = {1},
year = {2007}
}
@inproceedings{Powers1998,
abstract = {Recently I have been intrigued by the reappearance of an old friend, George Kingsley Zipf, in a number of not entirely expected places. The law named for him is ubiquitous, but Zipf did not actually discover the law so much as provide a plausible explanation. Others have proposed modifications to Zipf's Law, and closer examination uncovers systematic deviations from its normative form. We demonstrate how Zipf's analysis can be extended to include some of these phenomena.},
address = {Stroudsburg, PA, USA},
author = {Powers, David M W},
booktitle = {NeMLaP3/CoNLL '98 Proceedings of the Joint Conferences on New Methods in Language Processing and Computational Natural Language Learning},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Powers - 1998 - l.pdf:pdf},
pages = {151--160},
publisher = {Association for Computational Linguistics},
title = {{Applications and Explanations of Zipf's Law}},
year = {1998}
}
@article{Prathap2010,
abstract = {The h-index has captured the imagination of scientometricians and bibliometricians to such an extent that one can now divide the history of the subject virtually into a pre-Hirsch and a post-Hirsch period. Beyond its academic value, it is now used as a tool for research assessment of individuals, research faculties and institutions and even for comparing performance of journals and countries. Since its introduction, many Hirsch-type variants have been proposed to overcome perceived limitations of the original index. In this paper, using ideas from mathematical modeling, another mock h-index is proposed which may complement the h-index and give it better resolving power.},
author = {Prathap, Gangan},
doi = {10.1007/s11192-009-0066-2},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prathap - 2010 - Is there a place for a mock h-index.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Bibliometrics,Corrected quality ratio,Mock h-index,h-index},
number = {1},
pages = {153--165},
title = {{Is there a place for a mock h-index?}},
volume = {84},
year = {2010}
}
@article{Pritchard1969,
author = {Pritchard, Alan},
issn = {0022-0418},
journal = {Journal of Documentation},
pages = {348--349},
title = {{Statistical bibliography or bibliometrics?}},
volume = {25},
year = {1969}
}
@article{Radicchi2012,
abstract = {Citation numbers are extensively used for assessing the quality of scientific research. The use of raw citation counts is generally misleading, especially when applied to cross-disciplinary comparisons, since the average number of citations received is strongly dependent on the scientific discipline of reference of the paper. Measuring and eliminating biases in citation patterns is crucial for a fair use of citation numbers. Several numerical indicators have been introduced with this aim, but so far a specific statistical test for estimating the fairness of these numerical indicators has not been developed. Here we present a statistical method aimed at estimating the effectiveness of numerical indicators in the suppression of citation biases. The method is simple to implement and can be easily generalized to various scenarios. As a practical example we test, in a controlled case, the fairness of fractional citation count, which has been recently proposed as a tool for cross-discipline comparison. We show that this indicator is not able to remove biases in citation patterns and performs much worse than the rescaling of citation counts with average values. ?? 2011 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {1111.6053},
author = {Radicchi, Filippo and Castellano, Claudio},
doi = {10.1016/j.joi.2011.09.002},
eprint = {1111.6053},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radicchi, Castellano - 2012 - Testing the fairness of citation indicators for comparison across scientific domains The case of fractiona.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Citation analysis,Cross-disciplinary comparisons,Normalized citation indicators},
number = {1},
pages = {121--130},
publisher = {Elsevier Ltd},
title = {{Testing the fairness of citation indicators for comparison across scientific domains: The case of fractional citation counts}},
url = {http://dx.doi.org/10.1016/j.joi.2011.09.002},
volume = {6},
year = {2012}
}
@article{Radicchi2008,
abstract = {We study the distributions of citations received by a single publication within several disciplines, spanning broad areas of science. We show that the probability that an article is cited c times has large variations between different disciplines, but all distributions are rescaled on a universal curve when the relative indicator c(f) = c/c(0) is considered, where c(0) is the average number of citations per article for the discipline. In addition we show that the same universal behavior occurs when citation distributions of articles published in the same field, but in different years, are compared. These findings provide a strong validation of c(f) as an unbiased indicator for citation performance across disciplines and years. Based on this indicator, we introduce a generalization of the h index suitable for comparing scientists working in different fields.},
archivePrefix = {arXiv},
arxivId = {0806.0974},
author = {Radicchi, Filippo and Fortunato, Santo and Castellano, Claudio},
doi = {10.1073/pnas.0806977105},
eprint = {0806.0974},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radicchi, Fortunato, Castellano - 2008 - Universality of citation distributions toward an objective measure of scientific impact.pdf:pdf},
isbn = {1091-6490 (Electronic)$\backslash$r0027-8424 (Linking)},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Interdisciplinary Communication,Journal Impact Factor,Models,Selection Bias,Theoretical},
number = {45},
pages = {17268--72},
pmid = {18978030},
title = {{Universality of citation distributions: toward an objective measure of scientific impact.}},
url = {http://www.pnas.org/content/early/2008/10/30/0806977105},
volume = {105},
year = {2008}
}
@article{Radosevic2014,
abstract = {This paper explores the changing role of world regions (North America, EU15, South EU, Central and Eastern Europe (CEE), Former-USSR, Latin America, Asia Pacific and the Middle East) in science from 1981 to 2011. We use bibliometric data extracted from Thomson Reuter's National Science Indicators (2011) for 21 broad disciplines, and aggregated the data into the four major science areas: life, fundamental, applied and social sciences. Comparing three sub-periods (1981-1989, 1990-2000 and 2001-2011), we investigate (i) over time changes in descriptive indicators such as publications, citations, and relative impact; (ii) static specialization measured by revealed comparative advantage (RCA) in citations and papers; and (iii) dynamic specialization measured by absolute growth in papers. Descriptive results show a global shift in science largely in quantity (papers) and much less in impact (citations). We argue this should be interpreted as a shift in science's absorptive capacity but not necessarily a shift of knowledge generation at the world science frontier, which reflects the nature of science systems operating with high inertia and path dependency in areas of their historically inherited advantages and disadvantages. In view of their common historical legacy in science we are particularly interested in the process of convergence/divergence of the catching-up/transition regions with the world frontier regions. We implement an interpretative framework to compare regions in terms of their static and dynamic specialization from 1981-1989 to 2001-2011. Again, our analysis shows that while science systems are mostly characterised by strong inertia and historically inherited (dis)advantages, Asia Pacific, Latin America and CEE show strong catching-up characteristics but largely in the absorptive capacity of science. {\textcopyright} 2014 The Author(s).},
author = {Radosevic, Slavo and Yoruk, Esin},
doi = {10.1007/s11192-014-1344-1},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radosevic, Yoruk - 2014 - Are there global shifts in the world science base Analysing the catching up and falling behind of world region.pdf:pdf},
isbn = {01389130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Absorptive capacity in science base,Bibliometrics,Dynamic scientific specialization,Revealed comparative advantage,Static scientific specialization,World regions},
number = {3},
pages = {1897--1924},
pmid = {25411515},
title = {{Are there global shifts in the world science base? Analysing the catching up and falling behind of world regions}},
volume = {101},
year = {2014}
}
@article{Raghuraman2010,
abstract = {We have carried out a three-part study comparing the research performance of Indian institutions with that of other international institutions. In the first part, the publication profiles of various Indian institutions were examined and ranked based on the h-index and p-index. We found that the institutions of national importance contributed the highest in terms of publications and citations per institution. In the second part of the study, we looked at the publication profiles of various Indian institutions in the high-impact journals and compared these profiles against that of the top Asian and US universities. We found that the number of papers in these journals from India was miniscule compared to the US universities. Recognizing that the publication profiles of various institutions depend on the field/departments, we studied the publication profiles of many science and engineering departments at the Indian Institute of Science (IISc), Bangalore, the Indian Institutes of Technology, as well as top Indian universities. Because the number of faculty in each department varies widely, we have computed the publications and citations per faculty per year for each department. We have also compared this with other departments in various Asian and US universities. We found that the top Indian institution based on various parameters in various disciplines was IISc, but overall even the top Indian institutions do not compare favourably with the top US or Asian universities.},
author = {Raghuraman, K. P. and Chander, Romesh and Madras, Giridhar},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raghuraman, Chander, Madras - 2010 - Scientometric analysis of some disciplines Comparison of Indian institutions with other internation.pdf:pdf},
isbn = {0011-3891},
issn = {00113891},
journal = {Current Science},
keywords = {Indian and international institutions,Publications,Research performance,Scientometric analysis},
number = {5},
pages = {577--587},
title = {{Scientometric analysis of some disciplines: Comparison of Indian institutions with other international institutions}},
volume = {99},
year = {2010}
}
@article{Randic2009,
abstract = {It appears popular, particularly among science administrators, to use$\backslash$ncitations and various citation measures for ranking scientists, as if$\backslash$nsuch exercises would reflect the scientific potential of the persons$\backslash$nconsidered. In recent time the Hirsch index h in particular has obtained$\backslash$nvisibility in this respect in view of its simplicity. We consider a$\backslash$npossible extension of the concept of selective citations, which in fact$\backslash$nis innate to the h index, and propose a simple generalization, indices H$\backslash$nand Q, which to a degree supplement the information accompanying the$\backslash$nevaluation of h. The H index keeps record of the ``history{\{}''{\}} of$\backslash$ncitations and the quotient Q = H/h is a measure for the quality of a$\backslash$nscientist based on the history of his/her citations.},
author = {Randi{\'{c}}, Milan},
doi = {10.1007/s11192-008-2128-2},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Randi{\'{c}} - 2009 - Citations versus limitations of citations Beyond hirsch index.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {3},
pages = {809--818},
title = {{Citations versus limitations of citations: Beyond hirsch index}},
volume = {80},
year = {2009}
}
@book{Rehak2013,
address = {Ostrava},
author = {Řeh{\'{a}}k, David and {\v{S}}enovsk{\'{y}}, Pavel},
edition = {Fist Editi},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Melorose, Perroy, Careas - 2015 - No Title No Title.pdf:pdf},
isbn = {978-80-248-3252-4},
keywords = {Mobile,Named entity disambiguation,Natural language processing,News,Recommender system},
pages = {111},
publisher = {Vyskok{\'{a}} {\v{s}}kola b{\'{a}}ňsk{\'{a}} - Technick{\'{a}} univerzita Ostrava},
title = {{Průvodce v{\v{e}}dou a v{\'{y}}zkumem (nejen) pro studenty doktorsk{\'{e}}ho studia}},
url = {http://arl.uhk.cz/arl-hk/m-cs/detail-hk{\_}us{\_}cat-0035351-Pruvodce-vedou-a-vyzkumem-nejen-pro-studenty-doktorskeho-studia/},
year = {2013}
}
@article{Repanovici2010,
abstract = {Open access to scientific information can transform the world information. The research presented here measures the visibility and the impact of the university's scientific production of the Transilvania University of Brasov using the scientific methods of scientometry. These methods provide a means for determining the international value of an university and the statistical evaluation of an individual's scientific research results. In this paper, we define the scientific production and productivity, and present the main indicators for the measurement of the scientific activity. The impact of the research is measured and analyzed through citation analysis. The number of citations suggests the quality of the scientific information. Google Scholar, a freely available scientometric database, indexes academic papers from open access repositories and commercial sources, and also identifies referenced citations. The free Publish or Perish software can be used as an analysis instrument for the impact of the research. We present an exploratory study made at the Transilvania University of Brasov to evaluate the research output of the faculty. We analyzed their 2008 research performances as documented in their annual evaluation that states the number of papers, books, and research contracts. Using Publish or Perish, we calculated the H-index, G-index, HC-index and HI norm, of the 60 more productive professors. We present correlation indicators and discuss the importance of open access tools and repositories for increasing the impact of scientific research.},
author = {Repanovici, Angela},
doi = {10.1108/14678041111149345},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Repanovici - 2010 - Measuring the visibility of the University's scientific production using GoogleScholar, Publish or Perish software a.pdf:pdf},
isbn = {0024253081},
issn = {1467-8047},
journal = {Science and Technology Libraries},
keywords = {H-index,citations,institutional repository,open access,scientific research,scientometric indicators},
pages = {1--14},
title = {{Measuring the visibility of the University's scientific production using GoogleScholar, "Publish or Perish" software and Scientometrics}},
year = {2010}
}
@misc{Reuters2008,
abstract = {A library faced with collection decisions, a foundation making funding choices, or a goverment office weighing national research needs must rely on expert analysis of scientific research performance},
author = {Reuters, Thomson},
booktitle = {Thomson Reuters},
doi = {10.1097/NCN.0b013e31819ec9ac},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reuters - 2008 - Whitepaper Using Bibliometrics.pdf:pdf},
isbn = {0305-1862},
issn = {1538-2931},
pages = {12},
title = {{Whitepaper Using Bibliometrics :}},
year = {2008}
}
@phdthesis{Richterova2012,
abstract = {The Bachelor's Diploma Thesis ‚Citation Analysis of Dissertations written by Graduates of LIS Department at Masaryk University Brno‘ deals with information sources used by students of Library and Information Studies to write their theses. The theoretical part defines terms related to the citation, bibliographic records and mathematical-statistical methods used in the field of library science. Practical part is then performed citation analysis of barchelor‘s and master's works, created by students of the field. It aims to analyze the sources from which students come to identify literature that is core in the field of Information and Library Studies.},
author = {Richterov{\'{a}}, Monika},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Richterov{\'{a}} - 2012 - Bakal{\'{a}}řsk{\'{a}} diplomov{\'{a}} pr{\'{a}}ce.pdf:pdf},
keywords = {Citation analysis,Library and Information Science Department.,bibliography,bibliometrics,citation behavior,citation index,citation record,ethics of citation practices,information sources,mathematical and statistical methods,theses},
pages = {71},
school = {Masarykova univerzita, Filozofick{\'{a}} fakulta},
title = {{Cita{\v{c}}n{\'{i}} anal{\'{y}}za z{\'{a}}v{\v{e}}re{\v{c}}n{\'{y}}ch prac{\'{i}} na KISK FF MU Brno}},
year = {2012}
}
@article{Ricker2015,
abstract = {Academic evaluation committees have been increasingly receptive for$\backslash$nusing the number of published indexed articles, as well as citations, to$\backslash$nevaluate the performance of scientists. It is, however, impossible to$\backslash$ndevelop a stand-alone, objective numerical algorithm for the evaluation$\backslash$nof academic activities, because any evaluation necessarily includes$\backslash$nsubjective preference statements. In a market, the market prices$\backslash$nrepresent preference statements, but scientists work largely in a$\backslash$nnon-market context. I propose a numerical algorithm that serves to$\backslash$ndetermine the distribution of reward money in Mexico's evaluation$\backslash$nsystem, which uses relative prices of scientific goods and services as$\backslash$ninput. The relative prices would be determined by an evaluation$\backslash$ncommittee. In this way, large evaluation systems (like Mexico's Sistema$\backslash$nNacional de Investigadores) could work semi-automatically, but not$\backslash$narbitrarily or superficially, to determine quantitatively the academic$\backslash$nperformance of scientists every few years. Data of 73 scientists from$\backslash$nthe Biology Institute of Mexico's National University are analyzed, and$\backslash$nit is shown that the reward assignation and academic priorities depend$\backslash$nheavily on those preferences. A maximum number of products or activities$\backslash$nto be evaluated is recommended, to encourage quality over quantity.},
author = {Ricker, Martin},
doi = {10.1007/s11192-014-1521-2},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ricker - 2015 - A numerical algorithm with preference statements to evaluate the performance of scientists.pdf:pdf},
isbn = {1119201415212},
issn = {01389130},
journal = {Scientometrics},
keywords = {Academic evaluation,Evaluation committee,Scientists??? value,Sistema Nacional de Investigadores (Mexico),UNAM???s PRIDE (Mexico)},
number = {1},
pages = {191--212},
title = {{A numerical algorithm with preference statements to evaluate the performance of scientists}},
volume = {103},
year = {2015}
}
@article{Rigby2013,
abstract = {A small number of studies have sought to establish that research papers with more funding acknowledgements achieve higher impact and have claimed that such a link exists because research supported by more funding bodies undergoes more peer review. In this paper, a test of this link is made using recently available data from the Web of Science, a source of bibliographic data that now includes funding acknowledgements. The analysis uses 3,596 papers from a single year, 2009, and a single journal, the Journal of Biological Chemistry. Analysis of this data using OLS regression and two ranks tests reveals the link between count of funding acknowledgements and high impact papers to be statistically significant, but weak. It is concluded that count of funding acknowledgements should not be considered a reliable indicator of research impact at this level. Relatedly, indicators based on assumptions that may hold true at one level of analysis may not be appropriate at other levels.},
author = {Rigby, John},
doi = {10.1007/s11192-012-0779-5},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rigby - 2013 - Looking for the impact of peer review Does count of funding acknowledgements really predict research impact.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Funding acknowledgements,Indicators,Log transformation,Peer review,Regression},
number = {1},
pages = {57--73},
pmid = {23704798},
title = {{Looking for the impact of peer review: Does count of funding acknowledgements really predict research impact?}},
volume = {94},
year = {2013}
}
@article{Rousseau2013,
abstract = {Hypes occur in every domain of human behavior, including scientific research. We show in this contribution that journals and authors who studied the h-index benefited in terms of short-term citations. As, moreover, the introduction of the h-index is more a 'clever find' than a first rate intellectual achievement, its rise can be compared to a stock market bubble. ?? 2012 Elsevier Ltd.},
author = {Rousseau, Ronald and Garc{\'{i}}a-Zorita, Carlos and Sanz-Casado, Elias},
doi = {10.1016/j.joi.2012.11.012},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rousseau, Garca-Zorita, Sanz-Casado - 2013 - The h-bubble.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {H-Index,Hypes,Information science journals and researchers,Over-citation},
number = {2},
pages = {294--300},
title = {{The h-bubble}},
volume = {7},
year = {2013}
}
@article{Ruiz-Castillo2015,
abstract = {We study the problem of normalizing citation impact indicators for differences in citation practices across scientific fields. Normalization of citation impact indicators is usually done based on a field classification system. In practice, the Web of Science journal subject categories are often used for this purpose. However, many of these subject categories have a quite broad scope and are not sufficiently homogeneous in terms of citation practices. As an alternative, we propose to work with algorithmically constructed classification systems. We construct these classification systems by performing a large-scale clustering of publications based on their citation relations. In our analysis, 12 classification systems are constructed, each at a different granularity level. The number of fields in these systems ranges from 390 to 73,205 in granularity levels 1-12. This contrasts with the 236 subject categories in the WoS classification system. Based on an investigation of some key characteristics of the 12 classification systems, we argue that working with a few thousand fields may be an optimal choice. We then study the effect of the choice of a classification system on the citation impact of the 500 universities included in the 2013 edition of the CWTS Leiden Ranking. We consider both the MNCS and the PPtop10{\%} indicator. Globally, for all the universities taken together citation impact indicators generally turn out to be relatively insensitive to the choice of a classification system. Nevertheless, for individual universities, we sometimes observe substantial differences between indicators normalized based on the journal subject categories and indicators normalized based on an appropriately chosen algorithmically constructed classification system.},
author = {Ruiz-Castillo, Javier and Waltman, Ludo},
doi = {10.1016/j.joi.2014.11.010},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruiz-Castillo, Waltman - 2015 - Field-normalized citation impact indicators using algorithmically constructed classification systems of.pdf:pdf},
isbn = {978-90-817527-1-8},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Citation impact indicators,Classification systems,Clustering methodology,Field normalization,University rankings},
number = {1},
pages = {102--117},
publisher = {Elsevier Ltd},
title = {{Field-normalized citation impact indicators using algorithmically constructed classification systems of science}},
url = {http://dx.doi.org/10.1016/j.joi.2014.11.010},
volume = {9},
year = {2015}
}
@incollection{Russell2009,
address = {Oxford, UK},
author = {Russell, Jane M and Rousseau, Ronald},
booktitle = {Science and Technology Policy},
edition = {illustrate},
editor = {Arvanitis, Rigas},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Russell, Rousseau - 2002 - Bibliometrics and Institutional Evaluation.pdf:pdf},
isbn = {9781848260597},
keywords = {bibliographic,bibliometrics,citation analysis,databases,institutions,journal impact factors,peer review,research,research evaluation,research groups,research performance,scholarly journals,science and technology indicators,science citation index,science policy,scientists,scientometrics},
pages = {22--42},
publisher = {EOLSS Publications},
title = {{Bibliometrics and Institutional Evaluation}},
volume = {II},
year = {2009}
}
@article{Sangwal2012,
abstract = {The nature of the empirical proportionality constant A in the relation L = Ah(2) between total number of citations L of the publication output of an author and his/her Hirsch index h is analyzed using data of the publication output and citations for six scientists elected to the membership of the Royal Society in 2006 and 199 professors working in different institutions in Poland. The main problem with the h index of different authors calculated by using the above relation is that it underestimates the ranking of scientists publishing papers receiving very high citations and results in high values of A. It was found that the value of the Hirsch constant A for different scientists is associated with the discreteness of h and is related to the tapered Hirsch index h(T) by A(1/2) ≈ 1.21h(T). To overcome the drawback of a wide range of A associated with the discreteness of h for different authors, a simple index, the radius R of circular citation area, defined as R = (L/$\pi$)(1/2) ≈ h, is suggested. This circular citation area radius R is easy to calculate and improves the ranking of scientists publishing high-impact papers. Finally, after introducing the concept of citation acceleration a = L/t(2) = $\pi$(R/t)(2) (t is publication duration of a scientist), some general features of citations of publication output of Polish professors are described in terms of their citability. Analysis of the data of Polish professors in terms of citation acceleration a shows that: (1) the citability of the papers of a majority of physics and chemistry professors is much higher than that of technical sciences professors, and (2) increasing fraction of conference papers as well as non-English papers and engagement in administrative functions of professors result in decreasing citability of their overall publication output. ELECTRONIC SUPPLEMENTARY MATERIAL: The online version of this article (doi:10.1007/s11192-012-0805-7) contains supplementary material, which is available to authorized users.},
author = {Sangwal, Keshra},
doi = {10.1007/s11192-012-0805-7},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sangwal - 2012 - On the relationship between citations of publication output and Hirsch index h of authors Conceptualization of tapered.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Circular citation area radius R,Citation acceleration a,Citations L,Ferrers diagrams,Hirsch constant A = L/h 
                        2,Hirsch index h,Publication output,Tapered h index (h 
                        T)},
number = {3},
pages = {987--1004},
pmid = {23162174},
title = {{On the relationship between citations of publication output and Hirsch index h of authors: Conceptualization of tapered Hirsch index h 
                    T, circular citation area radius R and citation acceleration a}},
volume = {93},
year = {2012}
}
@article{Sangwal2012a,
abstract = {It is shown that the age-independent index based on h-type index per decade, called hereafter an $\alpha$ index instead of the a index, suggested by Kosmulski (Journal of Informetrics 3, 341-347, 2009) and Abt (Scientometrics 2012) is related to the square-root of the ratio of citation acceleration a to the Hirsch constant A.},
author = {Sangwal, Keshra},
doi = {10.1007/s11192-012-0628-6},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sangwal - 2012 - On the age-independent publication index.pdf:pdf},
issn = {01389130},
journal = {Scientometrics},
keywords = {Age-independent index ??,Citation acceleration a,Hirsch constant A,Hirsch index h},
number = {3},
pages = {1053--1058},
pmid = {22611294},
title = {{On the age-independent publication index}},
volume = {91},
year = {2012}
}
@article{Schreiber2008,
abstract = {The h-index has been introduced by Hirsch as a useful measure to characterize the scientific output of a researcher. I suggest a simple modification in order to take multiple co-authorship appropriately into account, by counting each paper only fractionally according to (the inverse of) the number of authors. The resulting h(m)-indices for eight famous physicists lead to a different ranking from the original h-indices.},
author = {Schreiber, Michael},
doi = {10.1088/1367-2630/10/4/040201},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schreiber - 2008 - To share the fame in a fair way, hm modifies h for multi-authored manuscripts.pdf:pdf},
isbn = {1367-2630},
issn = {13672630},
journal = {New Journal of Physics},
number = {020201},
title = {{To share the fame in a fair way, hm modifies h for multi-authored manuscripts}},
volume = {10},
year = {2008}
}
@phdthesis{Sebelova2008,
abstract = {Master diploma thesis deals with significance of the citation indexes for the document retrieval. Except this function, indexes are important in scientific discipline named bibliometrics and its methods. The basic unit of the indexes is bibliographic citation. If the citations want to fullfill their aims and functions in non-fiction literature, they have to follow the specific standards. After the analysis of the primary printed indexes in theoretical part of the thesis, you can continue in last part with the comparative analysis of the two best known citation indexes: Web of Science and Scopus.},
author = {{\v{S}}ebelov{\'{a}}, Iva},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Citovat - Unknown - ...................................... 11 1.2 v.pdf:pdf},
keywords = {Citation Index,Cita{\v{c}}n{\'{i}} rejstř{\'{i}}k,Science Citation Index,Scopus,Web of Science,bibliografick{\'{a}} citace,bibliographic citation,bibliometrics,bibliometrie,citation indexing,cita{\v{c}}n{\'{i}} indexov{\'{a}}n{\'{i}},document retrieval,hypertext reference,hypertextov{\'{y}} odkaz,vyhled{\'{a}}v{\'{a}}n{\'{i}} dokumentů,webometrics,webometrie},
pages = {6--124},
school = {Masaryk University, Faculty of Arts, Brno},
title = {{V{\'{y}}znam cita{\v{c}}n{\'{i}}ch rejstř{\'{i}}ků pro vyhled{\'{a}}v{\'{a}}n{\'{i}} dokumentů. Web of Science a Scopus}},
type = {Master's thesis},
year = {2008}
}
@article{Sedlackova2007,
abstract = {V sou{\v{c}}asn{\'{e}} spole{\v{c}}nosti je tvorba informac{\'{i}} a znalost{\'{i}} z{\'{a}}kladn{\'{i}}m krokem {\'{u}}sp{\v{e}}{\v{s}}n{\'{e}}ho managementu, v{\'{y}}raznou pod- porou osobn{\'{i}}ho růstu a profesn{\'{i}}ho postupu. Z t{\v{e}}chto důvodů je data mining mnoha odborn{\'{i}}ky pova{\v{z}}ov{\'{a}}n za jednu z velmi perspektivn{\'{i}}ch a atraktivn{\'{i}}ch {\v{c}}innost{\'{i}} budoucnosti ve v{\v{s}}ech oblastech a různ{\'{y}}ch {\'{u}}rovn{\'{i}}ch lidsk{\'{e}} aktivity. Je to proces transformace dat přes informace ke znalosti, přesn{\v{e}}ji ře{\v{c}}eno k ak{\v{c}}n{\'{i}} znalosti. Př{\'{i}}sp{\v{e}}vek zmiňuje data mining jako nov{\'{y}} n{\'{a}}stroj zpracov{\'{a}}n{\'{i}} a vyu{\v{z}}{\'{i}}v{\'{a}}n{\'{i}} informac{\'{i}} a sleduje mo{\v{z}}nosti aplikace v knihovnicko- in- forma{\v{c}}n{\'{i}} oblasti.},
author = {Sedl{\'{a}}{\v{c}}kov{\'{a}}, Be{\'{a}}ta},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sedl{\'{a}}{\v{c}}kov{\'{a}} - 2007 - Data mining a jeho uplatn{\v{e}}n{\'{i}} při pozn{\'{a}}van{\'{i}} knihovnick{\'{y}}ch jevů a z{\'{a}}konitost{\'{i}}.pdf:pdf},
journal = {KNI{\v{Z}}NICA},
number = {11-12},
pages = {21--22},
title = {{Data mining a jeho uplatn{\v{e}}n{\'{i}} při pozn{\'{a}}van{\'{i}} knihovnick{\'{y}}ch jevů a z{\'{a}}konitost{\'{i}}}},
volume = {8},
year = {2007}
}
@article{Shideler2016,
abstract = {Both end users and authors commonly evaluate scientific journals based on several popular journal metrics. Such metrics, in particular the ``impact factor,'' carry crucial weight in terms of which journals authors choose for submitting scientific works as well as to what titles an institutional library subscribes. While previous research has focused on the value of journals in terms of ``price per page,'' no study has investigated the relationship between common journal metrics and the price a journal advertises for an annual subscription. In the present study, we took a linear modeling approach using Akaike information criterion to determine which journal metric (impact factor, Eigenfactor score, article influence score, total cites, or proportion reviews) was the ``best'' predictor of the advertised annual subscription price for scientific journals. Examining three differing scientific fields (aquatic science, sociology, and immunology) and accounting for for-profit versus not-for-profit status, we found results to be field-dependent. Total cites was the best predicting metric for the annual advertised subscription price for aquatic science and immunology, while the Eigenfactor score was the best predictor for sociology. We hypothesize the relationship with price changes with differing magnitudes of citation flows in a field. Clear from our study was that no single measure of journal quality is universally applicable to determine subscription ``value.''},
author = {Shideler, Geoffrey S. and Ara{\'{u}}jo, Rafael J.},
doi = {10.1007/s11192-016-1943-0},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shideler, Arajo - 2016 - Measures of scholarly journal quality are not universally applicable to determining value of advertised annual.pdf:pdf},
issn = {15882861},
journal = {Scientometrics},
keywords = {Eigenfactor,Impact factor,Journal metrics,Journal pricing,Total cites},
pages = {1--11},
title = {{Measures of scholarly journal quality are not universally applicable to determining value of advertised annual subscription price}},
year = {2016}
}
@article{Sidiropoulos2007,
abstract = {What is the value of a scientist and its impact upon the scientific thinking? How can we measure the prestige of a journal or of a conference? The evaluation of the scientific work of a scientist and the estimation of the quality of a journal or conference has long attracted significant interest, due to the benefits from obtaining an unbiased and fair criterion. Although it appears to be simple, defining a quality metric is not an easy task. To overcome the disadvantages of the present metrics used for ranking scientists and journals, J.E. Hirsch proposed a pioneering metric, the now famous h-index. In this article, we demonstrate several inefficiencies of this index and develop a pair of generalizations and effective variants of it to deal with scientist ranking and with publication forum ranking. The new citation indices are able to disclose trendsetters in scientific research, as well as researchers that constantly shape their field with their influential work, no matter how old they are. We exhibit the effectiveness and the benefits of the new indices to unfold the full potential of the h-index, with extensive experimental results obtained from DBLP, a widely known on-line digital library.},
archivePrefix = {arXiv},
arxivId = {cs/0607066},
author = {Sidiropoulos, Antonis and Katsaros, Dimitrios and Manolopoulos, Yannis},
doi = {10.1007/s11192-007-1722-z},
eprint = {0607066},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sidiropoulos, Katsaros, Manolopoulos - 2007 - Generalized Hirsch h-index for disclosing latent facts in citation networks.pdf:pdf},
isbn = {1119200717},
issn = {01389130},
journal = {Scientometrics},
number = {2},
pages = {253--280},
primaryClass = {cs},
title = {{Generalized Hirsch h-index for disclosing latent facts in citation networks}},
volume = {72},
year = {2007}
}
@article{Singh2015,
abstract = {This paper presents a scientometric analysis of research work done on the emerging area of ‘Big Data' during the recent years. Research on ‘Big Data' started during last few years and within a short span of time has gained tremendous momentum. It is now considered one of the most important emerging areas of research in computational sciences and related disciplines. We have analyzed the research output data on ‘Big Data' during 2010–2014 indexed in both, the Web of Knowledge and Scopus. The analysis maps comprehensively the parameters of total output, growth of output, authorship and country- level collaboration patterns, major contributors (countries, institutions and individuals), top publication sources, thematic trends and emerging themes in the field. The paper presents an elaborate and one of its kind scientometric mapping of research on ‘Big Data'.},
author = {Singh, Vivek Kumar and Banshal, Sumit Kumar and Singhal, Khushboo and Uddin, Ashraf},
doi = {10.1007/s11192-015-1729-9},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh et al. - 2015 - Scientometric mapping of research on ‘Big Data'.pdf:pdf},
isbn = {1119201517299},
issn = {01389130},
journal = {Scientometrics},
keywords = {Big Data,Big Data research,Informetrics,Scientometrics},
number = {2},
pages = {727--741},
publisher = {Springer Netherlands},
title = {{Scientometric mapping of research on ‘Big Data'}},
url = {"http://dx.doi.org/10.1007/s11192-015-1729-9},
volume = {105},
year = {2015}
}
@article{Smith2012,
abstract = {Few contemporary inventions have influenced academic publishing as much as journal impact factors. On the other hand, debates and discussion on the potential limita- tions of, and appropriate uses for, journal performance indicators are almost as long as the history of the measures themselves. Given that scientometrics is often undertaken using bibliometric techniques, the history of the former is inextricably linked to the latter. As with any controversy it is difficult to separate an invention from its history, and for these reasons, the current article provides an overview of some key historical events of relevance to the impact factor. When he first proposed the concept over half a century ago, Garfield did not realise that impact factors would one day become the subject of such widespread contro- versy. As the current Special Issue of Scientometrics suggests, this debate continues today.},
author = {Smith, Derek R.},
doi = {10.1007/s11192-012-0685-x},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith - 2012 - Impact factors, scientometrics and the history of citation-based research.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Bibliometrics,Citation indexing,History,Impact factor,Scientometrics},
number = {2},
pages = {419--427},
title = {{Impact factors, scientometrics and the history of citation-based research}},
volume = {92},
year = {2012}
}
@article{Sohrabi2014,
abstract = {BACKGROUND: This study aimed to assess the effect of new package of interventions on scientific productions rate in Shahid Beheshti University of Medical Sciences.$\backslash$n$\backslash$nMETHODS: Through a health system research, we extracted policies from the strategic plan of the university and 10 interventions were developed to increase the scientific productions in terms of quality, quantity and commercialization and to develop infrastructure for research in health service provision and education. For evaluating the effectiveness of interventions, citation and publication indicators for individuals and schools were analyzed using descriptive statistics and t-test. They were extracted from Scopus and ISI web of knowledge during period of 1/1/2009 to 30/5/2012.$\backslash$n$\backslash$nRESULTS: There was an increasing trend in scientific productions from 2009 to mid-2012. We found 60 percent of total scientific productions of the university were published during last 3.5 years. During this 3.5 years, 10 more percentile of faculty members involved in research. Schools of pharmacy, Medicine and Health had the highest scientific products. Mean for h-index was 1.5 (SD=2.49) in ISI and 1.9 (SD=2.89) in Scopus database (p{\textless}0.001).$\backslash$n$\backslash$nCONCLUSION: Effective policies and interventions lead to 46{\%} increase in scientific productions from 2009 to 2010 and 56{\%} increase from 2010 to 2011.},
author = {Sohrabi, Mohammad-Reza and Rahmati-Roodsari, Mohammad and Rahmdar, Saeid-Reza},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sohrabi, Rahmati-Roodsari, Rahmdar - 2014 - Effect of university policies on research productions a scientometric study.pdf:pdf},
issn = {1016-1430},
journal = {Medical journal of the Islamic Republic of Iran},
keywords = {14 july,28,63,a scientomet-,citation,cite this article as,effect of university policies,hirsch index h,iran 2014,med j islam repub,on research productions,publication output,r,rahmati-roodsari m,rahmdar s,ric study,scietometrics,sohrabi m,vol},
number = {63},
pmid = {25405128},
title = {{Effect of university policies on research productions: a scientometric study.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4219892{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {28},
year = {2014}
}
@article{Soma2016,
author = {Soma, Nei Y},
doi = {10.1007/s11192-016-1908-3},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soma - 2016 - An analysis of bibliometric indicators to JCR according to Benford ' s law.pdf:pdf},
issn = {15882861},
journal = {Scientometrics},
keywords = {bibliometric indicators benford,journal citation reports jcr,s law},
number = {3},
pages = {1--13},
publisher = {Springer Netherlands},
title = {{An analysis of bibliometric indicators to JCR according to Benford ' s law}},
url = {"http://dx.doi.org/10.1007/s11192-016-1908-3},
volume = {107},
year = {2016}
}
@book{Soucek2009,
address = {Prague},
author = {Sou{\v{c}}ek, Martin},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ostrava - Unknown - Univerzita Karlova v Praze {\'{U}}stav informa {\v{c}} n{\'{i}} studi{\'{i}} a knihovnictv{\'{i}} Informa {\v{c}} n{\'{i}} a znalostn{\'{i}} management.pdf:pdf},
pages = {5--111},
publisher = {http://www.informacniveda.cz},
title = {{Informa{\v{c}}n{\'{i}} v{\v{e}}da}},
year = {2009}
}
@article{Stegehuis2015,
abstract = {A fundamental problem in citation analysis is the prediction of the long-term citation impact of recent publications. We propose a model to predict a probability distribution for the future number of citations of a publication. Two predictors are used: the impact factor of the journal in which a publication has appeared and the number of citations a publication has received one year after its appearance. The proposed model is based on quantile regression. We employ the model to predict the future number of citations of a large set of publications in the field of physics. Our analysis shows that both predictors (i.e., impact factor and early citations) contribute to the accurate prediction of long-term citation impact. We also analytically study the behavior of the quantile regression coefficients for high quantiles of the distribution of citations. This is done by linking the quantile regression approach to a quantile estimation technique from extreme value theory. Our work provides insight into the influence of the impact factor and early citations on the long-term citation impact of a publication, and it takes a step toward a methodology that can be used to assess research institutions based on their most recently published work.},
author = {Stegehuis, Clara and Litvak, Nelly and Waltman, Ludo},
doi = {10.1016/j.joi.2015.06.005},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stegehuis, Litvak, Waltman - 2015 - Predicting the long-term citation impact of recent publications.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Citation analysis,Citation impact,Impact factor,Prediction,Quantile estimation,Quantile regression},
number = {3},
pages = {642--657},
publisher = {Elsevier Ltd},
title = {{Predicting the long-term citation impact of recent publications}},
url = {http://dx.doi.org/10.1016/j.joi.2015.06.005},
volume = {9},
year = {2015}
}
@phdthesis{Semestr2016,
abstract = {Scientometrick{\'{a}} anal{\'{y}}za sl{\'{u}}{\v{z}}i na kvalitat{\'{i}}vne a kvantitat{\'{i}}vne hodnotenie vedeckej pr{\'{a}}ce. Vykon{\'{a}}va sa pomocou {\v{s}}tatistickej anal{\'{y}}zy publika{\v{c}}nej {\v{c}}innosti jednotliv{\'{y}}ch pracovn{\'{i}}kov, in{\v{s}}tit{\'{u}}ci{\'{i}} a dokonca cel{\'{y}}ch kraj{\'{i}}n. Kvalitu vedeck{\'{y}}ch publik{\'{a}}ci{\'{i}} ur{\v{c}}uje mno{\v{z}}stvo cit{\'{a}}ci{\'{i}} (odkazov) na publik{\'{a}}cie. Viac cit{\'{a}}ci{\'{i}} na {\v{c}}l{\'{a}}nok vyjadruje jeho popularitu, kvalitu a pr{\'{i}}nos pre vedeck{\'{y}} pokrok. Cieľom tejto pr{\'{a}}ce je kvalitat{\'{i}}tne a kvantitat{\'{i}}vne zhodnotiť publika{\v{c}}n{\'{u}} {\v{c}}innosť pracovn{\'{i}}kov Fakulty pr{\'{i}}rodn{\'{y}}ch vied Univerzity sv. Cyrila a Medova v Trnave za obdobnie 2000 – 2016.},
author = {Sz{\'{a}}sz, Juraj},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Semestr et al. - 2016 - Katedra Biol{\'{o}}gie.pdf:pdf},
school = {Univerzita sv. Cyrila a Metoda v Trnave, Fakulta pr{\'{i}}rodn{\'{y}}ch vied},
title = {{Semestr{\'{a}}lna pr{\'{a}}ca III Scientometrick{\'{a}} anal{\'{y}}za Fakulty pr{\'{i}}rodn{\'{y}}ch vied Univerzity Cyrila a Metoda v Trnave}},
year = {2016}
}
@article{Thelwall2016,
abstract = {There is no agreement over which statistical distribution is most appropriate for modelling citation count data. This is important because if one distribution is accepted then the relative merits of different citation-based indicators, such as percentiles, arithmetic means and geometric means, can be more fully assessed. In response, this article investigates the plausibility of the discretised lognormal and hooked power law distributions for modelling the full range of citation counts, with an offset of 1. The citation counts from 23 Scopus subcategories were fitted to hooked power law and discretised lognormal distributions but both distributions failed a Kolmogorov-Smirnov goodness of fit test in over three quarters of cases. The discretised lognormal distribution also seems to have the wrong shape for citation distributions, with too few zeros and not enough medium values for all subjects. The cause of poor fits could be the impurity of the subject subcategories or the presence of interdisciplinary research. Although it is possible to test for subject subcategory purity indirectly through a goodness of fit test in theory with large enough sample sizes, it is probably not possible in practice. Hence it seems difficult to get conclusive evidence about the theoretically most appropriate statistical distribution.},
archivePrefix = {arXiv},
arxivId = {1603.05078},
author = {Thelwall, Mike},
doi = {10.1016/j.joi.2016.03.001},
eprint = {1603.05078},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thelwall - 2016 - Are the discretised lognormal and hooked power law distributions plausible for citation data.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Citation distributions,Discretised lognormal distribution,Hooked power law},
number = {2},
pages = {454--470},
publisher = {Elsevier Ltd},
title = {{Are the discretised lognormal and hooked power law distributions plausible for citation data?}},
url = {http://dx.doi.org/10.1016/j.joi.2015.12.007},
volume = {10},
year = {2016}
}
@article{Thelwall2014,
abstract = {The citations to a set of academic articles are typically unevenly shared, with many articles attracting few citations and few attracting many. It is important to know more precisely how citations are distributed in order to help statistical analyses of citations, especially for sets of articles from a single discipline and a small range of years, as normally used for research evaluation. This article fits discrete versions of the power law, the lognormal distribution and the hooked power law to 20 different Scopus categories, using citations to articles published in 2004 and ignoring uncited articles. The results show that, despite its popularity, the power law is not a suitable model for collections of articles from a single subject and year, even for the purpose of estimating the slope of the tail of the citation data. Both the hooked power law and the lognormal distributions fit best for some subjects but neither is a universal optimal choice and parameter estimates for both seem to be unreliable. Hence only the hooked power law and discrete lognormal distributions should be considered for subject-and-year-based citation analysis in future and parameter estimates should always be interpreted cautiously. ?? 2014 Elsevier Ltd.},
author = {Thelwall, Mike and Wilson, Paul},
doi = {10.1016/j.joi.2014.08.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thelwall, Wilson - 2014 - Distributions for cited articles from individual subjects and years.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Citation analysis,Citation distribution,Hooked power law,Lognormal distribution,Power law},
number = {4},
pages = {824--839},
title = {{Distributions for cited articles from individual subjects and years}},
volume = {8},
year = {2014}
}
@book{Todeschini2016,
author = {Todeschini, Roberto and Baccini, Alberto},
isbn = {978-3-527-68195-2},
publisher = {Wiley},
title = {{Handbook of Bibliometric Indicators: Quantitative Tools for Studying and Evaluating Research}},
year = {2016}
}
@article{Tol2011,
abstract = {I propose a new method (Pareto weights) to objectively attribute citations to co-authors. Previous methods either profess ignorance about the seniority of co-authors (egalitarian weights) or are based in an ad hoc way on the order of authors (rank weights). Pareto weights are based on the respective citation records of the co-authors. Pareto weights are proportional to the probability of observing the number of citations obtained. Assuming a Pareto distribution, such weights can be computed with a simple, closed-form equation but require a few iterations and data on a scholar, her co-authors, and her co-authors' co-authors. The use of Pareto weights is illustrated with a group of prominent economists. In this case, Pareto weights are very different from rank weights. Pareto weights are more similar to egalitarian weights but can deviate up to a quarter in either direction (for reasons that are intuitive).},
author = {Tol, Richard S J},
doi = {10.1007/s11192-011-0451-5},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tol - 2011 - Credit where credit's due Accounting for co-authorship in citation counts.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Citations,Co-authors,Pareto distribution},
number = {1},
pages = {291--299},
pmid = {21957320},
title = {{Credit where credit's due: Accounting for co-authorship in citation counts}},
volume = {89},
year = {2011}
}
@article{Tol2008,
abstract = {A rational, successive g-index is proposed, and applied to economics departments in Ireland. The successive g-index has greater discriminatory power than the successive h-index, and the rational index performs better still. The rational, successive g-index is also more robust to differences in department size. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Tol, Richard S J},
doi = {10.1016/j.joi.2008.01.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tol - 2008 - A rational, successive g-index applied to economics departments in Ireland.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Department rankings,g-Index,h-Index},
number = {2},
pages = {149--155},
title = {{A rational, successive g-index applied to economics departments in Ireland}},
volume = {2},
year = {2008}
}
@article{Tol2012,
abstract = {Performance measures of individual scholars tend to ignore the context. I introduce contextualised metrics: cardinal and ordinal pseudo-Shapley values that measure a scholar's contribution to (perhaps power over) her own school and her market value to other schools should she change job. I illustrate the proposed measures with business scholars and business schools in Ireland. Although conceptually superior, the power indicators imply a ranking of scholars within a school that is identical to the corresponding conventional performance measures. The market value indicators imply an identical ranking within schools and a very similar ranking between schools. The ordinal indices further contextualise performance measures and thus deviate further from the corresponding conventional indicators. As the ordinal measures are discontinuous by construction, a natural classification of scholars emerges. Averaged over schools, the market values offer little extra information over the corresponding production and impact measures. The ordinal power measure indicates the robustness or fragility of an institution's place in the rank order. It is only weakly correlated with the concentration of publications and citations.},
author = {Tol, Richard S J},
doi = {10.1007/s11192-011-0555-y},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tol - 2012 - Shapley values for assessing research production and impact of schools and scholars.pdf:pdf},
issn = {01389130},
journal = {Scientometrics},
keywords = {Departments,Individuals,Rankings},
number = {3},
pages = {763--780},
pmid = {22347758},
title = {{Shapley values for assessing research production and impact of schools and scholars}},
volume = {90},
year = {2012}
}
@article{Tomancakova2015,
abstract = {Abstract The paper presents the research realized within bachelor thesis with the focus on citation analysis of the ProInflow journal. In the first part research methods, research questions and data processing are defined. In the second are presented particular results from the made quantitative research. That includes the most cited authors, journals and books, and also the age of cited documents and citation behaviour are compared and analysed.},
annote = {ISSN:  1804-2406},
author = {Toman{\v{c}}{\'{a}}kov{\'{a}}, Dana},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Toman{\v{c}}{\'{a}}kov{\'{a}} - 2015 - Cita{\v{c}}n{\'{i}} anal{\'{y}}za {\v{c}}asopisu ProInflow {\'{U}}vod C{\'{i}}lem t{\'{e}}to pr{\'{a}}ce je nal{\'{e}}zt nejcitovan{\v{e}}j{\v{s}}{\'{i}} {\v{c}}asopisy , pub.pdf:pdf},
journal = {ProInflow: {\v{C}}asopis pro Informa{\v{c}}n{\'{i}} v{\v{e}}dy},
keywords = {citation analysis,citations,proinflow journal,publications,quantitative research,scientific journals},
pages = {53--66},
title = {{Cita{\v{c}}n{\'{i}} anal{\'{y}}za {\v{c}}asopisu ProInflow}},
volume = {2},
year = {2015}
}
@inproceedings{Tomizawa2006,
address = {Ottawa, Ontario},
author = {Tomizawa, Hiroyuki and Hayashi, Takayuki},
booktitle = {BLUE SKY II 2006},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tomizawa, Hayashi - Unknown - Constructing a Multi-level Scientometric Indicators System.pdf:pdf},
pages = {1--13},
publisher = {Blue Sky II 2006 Statistics Canada},
title = {{Constructing a Multi-level Scientometric Indicators System}},
year = {2006}
}
@article{Torres-Salinas2009,
abstract = {In this work, we compare the difference in the number of citations compiled with Scopus as opposed to the Web of Science (WoS) with the aim of analysing the agreement among the citation rankings generated by these databases. For this, we analysed the area of Health Sciences of the University of Navarra (Spain), composed of a total of 50 departments and 864 researchers. The total number of published works reflected in the WoS during the period 1999-2005 was 2299. For each work, the number of citations in both databases was recorded. The results indicate that the works received 14.7{\%} more citations in Scopus than in WoS. In the departments, the difference was greater in the clinical ones than in the basic ones. In the case of the rankings of citations, it was found that both databases generate similar results. The Spearman and Kendall-Tau coefficients were higher than 0.9. It was concluded that the difference in the number of citations found did not correspond to the difference of coverage of WoS and Scopus. {\textcopyright} 2009 Akad{\'{e}}miai Kiad{\'{o}}, Budapest.},
author = {Torres-Salinas, Daniel and Lopez-C{\'{o}}zar, Emilio Delgado and Jim{\'{e}}nez-Contreras, Evaristo},
doi = {10.1007/s11192-008-2113-9},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Torres-Salinas, Lopez-C{\'{o}}zar, Jim{\'{e}}nez-Contreras - 2009 - Ranking of departments and researchers within a university using two different.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {3},
pages = {761--774},
title = {{Ranking of departments and researchers within a university using two different databases: Web of science versus scopus}},
volume = {80},
year = {2009}
}
@phdthesis{Troupova2011,
abstract = {The master thesis is focused on the scientometric methods of research and development evaluation and their use in particular system applied in the Czech Republic. Its introductory part presents the field of scientometrics, scientometric and bibliometric indicators and citation indices. Chapter 7 deals with research and development evaluation in Czech Republic, especially with Research Evaluation Guidelines and describes its assesment rules, results and changes due to its annual actualization. A battle of wills between the Guidelines supporters and opponents is the topic of chapter 8, in particular in the context of reallocation of institutional funding according to the Guidelines. Ideas and opinions of prominent scientists and policymakers are being presented followed by brief treatise on Czech system of research and development evaluation audit carried out by the company Technopolis Limited. In the conclusion the author summarizes and debates positives and negatives of the Czech system of science evaluation.},
author = {Troupov{\'{a}}, Al{\v{z}}b{\v{e}}ta},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karlova, Filozofick - 2011 - Scientometrick{\'{e}} hodnocen{\'{i}} v {\v{e}} dy se zam {\v{e}}ř en{\'{i}}m na {\v{C}} eskou republiku Scientometric research evaluati.pdf:pdf},
keywords = {Czech Republic,RIV,Research Evaluation Guidelines,Scientometrics,bibliometrics,citation indices,impact factor,publication outputs,research and development,research evaluation,statistic indicators},
pages = {180},
school = {Univerzita Karlova v Praze, Filozofick{\'{a}} fakulta},
title = {{Scientometrick{\'{e}} hodnocen{\'{i}} v{\v{e}}dy se zam{\v{e}}řen{\'{i}}m na {\v{C}}eskou republiku = Scientometric research evaluation with focus on the Czech Republic.}},
year = {2011}
}
@article{VanArensbergen2012,
abstract = {There is substantial literature on research performance differences between male and female researchers, and its explanation. Using publication records of 852 social scientists, we show that performance differences indeed exist. However, our case study suggests that in the younger generation of researchers these have disappeared. If performance differences exist at all in our case, young female researchers outperform young male researchers. The trend in developed societies, that women increasingly outperform men in all levels of education, is also becoming effective in the science system.},
author = {van Arensbergen, Pleun and van der Weijden, Inge and van den Besselaar, Peter},
doi = {10.1007/s11192-012-0712-y},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van Arensbergen, van der Weijden, van den Besselaar - 2012 - Gender differences in scientific productivity A persisting phenomenon.pdf:pdf},
issn = {01389130},
journal = {Scientometrics},
keywords = {Gender differences,Generation differences,Scholarly performance},
number = {3},
pages = {857--868},
pmid = {23162173},
title = {{Gender differences in scientific productivity: A persisting phenomenon?}},
volume = {93},
year = {2012}
}
@article{VandenBesselaar2015,
abstract = {The main rationale behind career grants is helping top talent to develop into the next generation leading scientists. Does career grant competition result in the selection of the best young talents? In this paper we investigate whether the selected applicants are indeed performing at the expected excellent level-something that is hardly investigated in the research literature.We investigate the predictive validity of grant decision-making, using a sample of 260 early career grant applications in three social science fields. We measure output and impact of the applicants about ten years after the application to find out whether the selected researchers perform ex post better than the non-successful ones. Overall, we find that predictive validity is low to moderate when comparing grantees with all non-successful applicants. Comparing grantees with the best performing non-successful applicants, predictive validity is absent. This implies that the common belief that peers in selection panels are good in recognizing outstanding talents is incorrect. We also investigate the effects of the grants on careers and show that recipients of the grants do have a better career than the non-granted applicants. This makes the observed lack of predictive validity even more problematic.},
author = {van den Besselaar, Peter and Sandstr{\"{o}}m, Ulf},
doi = {10.1016/j.joi.2015.07.011},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van den Besselaar, Sandstr{\"{o}}m - 2015 - Early career grants, performance, and careers A study on predictive validity of grant decisions.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Academic careers,Career grants,Gender differences,Grant allocation,Predictive validity},
number = {4},
pages = {826--838},
publisher = {Elsevier Ltd},
title = {{Early career grants, performance, and careers: A study on predictive validity of grant decisions}},
url = {http://dx.doi.org/10.1016/j.joi.2015.07.011},
volume = {9},
year = {2015}
}
@article{VanLeeuwen2012,
abstract = {In this study the issue of the validity of the argument against the applied length of citation windows in Journal Impact Factors calculations is critically re-analyzed. While previous studies argued against the relatively short citation window of 1-2 years, this study shows that the relative short term citation impact measured in the window underlying the Journal Impact Factor is a good predictor of the citation impact of the journals in the next years to come. Possible exceptions to this observation relate to journals with relatively low numbers of publications, and the citation impact related to publications in the year of publication. The study focuses on five Journal Subject Categories from the science and social sciences, on normal articles published in these journals, in the 2 years 2000 and 2004.},
author = {van Leeuwen, Thed},
doi = {10.1007/s11192-012-0677-x},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van Leeuwen - 2012 - Discussing some basic critique on Journal Impact Factors Revision of earlier comments.pdf:pdf},
isbn = {0138-9130$\backslash$r1588-2861},
issn = {01389130},
journal = {Scientometrics},
keywords = {Document types,Journal Impact Factor,Journal Subject Categories,Length of citation windows},
number = {2},
pages = {443--455},
pmid = {22844166},
title = {{Discussing some basic critique on Journal Impact Factors: Revision of earlier comments}},
volume = {92},
year = {2012}
}
@book{Vavrikova2008,
abstract = {Jak napov{\'{i}}d{\'{a}} {\'{u}}vodn{\'{i}} cit{\'{a}}t, ve v{\v{e}}d{\v{e}} lze m{\v{e}}řit kvalitu a kvantitu [GODIN, 2006]. Scientometrie je v{\v{e}}da, kter{\'{a}} se t{\'{i}}mto m{\v{e}}řen{\'{i}}m zab{\'{y}}v{\'{a}}, sna{\v{z}}{\'{i}} se nal{\'{e}}zat metody a metriky pro ur{\v{c}}en{\'{i}} jednoho {\v{c}}i druh{\'{e}}ho aspektu, obecn{\v{e}}ji se tak{\'{e}} v{\v{z}}il pojem m{\v{e}}řen{\'{i}} v{\'{y}}konnosti v{\v{e}}dy. Ve sv{\'{e}} samotn{\'{e}} podstat{\v{e}} sleduje a hodnot{\'{i}} komunikaci ve v{\v{e}}d{\v{e}}, neboť v{\v{s}}echna m{\v{e}}řen{\'{i}} jsou odvozena od interakc{\'{i}} mezi jednotliv{\'{y}}mi elementy scientometrie, touto z{\'{a}}kladn{\'{i}} interakc{\'{i}} je citace. Jej{\'{i}} n{\'{a}}zev je odvozen z metrein – m{\v{e}}řit (řec., lat.), scientia – znalost, v{\v{e}}d{\v{e}}n{\'{i}}. Scientometrie př{\'{i}}mo navazuje a vych{\'{a}}z{\'{i}} z informa{\v{c}}n{\'{i}} v{\v{e}}dy a pou{\v{z}}{\'{i}}v{\'{a}} mj. jej{\'{i}} metody, pro spr{\'{a}}vn{\'{e}} pochopen{\'{i}} je ji třeba vsadit do kontextu jednotliv{\'{y}}ch metod bibliometrie a informetrie. Prakticky je scientometrie dnes nejv{\'{i}}ce vyu{\v{z}}{\'{i}}v{\'{a}}na pro hodnocen{\'{i}} v{\v{e}}dy pro rozd{\v{e}}lov{\'{a}}n{\'{i}} finan{\v{c}}n{\'{i}}ch zdrojů ve v{\v{e}}d{\v{e}}.},
address = {Praha},
author = {Vavř{\'{i}}kov{\'{a}}, Lucie},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vavř{\'{i}}kov{\'{a}} - 2008 - {\'{U}}vod Do Scientometrie.pdf:pdf},
pages = {1--32},
publisher = {{\'{U}}stav informa{\v{c}}n{\'{i}}ch studi{\'{i}} a knihovnictv{\'{i}}, Univerzita Karlova v Praze},
title = {{{\'{U}}vod Do Scientometrie}},
url = {http://texty.jinonice.cuni.cz/studijni-texty/vavrikova-lucie/vavrikova{\_}1.pdf/view},
year = {2008}
}
@article{Vieira2010,
abstract = {This paper introduces a new impact indicator for the research effort of a university, nh3. The number of documents or the number of citations obtained by an institution are used frequently in international ranking of institutions. However, these are very dependent on the size and this is inducing mergers with the apparent sole goal of improving the research ranking. The alternative is to use the ratio of the two measures, the mean citation rate, that is size independent but it has been shown to fluctuate along the time as a consequence of its dependence on a very small number of documents with an extremely good citation performance. In the last few years, the popularity of the Hirsch index as an indicator of the research performance of individual researchers led to its application to journals and institutions. However, the original aim of this h index of giving a mixed measure of the number of documents published and their impact as measured by the citations collected along the time is totally undesirable for institutions as the overall size may be considered irrelevant for the impact evaluation of research. Furthermore, the h index when applied to institutions tends to retain a very small number of documents making all other research production irrelevant for this indicator. The nh3 index proposed here is designed to measure solely the impact of research in a way that is independent of the size of the institution and is made relatively stable by making a 20-year estimate of the citations of the documents produced in a single year. ?? 2010 Elsevier Ltd.},
author = {Vieira, E. S. and Gomes, J. A N F},
doi = {10.1016/j.joi.2010.06.006},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vieira, Gomes - 2010 - A research impact indicator for institutions.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {H index,Institutional impact,Research impact indicator,Size-dependence of the h index},
number = {4},
pages = {581--590},
publisher = {Elsevier Ltd},
title = {{A research impact indicator for institutions}},
url = {http://dx.doi.org/10.1016/j.joi.2010.06.006},
volume = {4},
year = {2010}
}
@article{Vieira2009,
abstract = {For many years, the ISI Web of Knowledge from Thomson Reuters was the sole publication and citation database covering all areas of science thus becoming an invaluable tool in bibliometric analysis. In 2004, Elsevier introduced Scopus and this is rapidly becoming a good alternative. Several attempts have been made at comparing these two instruments from the point of view of journal coverage for research or for bibliometric assessment of research output. This paper attempts to answer the question that all researchers ask, i.e., what is to be gained by searching both databases? Or, if you are forced to opt for one of them, which should you prefer? To answer this question, a detailed paper by paper study is presented of the coverage achieved by ISI Web of Science and by Scopus of the output of a typical university. After considering the set of Portuguese universities, the detailed analysis is made for two of them for 2006, the two being chosen for their comprehensiveness typical of most European universities. The general conclusion is that about 2/3 of the documents referenced in any of the two databases may be found in both databases while a fringe of 1/3 are only referenced in one or the other. The citation impact of the documents in the core present in both databases is higher, but the impact of the fringe that are present only in one of the databases should not be disregarded as some high impact documents may be found among them.},
archivePrefix = {arXiv},
arxivId = {0803.1716},
author = {Vieira, Elizabeth S. and Gomes, Jos{\'{e}} A N F},
doi = {10.1007/s11192-009-2178-0},
eprint = {0803.1716},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vieira, Gomes - 2009 - A comparison of Scopus and Web of science for a typical university.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
number = {2},
pages = {587--600},
pmid = {502955140},
title = {{A comparison of Scopus and Web of science for a typical university}},
volume = {81},
year = {2009}
}
@article{Viiu2016,
abstract = {The paper investigates the theoretical response of h-type bibliometric indicators developed over the past decade when faced with the problem of manipulation through self-citation practices. An extreme self-citation scenario is used to test the theoretical resistance of the research performance metrics to strategic manipulation and to determine the magnitude of the impact that self-citations may induce on the indicators. The original h-index, eighteen selected variants, as well as traditional bibliometric indicators are considered. The results of the theoretical study indicate that while all indicators are vulnerable to manipulation, some of the h-index variants are more susceptible to the influence of strategic behavior than others: elite set indicators prove more resilient than the original h while other variants, including most of those directly derived from the h-index, are shown to be less robust. Variants that take into account time constraints prove to be especially useful for detecting potential manipulation. As a practical tool which may aid further studies, the article offers a collection of functions to compute the h-index and several of its variants in the R language and environment for statistical computing.},
author = {V{\^{i}}iu, Gabriel-Alexandru},
doi = {10.1016/j.joi.2016.04.010},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/V{\^{i}}iu - 2016 - A theoretical evaluation of Hirsch-type bibliometric indicators confronted with extreme self-citation.pdf:pdf},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Bibliometric indicators,Manipulation,Research evaluation,Self-citation,h-Index variants},
number = {2},
pages = {552--566},
publisher = {Elsevier Ltd},
title = {{A theoretical evaluation of Hirsch-type bibliometric indicators confronted with extreme self-citation}},
url = {http://www.sciencedirect.com/science/article/pii/S1751157716300542},
volume = {10},
year = {2016}
}
@article{Vinkler2009,
abstract = {There are several simple and sophisticated scientometric indicators generally applied in the literature (e.g. total number of publications and citations, citations per journal paper, relative citedness indexes, Hirsch index, etc.), which may characterize the publications of scientists both qualitatively and quantitatively. The calculation methods generally use data referring to the total set of papers studied. Scientific progress, however, may be attributed primarily to information in the highly cited publications. Therefore, a new indicator ({\{}pi{\}}-index) is suggested for comparative assessment of scientists active in similar subject fields. The {\{}pi{\}}-index is equal to one hundredth of the number of citations obtained to the top square root of the total number of journal papers ( elite set of papers') ranked by the decreasing number of citations. The relation of the {\{}pi{\}}-index to other indexes and its dependence on the field is studied, using data of journal papers of highly cited researchers'.},
author = {Vinkler, P.},
doi = {10.1177/0165551509103601},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vinkler - 2009 - The pi index a new indicator for assessing scientific impact.pdf:pdf},
isbn = {0165-5515},
issn = {0165-5515},
journal = {Journal of Information Science},
keywords = {evaluation of publications,highly cited papers,hirsch index,scientometric,$\pi$ -index},
number = {5},
pages = {602--612},
title = {{The pi index: a new indicator for assessing scientific impact}},
url = {http://jis.sagepub.com/cgi/doi/10.1177/0165551509103601$\backslash$nhttp://jis.sagepub.com/content/35/5/602.abstract},
volume = {35},
year = {2009}
}
@article{Waaijer2011,
abstract = {Bibliometric mapping of scientific articles based on keywords and technical terms in abstracts is now frequently used to chart scientific fields. In contrast, no significant mapping has been applied to the full texts of non-specialist documents. Editorials in Nature and Science are such non-specialist documents, reflecting the views of the two most read scientific journals on science, technology and policy issues. We use the VOSviewer mapping software to chart the topics of these editorials. A term map and a document map are constructed and clusters are distinguished in both of them. The validity of the document clustering is verified by a manual analysis of a sample of the editorials. This analysis confirms the homogeneity of the clusters obtained by mapping and augments the latter with further detail. As a result, the analysis provides reliable information on the distribution of the editorials over topics, and on differences between the journals. The most striking difference is that Nature devotes more attention to internal science policy issues and Science more to the political influence of scientists. ELECTRONIC SUPPLEMENTARY MATERIAL: The online version of this article (doi:10.1007/s11192-010-0205-9) contains supplementary material, which is available to authorized users.},
author = {Waaijer, Cathelijn J F and van Bochove, Cornelis A. and van Eck, Nees Jan},
doi = {10.1007/s11192-010-0205-9},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Waaijer, van Bochove, van Eck - 2011 - On the map Nature and Science editorials.pdf:pdf},
isbn = {01389130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Bibliometrics,Classification,Editorials,Full-text,Mapping,VOSviewer},
number = {1},
pages = {99--112},
pmid = {21212822},
title = {{On the map: Nature and Science editorials}},
volume = {86},
year = {2011}
}
@article{Waltman2016,
abstract = {Citation impact indicators nowadays play an important role in research evaluation, and consequently these indicators have received a lot of attention in the bibliometric and scientometric literature. This paper provides an in-depth review of the literature on citation impact indicators. First, an overview is given of the literature on bibliographic databases that can be used to calculate citation impact indicators (Web of Science, Scopus, and Google Scholar). Next, selected topics in the literature on citation impact indicators are reviewed in detail. The first topic is the selection of publications and citations to be included in the calculation of citation impact indicators. The second topic is the normalization of citation impact indicators, in particular normalization for field differences. Counting methods for dealing with co-authored publications are the third topic, and citation impact indicators for journals are the last topic. The paper concludes by offering some recommendations for future research.},
archivePrefix = {arXiv},
arxivId = {1507.02099},
author = {Waltman, Ludo},
doi = {10.1016/j.joi.2016.02.007},
eprint = {1507.02099},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Waltman - 2016 - A review of the literature on citation impact indicators.pdf:pdf},
isbn = {1993-8233},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Bibliographic database,Citation analysis,Citation impact indicator,Counting method,Normalization},
number = {2},
pages = {365--391},
pmid = {5254657},
publisher = {Elsevier Ltd},
title = {{A review of the literature on citation impact indicators}},
url = {http://dx.doi.org/10.1016/j.joi.2016.02.007},
volume = {10},
year = {2016}
}
@article{Waltman2013,
abstract = {In a systematic large-scale empirical analysis, we compare a traditional normalization approach based on a field classification system with three source normalization approaches. We pay special attention to the selection of the publications included in the analysis. Publications in national scientific journals, popular scientific magazines, and trade magazines are not included. Unlike earlier studies, we use algorithmically constructed classification systems to evaluate the different normalization approaches. Our analysis shows that a source normalization approach based on the recently introduced idea of fractional citation counting does not perform well. Two other source normalization approaches generally outperform the classification-system-based normalization approach that we study. Our analysis therefore offers considerable support for the use of source-normalized bibliometric indicators. ?? 2013 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {arXiv:1301.4941},
author = {Waltman, Ludo and van Eck, Nees Jan},
doi = {10.1016/j.joi.2013.08.002},
eprint = {arXiv:1301.4941},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Waltman, van Eck - 2013 - A systematic empirical comparison of different approaches for normalizing citation impact indicators.pdf:pdf},
isbn = {9783200031357},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Citation,Classification system,Normalization,Source normalization},
number = {4},
pages = {833--849},
title = {{A systematic empirical comparison of different approaches for normalizing citation impact indicators}},
volume = {7},
year = {2013}
}
@article{Waltman2013a,
abstract = {Different scientific fields have different citation practices. Citation-based bib- liometric indicators need to normalize for such differences between fields in order to allow for meaningful between-field comparisons of citation impact. Traditionally, normalization for field differences has usually been done based on a field classification system. In this approach, each publication belongs to one or more fields and the citation impact of a publication is calculated relative to the other publications in the same field. Recently, the idea of source normalization was introduced, which offers an alternative approach to normalize for field differences. In this approach, normalization is done by looking at the referencing behavior of citing publications or citing journals. In this paper, we provide an overview of a number of source normalization approaches and we empirically compare these approaches with a traditional normalization approach based on a field classification system. We also pay attention to the issue of the selection of the journals to be included in a normalization for field differences. Our analysis indicates a number of problems of the traditional classification-system-based normalization approach, suggesting that source normalization approaches may yield more accurate results.},
archivePrefix = {arXiv},
arxivId = {1208.6122},
author = {Waltman, Ludo and van Eck, Nees Jan},
doi = {10.1007/s11192-012-0913-4},
eprint = {1208.6122},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Waltman, van Eck - 2013 - Source normalized indicators of citation impact An overview of different approaches and an empirical compariso.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Bibliometric indicator,Citation analysis,Field normalization,Source normalization},
number = {3},
pages = {699--716},
title = {{Source normalized indicators of citation impact: An overview of different approaches and an empirical comparison}},
volume = {96},
year = {2013}
}
@article{Waltman2015,
abstract = {Bibliometric studies often rely on field-normalized citation impact indicators in order to make comparisons between scientific fields. We discuss the connection between field normalization and the choice of a counting method for handling publications with multiple co-authors. Our focus is on the choice between full counting and fractional counting. Based on an extensive theoretical and empirical analysis, we argue that properly field-normalized results cannot be obtained when full counting is used. Fractional counting does provide results that are properly field normalized. We therefore recommend the use of fractional counting in bibliometric studies that require field normalization, especially in studies at the level of countries and research organizations. We also compare different variants of fractional counting. In general, it seems best to use either the author-level or the address-level variant of fractional counting.},
author = {Waltman, Ludo and van Eck, Nees Jan},
doi = {10.1016/j.joi.2015.08.001},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Waltman, van Eck - 2015 - Field-normalized citation impact indicators and the choice of an appropriate counting method.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Citation analysis,Counting method,Field normalization,Fractional counting,Full counting},
number = {4},
pages = {872--894},
title = {{Field-normalized citation impact indicators and the choice of an appropriate counting method}},
volume = {9},
year = {2015}
}
@article{Waltman2012,
abstract = {Classifying journals or publications into research areas is an essential element of many bibliometric analyses. Classification usually takes place at the level of journals, where the Web of Science subject categories are the most popular classification system. However, journal-level classification systems have two important limitations: They offer only a limited amount of detail, and they have difficulties with multidisciplinary journals. To avoid these limitations, we introduce a new methodology for constructing classification systems at the level of individual publications. In the proposed methodology, publications are clustered into research areas based on citation relations. The methodology is able to deal with very large numbers of publications. We present an application in which a classification system is produced that includes almost 10 million publications. Based on an extensive analysis of this classification system, we discuss the strengths and the limitations of the proposed methodology. Important strengths are the transparency and relative simplicity of the methodology and its fairly modest computing and memory requirements. The main limitation of the methodology is its exclusive reliance on direct citation relations between publications. The accuracy of the methodology can probably be increased by also taking into account other types of relations–for instance, based on bibliographic coupling.},
archivePrefix = {arXiv},
arxivId = {http://arxiv.org/ftp/arxiv/papers/1203/},
author = {Waltman, Ludo and {Van Eck}, Nees Jan},
doi = {10.1002/asi.22748},
eprint = {/arxiv.org/ftp/arxiv/papers/1203/},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Waltman, Van Eck - 2012 - A new methodology for constructing a publication-level classification system of science.pdf:pdf},
isbn = {1532-2890},
issn = {15322882},
journal = {Journal of the American Society for Information Science and Technology},
keywords = {bibliometrics,citation analysis},
number = {12},
pages = {2378--2392},
primaryClass = {http:},
title = {{A new methodology for constructing a publication-level classification system of science}},
volume = {63},
year = {2012}
}
@article{Waltman2011,
abstract = {The crown indicator is a well-known bibliometric indicator of research performance developed by our institute. The indicator aims to normalize citation counts for differences among fields. We critically examine the theoretical basis of the normalization mechanism applied in the crown indicator. We also make a comparison with an alternative normalization mechanism. The alternative mechanism turns out to have more satisfactory properties than the mechanism applied in the crown indicator. In particular, the alternative mechanism has a so-called consistency property. The mechanism applied in the crown indicator lacks this important property. As a consequence of our findings, we are currently moving towards a new crown indicator, which relies on the alternative normalization mechanism. ?? 2010 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {1004.1632},
author = {Waltman, Ludo and van Eck, Nees Jan and van Leeuwen, Thed N. and Visser, Martijn S. and van Raan, Anthony F J},
doi = {10.1007/s11192-011-0354-5},
eprint = {1004.1632},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Waltman et al. - 2011 - Towards a new crown indicator An empirical analysis(2).pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Bibliometric indicator,Citation,Crown indicator,Field,Normalization},
number = {3},
pages = {467--481},
pmid = {21654898},
publisher = {Elsevier Ltd},
title = {{Towards a new crown indicator: An empirical analysis}},
url = {http://dx.doi.org/10.1016/j.joi.2010.08.001},
volume = {87},
year = {2011}
}
@article{Waltman2011b,
abstract = {Two commonly used ideas in the development of citation-based research performance indicators are the idea of normalizing citation counts based on a field classification scheme and the idea of recursive citation weighing (like in PageRank-inspired indicators). We combine these two ideas in a single indicator, referred to as the recursive mean normalized citation score indicator, and we study the validity of this indicator. Our empirical analysis shows that the proposed indicator is highly sensitive to the field classification scheme that is used. The indicator also has a strong tendency to reinforce biases caused by the classification scheme. Based on these observations, we advise against the use of indicators in which the idea of normalization based on a field classification scheme and the idea of recursive citation weighing are combined.},
archivePrefix = {arXiv},
arxivId = {1105.3212},
author = {Waltman, Ludo and Yan, Erjia and van Eck, Nees Jan},
doi = {10.1007/s11192-011-0449-z},
eprint = {1105.3212},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Waltman, Yan, van Eck - 2011 - A recursive field-normalized bibliometric performance indicator An application to the field of library an.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {Bibliometric indicator,Citation impact,Field normalization,Recursive indicator},
number = {1},
pages = {301--314},
pmid = {21957321},
title = {{A recursive field-normalized bibliometric performance indicator: An application to the field of library and information science}},
volume = {89},
year = {2011}
}
@article{Wang2016,
abstract = {Journal classification systems play an important role in bibliometric analyses. The two most important bibliographic databases, Web of Science and Scopus, each provide a journal classification system. However, no study has systematically investigated the accuracy of these classification systems. To examine and compare the accuracy of journal classification systems, we define two criteria on the basis of direct citation relations between journals and categories. We use Criterion I to select journals that have weak connections with their assigned categories, and we use Criterion II to identify journals that are not assigned to categories with which they have strong connections. If a journal satisfies either of the two criteria, we conclude that its assignment to categories may be questionable. Accordingly, we identify all journals with questionable classifications in Web of Science and Scopus. Furthermore, we perform a more in-depth analysis for the field of Library and Information Science to assess whether our proposed criteria are appropriate and whether they yield meaningful results. It turns out that according to our citation-based criteria Web of Science performs significantly better than Scopus in terms of the accuracy of its journal classification system.},
archivePrefix = {arXiv},
arxivId = {1511.00735},
author = {Wang, Qi and Waltman, Ludo},
doi = {10.1016/j.joi.2016.02.003},
eprint = {1511.00735},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Waltman - 2016 - Large-scale analysis of the accuracy of the journal classification systems of Web of Science and Scopus.pdf:pdf},
issn = {18755879},
journal = {Journal of Informetrics},
keywords = {Bibliographic database,Citation analysis,Journal classification system,Scopus,Web of Science},
number = {2},
pages = {347--364},
publisher = {Elsevier Ltd},
title = {{Large-scale analysis of the accuracy of the journal classification systems of Web of Science and Scopus}},
url = {http://dx.doi.org/10.1016/j.joi.2016.02.003},
volume = {10},
year = {2016}
}
@article{Wang2015,
abstract = {In this study, we compare the difference in the impact between open access (OA) and non-open access (non-OA) articles. 1761 Nature Communications articles published from 1 January 2012 to 31 August 2013 are selected as our research objects, including 587 OA articles and 1174 non-OA articles. Citation data and daily updated article-level metrics data are harvested directly from the platform of nature.com. Data is analyzed from the static versus temporal-dynamic perspectives. The OA citation advantage is confirmed, and the OA advantage is also applicable when extending the comparing from citation to article views and social media attention. More important, we find that OA papers not only have the great advantage of total downloads, but also have the feature of keeping sustained and steady downloads for a long time. For article downloads, non-OA papers only have a short period of attention, when the advantage of OA papers exists for a much longer time.},
archivePrefix = {arXiv},
arxivId = {1503.05702},
author = {Wang, Xianwen and Liu, Chen and Mao, Wenli and Fang, Zhichao},
doi = {10.1007/s11192-015-1589-3},
eprint = {1503.05702},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2015 - Erratum to The open access advantage considering citation, article usage and social media attention Scientometrics,.pdf:pdf},
isbn = {0138-9130},
issn = {01389130},
journal = {Scientometrics},
keywords = {access advantage,article-level metrics {\'{a}} usage,media attention {\'{a}} open,metrics {\'{a}} altmetrics {\'{a}},open access {\'{a}} social},
number = {3},
pages = {1149},
title = {{Erratum to: The open access advantage considering citation, article usage and social media attention [Scientometrics, DOI:10.1007/s11192-015-1547-0]}},
volume = {103},
year = {2015}
}
@article{Wu2013,
abstract = {Using the dataset based on Thomson Reuters Scientific " Web of Science" the distributions of some well-known indicators, such as h-index and g-index, were investigated, and different citation behaviors across different scientific fields resulting from their field dependences were found. To develop a field-independent index, two scaling methods, based on average citation of subject category and journal, were used to normalize the citation received by each paper of a certain author. The distributions of the generalized h-indices in different fields were found to follow a lognormal function with mean and standard deviation of approximately -0.8 and 0.8, respectively. A field-independent index fi-index was then proposed, and its distribution was found to satisfy a universal power-law function with scaling exponent $\alpha$ approaching 3.0. Both the power-law and the lognormal universality of the distributions verified the field independence of these indicators. However, deciding which of the scaling methods is the better one is necessary for the validation of the field-independent index. {\textcopyright} 2012 Elsevier Ltd.},
author = {Wu, Jiang},
doi = {10.1016/j.joi.2012.08.007},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu - 2013 - Investigating the universal distributions of normalized indicators and developing field-independent index.pdf:pdf},
isbn = {1751-1577},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Field independence,G-Index,H-Index,Lognormal distributions,Power-law distributions,Universality},
number = {1},
pages = {63--71},
publisher = {Elsevier Ltd},
title = {{Investigating the universal distributions of normalized indicators and developing field-independent index}},
url = {http://dx.doi.org/10.1016/j.joi.2012.08.007},
volume = {7},
year = {2013}
}
@article{Xing2004,
abstract = {With the rapid growth of the Web, users easily get lost in the rich hyper structure. Providing the relevant information to users to cater to their needs is the primary goal of Website owners. Therefore, finding the content of the Web and retrieving the users' interests and needs from their behavior have become increasingly important. Web mining is used to categorize users and pages by analyzing user behavior, the content of the pages, and the order of the URLs that tend to be accessed. Web structure mining plays an important role in this approach. Two page ranking algorithms, HITS and PageRank, are commonly used in Web structure mining. Both algorithms treat all links equally when distributing rank scores. Several algorithms have been developed to improve the performance of these methods. The weighted PageRank algorithm (WPR), an extension to the standard PageRank algorithm, is introduced. WPR takes into account the importance of both the inlinks and the outlinks of the pages and distributes rank scores based on the popularity of the pages. The results of our simulation studies show that WPR performs better than the conventional PageRank algorithm in terms of returning a larger number of relevant pages to a given query.},
author = {Xing, Wenpu and Ghorbani, Ali},
doi = {10.1109/DNSR.2004.1344743},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xing, Ghorbani - 2004 - Weighted PageRank algorithm.pdf:pdf},
isbn = {0-7695-2096-0},
journal = {Proceedings of the Second Annual Conference on Communication Networks and Services Research},
keywords = {hits,in the future,of web content mining,pagerank,users want to view,wcm,web mining,web mining consists,web structure mining,weighted pagerank},
pages = {305--314},
title = {{Weighted PageRank algorithm}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1344743},
year = {2004}
}
@article{Zhang2009,
abstract = {BACKGROUND: The h-index has already been used by major citation databases to evaluate the academic performance of individual scientists. Although effective and simple, the h-index suffers from some drawbacks that limit its use in accurately and fairly comparing the scientific output of different researchers. These drawbacks include information loss and low resolution: the former refers to the fact that in addition to h(2) citations for papers in the h-core, excess citations are completely ignored, whereas the latter means that it is common for a group of researchers to have an identical h-index. METHODOLOGY/PRINCIPAL FINDINGS: To solve these problems, I here propose the e-index, where e(2) represents the ignored excess citations, in addition to the h(2) citations for h-core papers. Citation information can be completely depicted by using the h-index together with the e-index, which are independent of each other. Some other h-type indices, such as a and R, are h-dependent, have information redundancy with h, and therefore, when used together with h, mask the real differences in excess citations of different researchers. CONCLUSIONS/SIGNIFICANCE: Although simple, the e-index is a necessary h-index complement, especially for evaluating highly cited scientists or for precisely comparing the scientific output of a group of scientists having an identical h-index.},
author = {Zhang, Chun Ting},
doi = {10.1371/journal.pone.0005429},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang - 2009 - The e-Index, Complementing the h-Index for Excess Citations.pdf:pdf},
isbn = {1932-6203 (Electronic)},
issn = {19326203},
journal = {PLoS ONE},
number = {5},
pages = {2--5},
pmid = {19415119},
title = {{The e-Index, Complementing the h-Index for Excess Citations}},
volume = {4},
year = {2009}
}
@article{Zhao2016,
author = {Zhao, Yong and Li, Dong and Han, Mingjie and Li, Chenying and Li, Dongmei},
doi = {10.1007/s11192-016-1898-1},
file = {:home/sars/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2016 - Characteristics of research collaboration in biotechnology in China evidence from publications indexed in the SCIE.pdf:pdf},
issn = {15882861},
journal = {Scientometrics},
keywords = {Bibliometric methods,Biotechnology,Characteristics,China,Research collaboration},
number = {3},
pages = {1--15},
publisher = {Springer Netherlands},
title = {{Characteristics of research collaboration in biotechnology in China: evidence from publications indexed in the SCIE}},
url = {"http://dx.doi.org/10.1007/s11192-016-1898-1},
volume = {107},
year = {2016}
}

@article{Broadus1987,
author = {Broadus, Robert N.},
title = {Early approaches to bibliometrics},
journal = {Journal of the American Society for Information Science},
volume = {38},
number = {2},
publisher = {Wiley Subscription Services, Inc., A Wiley Company},
issn = {1097-4571},
url = {http://dx.doi.org/10.1002/(SICI)1097-4571(198703)38:2<127::AID-ASI6>3.0.CO;2-K},
doi = {10.1002/(SICI)1097-4571(198703)38:2<127::AID-ASI6>3.0.CO;2-K},
pages = {127--129},
year = {1987},
}

@book{Krištofičová1997,
  title={Prostriedky hodnotenia kni{\v{z}}ni{\v{c}}n{\`y}ch a vedeckoinforma{\v{c}}n{\`y}ch procesov},
  author={Kri{\v{s}}tofi{\v{c}}ov{\'a}, E.},
  isbn={9788085165623},
  lccn={99519622},
  url={https://books.google.sk/books?id=cdGEAAAACAAJ},
  year={1997},
  publisher={Centrum vedecko-technick{\`y}ch inform{\'a}ci{\'\i} SR}
}

@article{Vinkler2001,
author={Vinkler, P{\'e}ter},
title={An attempt for defining some basic categories of scientometrics and classifying the indicators of evaluative scientometrics},
journal={Scientometrics},
year={2001},
volume={50},
number={3},
pages={539--544},
issn={1588-2861},
doi={10.1023/A:1010519000767},
url={http://dx.doi.org/10.1023/A:1010519000767}
}

@Online{Glanzel2004,
	author={Gl{\"a}nzel, Wolfgang and Debackere, Koenradd},
	title={Measuring communication in science : Opportunities and limitations of bibliometric methods},
	publisher={{Steunpunt O\&O Indicatoren}},
	city={Leuven},
	year={2004},
	url={https://www.ulb.ac.be/unica/docs/Sch-com-2004-pres-Glanzel.ppt}
}

@article{Bradford1985,
	author={{Bradford, Samuel C.}},
	title={Sources of Information on Specific Subjects},
	journal={Journal of Information Science},
	year={1985},
	volume={10},
	number={4},
	pages={173--180},
	issn={0165-5515}
}

@article{Bjorneborn2004,
	author = {Björneborn, Lennart and Ingwersen, Peter},
	title = {Toward a basic framework for webometrics},
	journal = {Journal of the American Society for Information Science and Technology},
	volume = {55},
	number = {14},
	publisher = {Wiley Subscription Services, Inc., A Wiley Company},
	issn = {1532-2890},
	url = {http://dx.doi.org/10.1002/asi.20077},
	doi = {10.1002/asi.20077},
	pages = {1216--1227},
	year = {2004},
}

@book{Zipf1935,
  abstract = {first semantic formulation of Zipfs Law},
  added-at = {2007-09-13T14:33:04.000+0200},
  address = {New York, NY, USA},
  author = {Zipf, George Kingsley},
  biburl = {http://www.bibsonomy.org/bibtex/2dd2a96750a2011c85be7e3af523d5d75/lysander07},
  interhash = {8b67f892d5218ba8e9089a71533c83a7},
  intrahash = {dd2a96750a2011c85be7e3af523d5d75},
  keywords = {informationRetrieval linguistics},
  publisher = {Houghton-Mifflin},
  timestamp = {2009-01-27T15:24:50.000+0100},
  title = {The Psychobiology of Language},
  year = 1935
}


@techreport{Page1999,
          number = {1999-66},
           month = {November},
          author = {Lawrence Page and Sergey Brin and Rajeev Motwani and Terry Winograd},
            note = {Previous number = SIDL-WP-1999-0120},
           title = {The PageRank Citation Ranking: Bringing Order to the Web.},
            type = {Technical Report},
       publisher = {Stanford InfoLab},
            year = {1999},
     institution = {Stanford InfoLab},
             url = {http://ilpubs.stanford.edu:8090/422/},
        abstract = {The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank, a mathod for rating Web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to efficiently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation.}
}

@article{Falagas2008,
    abstract = {{The application of currently available sophisticated algorithms of citation analysis allows for the incorporation of the "quality" of citations in the evaluation of scientific journals. We sought to compare the newly introduced SCImago journal rank (SJR) indicator with the journal impact factor (IF). We retrieved relevant information from the official Web sites hosting the above indices and their source databases. The SJR indicator is an open-access resource, while the journal IF requires paid subscription. The SJR indicator (based on Scopus data) lists considerably more journal titles published in a wider variety of countries and languages, than the journal IF (based on Web of Science data). Both indices divide citations to a journal by articles of the journal, during a specific time period. However, contrary to the journal IF, the SJR indicator attributes different weight to citations depending on the "prestige" of the citing journal without the influence of journal self-citations; prestige is estimated with the application of the PageRank algorithm in the network of journals. In addition, the SJR indicator includes the total number of documents of a journal in the denominator of the relevant calculation, whereas the journal IF includes only "citable" articles (mainly original articles and reviews). A 3-yr period is analyzed in both indices but with the use of different approaches. Regarding the top 100 journals in the 2006 journal IF ranking order, the median absolute change in their ranking position with the use of the SJR indicator is 32 (1st quartile: 12; 3rd quartile: 75). Although further validation is warranted, the novel SJR indicator poses as a serious alternative to the well-established journal IF, mainly due to its open-access nature, larger source database, and assessment of the quality of citations.}},
    author = {Falagas, Matthew E. and Kouranos, Vasilios D. and Jorge, Ricardo A. and Karageorgopoulos, Drosos E.},
    citeulike-article-id = {4003169},
    citeulike-linkout-0 = {http://dx.doi.org/10.1096/fj.08-107938},
    doi = {10.1096/fj.08-107938},
    journal = {The FASEB Journal},
    keywords = {algorithms, as, bibliographic, bibliometrics, databases, file-import-09-02-03, periodicals, topic},
    local-url = {file://localhost/Users/piotr/Documents/Papers/2008/Falagas/The\%20FASEB\%20Journal\%202008\%20Falagas-1.pdf},
    month = aug,
    number = {8},
    pages = {2623--8},
    posted-at = {2009-02-03 22:55:04},
    priority = {2},
    title = {{Comparison of SCImago journal rank indicator with journal impact factor}},
    url = {http://dx.doi.org/10.1096/fj.08-107938},
    volume = {22},
    year = {2008}
}

@article{GuerreroBote2012,
	title = {A further step forward in measuring journals’ scientific prestige: The \{SJR2\} indicator},
	journal = {Journal of Informetrics},
	volume = {6},
	number = {4},
	pages = {674--688},
	year = {2012},
	issn = {1751-1577},
	doi = {http://dx.doi.org/10.1016/j.joi.2012.07.001},
	url = {http://www.sciencedirect.com/science/article/pii/S1751157712000521},
	author = {Vicente P. Guerrero-Bote and Félix Moya-Anegón},
	keywords = {\"SJR2\" indicator},
	keywords = {Academic journals},
	keywords = {Journal prestige},
	keywords = {Eigenvector centrality},
	keywords = {Citation networks}
}

@article{Vine2006,
	author = {Vine, Rita},
	title={Google Scholar},
	journal={J Med Libr Assoc},
	year={2006},
	month={Jan},
	publisher={Medical Library Association},
	volume={94},
	number={1},
	pages={97--99},
	issn={1536-5050},
	url={http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1324783/}
}

@article{Beel2009,
	author = {Beel, J{\"o}ran and Gripp, Bela},
	title = {Google Scholar‘s Ranking Algorithm: An ntroductory Overview},
	journal = {International Society for Scientometrics and Informetrics},
	year = {2009},
	month = {July},
	volume = {1},
	pages = {230--241},
	issn = {2175-1935},
}


@article{Orduna-Malea2015,
	author = {Orduna-Malea, Enrique
	and Ayll{\'o}n, Juan M.
	and Mart{\'i}n-Mart{\'i}n, Alberto
	and Delgado L{\'o}pez-C{\'o}zar, Emilio},
	title = {Methods for estimating the size of Google Scholar},
	journal = {Scientometrics},
	year = {2015},
	volume = {104},
	number = {3},
	pages = {931--949},
	abstract = {The emergence of academic search engines (mainly Google Scholar and Microsoft Academic Search) that aspire to index the entirety of current academic knowledge has revived and increased interest in the size of the academic web. The main objective of this paper is to propose various methods to estimate the current size (number of indexed documents) of Google Scholar (May 2014) and to determine its validity, precision and reliability. To do this, we present, apply and discuss three empirical methods: an external estimate based on empirical studies of Google Scholar coverage, and two internal estimate methods based on direct, empty and absurd queries, respectively. The results, despite providing disparate values, place the estimated size of Google Scholar at around 160--165 million documents. However, all the methods show considerable limitations and uncertainties due to inconsistencies in the Google Scholar search functionalities.},
	issn = {1588-2861},
	doi = {10.1007/s11192-015-1614-6},
	url = {http://dx.doi.org/10.1007/s11192-015-1614-6}
}


@article{Khabsa2014,
    author = {Khabsa, Madian AND Giles, C. Lee},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {The Number of Scholarly Documents on the Public Web},
    year = {2014},
    month = {05},
    volume = {9},
    url = {http://dx.doi.org/10.1371\%2Fjournal.pone.0093949},
    pages = {1-6},
    abstract = {The number of scholarly documents available on the web is estimated using capture/recapture methods by studying the coverage of two major academic search engines: Google Scholar and Microsoft Academic Search. Our estimates show that at least 114 million English-language scholarly documents are accessible on the web, of which Google Scholar has nearly 100 million. Of these, we estimate that at least 27 million (24\%) are freely available since they do not require a subscription or payment of any kind. In addition, at a finer scale, we also estimate the number of scholarly documents on the web for fifteen fields: Agricultural Science, Arts and Humanities, Biology, Chemistry, Computer Science, Economics and Business, Engineering, Environmental Sciences, Geosciences, Material Science, Mathematics, Medicine, Physics, Social Sciences, and Multidisciplinary, as defined by Microsoft Academic Search. In addition, we show that among these fields the percentage of documents defined as freely available varies significantly, i.e., from 12 to 50\%.},
    number = {5},
    doi = {10.1371/journal.pone.0093949}
}

@Online{Jacso2009,
	author={Jacso, Peter},
	title={Google Scholar’s Ghost Authors},
	publisher={Library Journal},
	year={2009},
	url={http://lj.libraryjournal.com/2009/11/industry-news/google-scholars-ghost-authors/}
}



@article{Jacso2010,
	author = {Jacsó, Péter},
	title = {Metadata mega mess in Google Scholar},
	journal = {Online Information Review},
	volume = {34},
	number = {1},
	pages = {175-191},
	year = {2010},
	doi = {10.1108/14684521011024191},
	URL = {http://dx.doi.org/10.1108/14684521011024191},
	abstract = { Purpose – Google Scholar (GS) has shed the beta label on the fifth anniversary of launching its service. This paper aims to address this issue.Design/methodology/approach – As good as GS is – through its keyword search option – to find information about tens of millions of documents, many of them in open access full text format, it is as bad for metadata‐based searching when, beyond keywords in the title, abstract, descriptor and/or full text, the searcher also has to use author name, journal title and/or publication year in specifying the query. This paper provides a review of recent developments in Google Scholar.Findings – GS is especially inappropriate for bibliometric searches, for evaluating the publishing performance and impact of researchers and journals.Originality/value – Even if the clean up of Google Scholar accelerates it should not be forgotten that those evaluations of individuals and journals that have been done based on Google Scholar in the past few years have grossly handicapped many authors and journals whose name was replaced by phantom entries. }
}

@inproceedings{Beel2010b,
 author = {Beel, J\"{o}ran and Gipp, Bela},
 title = {On the Robustness of Google Scholar Against Spam},
 booktitle = {Proceedings of the 21st ACM Conference on Hypertext and Hypermedia},
 series = {HT '10},
 year = {2010},
 isbn = {978-1-4503-0041-4},
 location = {Toronto, Ontario, Canada},
 pages = {297--298},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/1810617.1810683},
 doi = {10.1145/1810617.1810683},
 acmid = {1810683},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {academic search engines, citation spam, search engines, spam, spamdexing},
} 

@article{Beel2010a,
    author = {Beel, J\"{o}eran and Gipp, Bela},
    citeulike-article-id = {8461062},
    citeulike-linkout-0 = {http://dx.doi.org/10.3998/3336451.0013.305},
    day = {17},
    doi = {10.3998/3336451.0013.305},
    issn = {10802711},
    journal = {Journal of Electronic Publishing},
    keywords = {academicseo, altmetrics, google\_scholar, metrics, ranking},
    month = dec,
    number = {3},
    posted-at = {2010-12-21 14:24:12},
    priority = {0},
    title = {{Academic Search Engine Spam and Google Scholar's Resilience Against it}},
    url = {http://dx.doi.org/10.3998/3336451.0013.305},
    volume = {13},
    year = {2010}
}

@Article{Kazakis2014b,
	author = {Kazakis, Nikolaos A.},
	title = {Bibliometric evaluation of the research performance of the Greek civil engineering departments in National and European context},
	journal = {Scientometrics},
	year = {2014},
	volume = {101},
	number = {1},
	pages = {505--525},
	abstract = {Quality evaluation and its assurance in higher education institutions constitute an obligation and scope of most European Universities. To accomplish this, quantitative indices, known as bibliometrics, are recruited which are considered a useful evaluation tool particularly for academics' and Universities' research performance. In the present study, the research quality of the five Greek civil engineering departments (Athens, Patras, Thessaloniki, Volos, Xanthi) is assessed by means of several advanced bibliometric indices calculated separately for each academic. Statistical analysis of the data is also performed to compare the observed differences in the mean values of the calculated indices. The study is conducted both in department and academic rank level to explore how research activity is distributed among the various ranks. In addition, to evaluate the research status of the Greek departments in the European context, their research output is compared with that of London civil engineering department. To explore the dependence of bibliometrics on seniority, bibliometric analysis considering the research activity of all academics only during the last decade is also made. Finally, the temporal progress of the research productivity leads to interesting findings about the impact of the European economic crisis on research performance. In general, bibliometrics demonstrate that Patras department host academics of better quality, but Athens exhibits higher scientific activity over the last decade. Superiority of London department is evident but few bibliometrics are comparable with the ones of the Greek departments. Results also indicate that no common standards in hiring/promotion of academics are established, while the European socio-economic crisis has significant negative impact on research productivity.},
	issn = {1588-2861},
	doi = {10.1007/s11192-014-1326-3},
	url = {http://dx.doi.org/10.1007/s11192-014-1326-3}
}






@article{Altanopoulou2012,
  author = {Altanopoulou, Panagiota  and  Dontsidou, Maria and Tselios, Nikolaos},
  title = {Evaluation of ninety-three major Greek university departments using Google Scholar},
  journal = {Quality in Higher Education},
  volume = {18},
  number = {1},
  pages = {111-137},
  year = {2012},
  doi = {10.1080/13538322.2012.670918},
  URL = {http://dx.doi.org/10.1080/13538322.2012.670918},

}


